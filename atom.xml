<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>一只程序喵</title>
  
  <subtitle>刘明辉的个人博客</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="http://yoursite.com/"/>
  <updated>2019-08-23T14:49:53.723Z</updated>
  <id>http://yoursite.com/</id>
  
  <author>
    <name>刘明辉</name>
    
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>deeplearning.ai学习笔记（九）构建机器学习项目之机器学习策略（下）</title>
    <link href="http://yoursite.com/2019/08/23/deeplearning-ai%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B9%9D%EF%BC%89%E6%9E%84%E5%BB%BA%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%A1%B9%E7%9B%AE%E4%B9%8B%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AD%96%E7%95%A5%EF%BC%88%E4%B8%8B%EF%BC%89/"/>
    <id>http://yoursite.com/2019/08/23/deeplearning-ai学习笔记（九）构建机器学习项目之机器学习策略（下）/</id>
    <published>2019-08-23T01:35:24.000Z</published>
    <updated>2019-08-23T14:49:53.723Z</updated>
    
    <content type="html"><![CDATA[<h2 id="错误分析（Error-Analysis）"><a href="#错误分析（Error-Analysis）" class="headerlink" title="错误分析（Error Analysis）"></a>错误分析（Error Analysis）</h2><p>通过人工检查机器学习模型得出的结果中出现的一些错误，有助于深入了解下一步要进行的工作。这个过程被称作<strong>错误分析</strong>。</p><h3 id="分析方法"><a href="#分析方法" class="headerlink" title="分析方法"></a>分析方法</h3><p>对输出结果中分类错误的样本进行人工分析，建立一个表格来记录每一个分类错误的具体信息。通过统计不同错误标记类型占总数的百分比，发现哪些问题亟待解决，或者提供构思新优化方向的灵感。</p><p>例：</p><div class="table-container"><table><thead><tr><th><strong>Image</strong></th><th style="text-align:center"><strong>Dog</strong></th><th><strong>Great Cat</strong></th><th><strong>Blurry</strong></th><th><strong>Incorrectly labeled</strong></th><th><strong>Comments</strong></th></tr></thead><tbody><tr><td>…</td><td style="text-align:center"></td><td></td><td></td><td></td><td></td></tr><tr><td>98</td><td style="text-align:center"></td><td></td><td></td><td>✓</td><td>Labeler missed cat in background</td></tr><tr><td>99</td><td style="text-align:center"></td><td>✓</td><td></td><td></td><td></td></tr><tr><td>100</td><td style="text-align:center"></td><td></td><td></td><td>✓</td><td>Drawing   of a cat;   Not   a real cat.</td></tr><tr><td>% of total</td><td style="text-align:center">8%</td><td>43%</td><td>61%</td><td>6%</td></tr></tbody></table></div><h3 id="错误标记（incorrectly-labeled）问题"><a href="#错误标记（incorrectly-labeled）问题" class="headerlink" title="错误标记（incorrectly labeled）问题"></a>错误标记（incorrectly labeled）问题</h3><p><strong>训练集中：</strong></p><blockquote><p>DL algorithms are quite robust to random errors in the training set.</p></blockquote><p>由于深度学习算法对于随机误差的<strong>鲁棒性（Robust）</strong>，只要出错的样本数量较小且分布<strong>近似随机</strong>，就不必花费时间一一修正。</p><p><strong>验证/测试集中：</strong></p><p>在进行误差分析时，通过统计人为标记错误所占的百分比，来大致分析这种情况对模型的识别准确率的影响，并比较该比例的大小和其他错误类型的比例，以此判断是否值得去将错误的标记一一进行修正，还是可以忽略。</p><p>注：在验证集和测试集上<strong>同时使用同样的修正手段</strong>，以保证验证集和测试集来自相同的分布。</p><h3 id="总结：快速搭建系统并迭代"><a href="#总结：快速搭建系统并迭代" class="headerlink" title="总结：快速搭建系统并迭代"></a><strong>总结：快速搭建系统并迭代</strong></h3><blockquote><p>Build your first system quickly, then iterate.</p></blockquote><ol><li>设置好训练、验证、测试集及衡量指标，确定目标；</li><li>快速训练出一个初步的系统，用训练集来拟合参数，用验证集<strong>调参</strong>，用测试集评估；</li><li>通过<strong>偏差/方差分析</strong>以及<strong>错误分析</strong>等方法，决定下一步优先处理的方向。</li></ol><h2 id="Train-set与Dev-Test-set分布不一致问题"><a href="#Train-set与Dev-Test-set分布不一致问题" class="headerlink" title="Train set与Dev/Test set分布不一致问题"></a>Train set与Dev/Test set分布不一致问题</h2><p>以猫咪识别为例：</p><ul><li>训练集：由网络爬取得到，图片比较清晰，而且规模较大（例如 20 万）；</li><li>验证/测试集：来自用户手机拍摄，图片比较模糊，且数量较少（例如 1 万）。</li></ul><h3 id="分布不一致情况下的数据集划分"><a href="#分布不一致情况下的数据集划分" class="headerlink" title="分布不一致情况下的数据集划分"></a>分布不一致情况下的数据集划分</h3><p>策略：<strong>保证验证/测试集更接近实际应用场景</strong>。</p><p>例：将 20 万张网络爬取的图片和 5000 张用户上传的图片作为训练集，而将剩下的 5000 张图片一半作验证集，一半作测试集。</p><h3 id="分布不一致情况下的偏差-方差分析"><a href="#分布不一致情况下的偏差-方差分析" class="headerlink" title="分布不一致情况下的偏差/方差分析"></a>分布不一致情况下的偏差/方差分析</h3><p>在可能存在训练集和验证/测试集分布不一致的情况下，再定义一个<strong>训练-验证集（Training-dev Set）</strong>。训练-验证集和训练集的分布相同（或者是训练集分割出的子集），但是不参与训练过程。</p><ul><li>训练集错误率和训练-验证集错误率的差值反映了方差；</li><li>训练-验证集错误率和验证集错误率的差值反映了样本分布不一致的问题。</li></ul><p><strong>总结：偏差/方差分析</strong></p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://s2.ax1x.com/2019/08/23/msFt9H.png" alt="偏差/方差分析" title>                </div>                <div class="image-caption">偏差/方差分析</div>            </figure><h3 id="分布不一致问题解决建议"><a href="#分布不一致问题解决建议" class="headerlink" title="分布不一致问题解决建议"></a>分布不一致问题解决建议</h3><ul><li>进行<strong>错误分析</strong>，了解训练集和验证/测试集的具体差异；</li><li>尝试将训练数据调整得更像验证集，或者收集更多类似于验证/测试集的数据。（例如：进行<strong>人工合成数据</strong>，给训练集人工添加背景噪声，合成类似实际场景的声音，即类似验证/测试集。）</li></ul><h2 id="迁移学习（Tranfer-Learning）"><a href="#迁移学习（Tranfer-Learning）" class="headerlink" title="迁移学习（Tranfer Learning）"></a>迁移学习（Tranfer Learning）</h2><p><strong>迁移学习（Tranfer Learning）</strong>是通过将已训练好的神经网络模型的一部分网络结构应用到另一模型，将一个神经网络从某个任务中学到的知识和经验运用到另一个任务中，以显著提高学习任务的性能。</p><h3 id="迁移学习的过程"><a href="#迁移学习的过程" class="headerlink" title="迁移学习的过程"></a>迁移学习的过程</h3><ol><li><strong>预训练（Pre-Training）：</strong>初始<em>W</em>[<em>l</em>], <em>b</em>[<em>l</em>]由之前的模型训练得到。</li><li><strong>微调（Fine-Tuning）</strong><ul><li>若构建新模型的样本数量较少，<strong>只训练输出层的权重系数<em>W</em>[<em>L</em>], <em>b</em>[<em>L</em>]</strong>，保持其它层所有的权重系数<em>W</em>[<em>l</em>], <em>b</em>[<em>l</em>]不变；</li><li>若构建新模型的样本数量足够多，保留网络结构，<strong>重新训练所有层的权重系数</strong>。</li></ul></li></ol><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://s2.ax1x.com/2019/08/23/msFJ4e.png" alt="迁移学习" title>                </div>                <div class="image-caption">迁移学习</div>            </figure><p>迁移学习可以保留原神经网络的一部分，可以去掉输出层后再增加额外一些神经层。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://s2.ax1x.com/2019/08/23/msFN3d.png" alt="迁移学习——增加网络层数" title>                </div>                <div class="image-caption">迁移学习——增加网络层数</div>            </figure><h3 id="迁移学习的适用条件"><a href="#迁移学习的适用条件" class="headerlink" title="迁移学习的适用条件"></a>迁移学习的适用条件</h3><ol><li>两个任务有同样的输入（比如都是图像或者都是音频）；</li><li><strong>拥有更多数据的任务迁移到数据较少的任务</strong>；</li><li>某一任务的低层次特征对另一个任务的学习有帮助。</li></ol><h2 id="多任务学习（Multi-Task-Learning）"><a href="#多任务学习（Multi-Task-Learning）" class="headerlink" title="多任务学习（Multi-Task Learning）"></a>多任务学习（Multi-Task Learning）</h2><p><strong>多任务学习（Multi-Task Learning）</strong>使用单个神经网络模型，利用共享表示并行地训练，同时学习多个任务。多任务学习的基本假设是<strong>多个任务之间具有相关性</strong>，并且任务之间可以利用相关性相互促进。</p><p>在实践中，多任务学习的使用频率要远低于迁移学习。计算机视觉领域中的<strong>物体识别</strong>是一个多任务学习的例子。</p><h3 id="多任务学习的输出与代价函数"><a href="#多任务学习的输出与代价函数" class="headerlink" title="多任务学习的输出与代价函数"></a>多任务学习的输出与代价函数</h3><p>以汽车自动驾驶为例，需要实现的多任务是识别行人、车辆、交通标志和信号灯。如果在输入的图像中检测出车辆和交通标志，则输出的 y 为：</p><script type="math/tex; mode=display"> y=\begin{bmatrix}   0 \\   1\\  1\\  0  \end{bmatrix}</script><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://s2.ax1x.com/2019/08/23/msFGND.png" alt="多任务学习实例——汽车自动驾驶" title>                </div>                <div class="image-caption">多任务学习实例——汽车自动驾驶</div>            </figure><p><strong>多任务学习 vs. 多分类问题：</strong>Softmax 回归的输出向量 y 中只有一个元素为 1；多任务学习的输出向量 y 中可以有多个元素为 1。</p><h3 id="多任务学习的适用条件"><a href="#多任务学习的适用条件" class="headerlink" title="多任务学习的适用条件"></a>多任务学习的适用条件</h3><ol><li>训练的一组任务可以共用低层次特征；</li><li>每个任务的数据量通常比较接近；</li><li>能够训练一个足够大的神经网络，以同时做好所有的工作。与为每个任务训练单个神经网络相比，多任务学习神经网络足够大时性能不会差。</li></ol><h2 id="端到端深度学习（End-to-end-Deep-Learning）"><a href="#端到端深度学习（End-to-end-Deep-Learning）" class="headerlink" title="端到端深度学习（End-to-end Deep Learning）"></a>端到端深度学习（End-to-end Deep Learning）</h2><h3 id="机器学习分块模型-vs-端到端深度学习"><a href="#机器学习分块模型-vs-端到端深度学习" class="headerlink" title="机器学习分块模型 vs. 端到端深度学习"></a>机器学习分块模型 vs. 端到端深度学习</h3><ol><li><p>概念</p><ul><li><strong>传统的机器学习分块模型：</strong>每一个模块处理一种输入，然后其输出作为下一个模块的输入，构成一条流水线。</li><li><strong>端到端深度学习（End-to-end Deep Learning）：</strong>只用一个单一的神经网络模型来实现所有的功能，将所有模块混合在一起，只关心输入和输出。</li></ul></li><li><p>应用情况</p><ul><li><p>若数据量较少，传统机器学习分块模型所构成的流水线效果较好；</p></li><li><p>若数据量足够大，且训练出的神经网络模型足够复杂，那么端到端深度学习模型的性能会比传统机器学习分块模型更好；</p></li><li><p>若数据量规模适中，可以使用流水线混合端到端深度学习。</p><p><img src="https://s2.ax1x.com/2019/08/23/msF8AO.png" alt="机器学习分块模型 vs. 端到端深度学习"></p></li></ul></li></ol><h3 id="端到端深度学习的优缺点"><a href="#端到端深度学习的优缺点" class="headerlink" title="端到端深度学习的优缺点"></a>端到端深度学习的优缺点</h3><p><strong>优点：</strong></p><ul><li>让数据发挥主导作用：只要有足够多的数据和足够大的神经网络都可以拟合出X到Y的映射，而不需要用人类固有的认知（或者说，成见）来进行分析；</li><li>所需手工设计的组件更少，简化设计工作流程。</li></ul><p><strong>缺点：</strong></p><ul><li>需要大量的数据；</li><li>排除了可能有用的人工设计组件。</li></ul>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;错误分析（Error-Analysis）&quot;&gt;&lt;a href=&quot;#错误分析（Error-Analysis）&quot; class=&quot;headerlink&quot; title=&quot;错误分析（Error Analysis）&quot;&gt;&lt;/a&gt;错误分析（Error Analysis）&lt;/h2&gt;&lt;
      
    
    </summary>
    
    
      <category term="学习笔记" scheme="http://yoursite.com/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
      <category term="deeplearning.ai" scheme="http://yoursite.com/tags/deeplearning-ai/"/>
    
  </entry>
  
  <entry>
    <title>deeplearning.ai学习笔记（八）构建机器学习项目之机器学习策略（上）</title>
    <link href="http://yoursite.com/2019/08/22/deeplearning-ai%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E5%85%AB%EF%BC%89%E6%9E%84%E5%BB%BA%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E9%A1%B9%E7%9B%AE%E4%B9%8B%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E7%AD%96%E7%95%A5%EF%BC%88%E4%B8%8A%EF%BC%89/"/>
    <id>http://yoursite.com/2019/08/22/deeplearning-ai学习笔记（八）构建机器学习项目之机器学习策略（上）/</id>
    <published>2019-08-22T07:49:48.000Z</published>
    <updated>2019-08-22T12:19:11.440Z</updated>
    
    <content type="html"><![CDATA[<h2 id="正交化（Orthogonalization）方法"><a href="#正交化（Orthogonalization）方法" class="headerlink" title="正交化（Orthogonalization）方法"></a>正交化（Orthogonalization）方法</h2><p><strong>正交化（Orthogonalization）</strong>的核心在于每次调整只会影响模型某一方面的性能，而对其他功能没有影响。这种方法有助于更快更有效地进行机器学习模型的调试和优化。</p><p>对于机器学习系统，可以大致分成四个独立的目标，且都有其对应的正交化方法：</p><a id="more"></a><ol><li>建立的模型在训练集上表现良好（Fit training set well on cost function）；<ul><li>训练更复杂的NN</li><li>使用更高级的优化算法（如Adam）</li><li>……</li></ul></li><li>建立的模型在验证集上表现良好（Fit dev set well on cost function）；<ul><li>正则化</li><li>采用更多训练样本</li><li>……</li></ul></li><li>建立的模型在测试集上表现良好（Fit test set well on cost function）；<ul><li>使用更多的验证集样本</li><li>……</li></ul></li><li>建立的模型在实际应用中表现良好（Performs well in real world）。<ul><li>更换验证集</li><li>使用新的cost function</li><li>……</li></ul></li></ol><p><strong>反例：early stopping</strong>——在提升验证集性能的同时降低了训练集的性能，即同时影响两个目标，不具有正交性。</p><h2 id="系统评价指标"><a href="#系统评价指标" class="headerlink" title="系统评价指标"></a>系统评价指标</h2><h3 id="单值评价指标"><a href="#单值评价指标" class="headerlink" title="单值评价指标"></a>单值评价指标</h3><p>通过设置一个量化的<strong>单值评价指标</strong>（single-number evaluation metric），可以使我们根据这一指标比较不同超参数对应的模型的优劣，从而选择最优的那个模型。</p><p>例：二分类问题中的<strong>准确率（Precision）</strong>、<strong>召回率（Recall）</strong>、<strong>F1 Score</strong></p><script type="math/tex; mode=display">准确率~P=\frac{预测为正类的正类数量}{预测为正类的数量}*100\\召回率~R=\frac{预测为正类的正类数量}{正类的数量}*100\\F_1=\frac{2}{\frac{1}{P}+\frac{1}{R}}=\frac{2PR}{P+R}</script><p>F1 Score 其实就是精准率和召回率的<strong>调和平均数（Harmonic Mean）</strong>。实际应用中，通常使用综合了精确率和召回率的单值评价指标 F1 Score 来评价模型的好坏。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://s2.ax1x.com/2019/08/22/m0dvzn.png" alt="F1 Score评价（A更优）" title>                </div>                <div class="image-caption">F1 Score评价（A更优）</div>            </figure><p>除了F1 Score之外，我们还可以使用平均值作为单值评价指标来对模型进行评估。如评价六个模型对不同国家样本的错误率不同，可以计算其平均性能，然后选择平均错误率最小的那个模型。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://s2.ax1x.com/2019/08/22/m0wpLV.png" alt="平均值评价（C更优）" title>                </div>                <div class="image-caption">平均值评价（C更优）</div>            </figure><h3 id="优化指标和满足指标"><a href="#优化指标和满足指标" class="headerlink" title="优化指标和满足指标"></a>优化指标和满足指标</h3><p>把所有的性能指标都综合在一起，构成单值评价指标是比较困难的。可以<strong>把某些性能作为优化指标（Optimizing metic），寻求最优化值</strong>；而<strong>某些性能作为满足指标（Satisficing metic），满足阈值即可</strong>。</p><p>例：</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://s2.ax1x.com/2019/08/22/m0wSs0.png" alt="Optimizing metic vs. Satisficing metic" title>                </div>                <div class="image-caption">Optimizing metic vs. Satisficing metic</div>            </figure><p>将Accuracy作为优化指标，将Running time作为满足指标。即<strong>给Running time设定一个阈值，在其满足阈值的情况下，选择Accuracy最大的模型</strong>。如果设定Running time必须在100ms以内，那么很明显，模型C不满足阈值条件，首先剔除；模型B相比较模型A而言，Accuracy更高，性能更好。</p><h2 id="人类表现水平（Human-level-performance）"><a href="#人类表现水平（Human-level-performance）" class="headerlink" title="人类表现水平（Human-level performance）"></a>人类表现水平（Human-level performance）</h2><h3 id="人类水平误差-vs-贝叶斯最优误差"><a href="#人类水平误差-vs-贝叶斯最优误差" class="headerlink" title="人类水平误差 vs. 贝叶斯最优误差"></a>人类水平误差 vs. 贝叶斯最优误差</h3><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://s2.ax1x.com/2019/08/22/m0wioF.png" alt="机器学习系统表现水平增长" title>                </div>                <div class="image-caption">机器学习系统表现水平增长</div>            </figure><p>上图展示了随着时间的推进，机器学习系统和人的表现水平的变化。一般的，当机器学习超过人的表现水平后，它的进步速度逐渐变得缓慢，最终性能无法超过某个理论上限，这个上限被称为<strong>贝叶斯最优误差（Bayes Optimal Error）</strong>。</p><p>一般用<strong>人类水平误差（Human-level Error）</strong>来代表贝叶斯最优误差（或者简称贝叶斯误差）。对于不同领域的例子，不同人群由于其经验水平不一，错误率也不同。一般来说，<strong>我们将表现最好的作为人类水平误差</strong>。</p><p><strong>总结：</strong></p><ul><li>贝叶斯最优误差：理论上可能达到的最优误差；</li><li>人类水平误差：贝叶斯最优误差的近似值（尤其对于图像、声音等自然感知问题）。</li></ul><h3 id="可避免偏差（Avoidable-Bias）"><a href="#可避免偏差（Avoidable-Bias）" class="headerlink" title="可避免偏差（Avoidable Bias）"></a>可避免偏差（Avoidable Bias）</h3><p><strong>可避免偏差</strong>（Avoidable Bias）：模型在<strong>训练集</strong>上的误差与人类表现水平的差值<strong>。</strong></p><ul><li>可避免偏差低——意味着模型在训练集上的表现很好；</li><li>训练集与验证集之间错误率的差值小——意味着模型在验证集与测试集上的表现和训练集同样好。</li></ul><p><strong>策略：如果可避免偏差大于训练集与验证集之间错误率的差值，之后的工作就应该专注于减小偏差；反之，就应该专注于减小方差。</strong></p><p><strong>注：不同人选择人类水平误差的基准的不同会带来一定的影响。</strong></p><p>例如，如果某模型在训练集上的错误率为 0.7%，验证集的错误率为 0.8%。如果选择的人类水平误差为 0.5%，那么偏差（bias）比方差（variance）更加突出；而如果选择的人类水平误差为 0.7%，则方差更加突出。也就是说，根据人类水平误差的不同选择，我们可能因此选择不同的优化操作。</p><h3 id="提高模型表现水平"><a href="#提高模型表现水平" class="headerlink" title="提高模型表现水平"></a>提高模型表现水平</h3><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://s2.ax1x.com/2019/08/22/m0wki4.png" alt="Improving your model performance" title>                </div>                <div class="image-caption">Improving your model performance</div>            </figure>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;正交化（Orthogonalization）方法&quot;&gt;&lt;a href=&quot;#正交化（Orthogonalization）方法&quot; class=&quot;headerlink&quot; title=&quot;正交化（Orthogonalization）方法&quot;&gt;&lt;/a&gt;正交化（Orthogonalization）方法&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;正交化（Orthogonalization）&lt;/strong&gt;的核心在于每次调整只会影响模型某一方面的性能，而对其他功能没有影响。这种方法有助于更快更有效地进行机器学习模型的调试和优化。&lt;/p&gt;
&lt;p&gt;对于机器学习系统，可以大致分成四个独立的目标，且都有其对应的正交化方法：&lt;/p&gt;
    
    </summary>
    
    
      <category term="学习笔记" scheme="http://yoursite.com/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
      <category term="deeplearning.ai" scheme="http://yoursite.com/tags/deeplearning-ai/"/>
    
  </entry>
  
  <entry>
    <title>deeplearning.ai学习笔记（七）优化深度神经网络之超参数调试、批标准化与深度学习框架</title>
    <link href="http://yoursite.com/2019/08/20/deeplearning-ai%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%83%EF%BC%89%E4%BC%98%E5%8C%96%E6%B7%B1%E5%BA%A6%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B9%8B%E8%B6%85%E5%8F%82%E6%95%B0%E8%B0%83%E8%AF%95%E3%80%81Batch%E6%A0%87%E5%87%86%E5%8C%96%E4%B8%8E%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E6%A1%86%E6%9E%B6/"/>
    <id>http://yoursite.com/2019/08/20/deeplearning-ai学习笔记（七）优化深度神经网络之超参数调试、Batch标准化与深度学习框架/</id>
    <published>2019-08-20T07:00:21.000Z</published>
    <updated>2019-08-22T12:18:24.240Z</updated>
    
    <content type="html"><![CDATA[<h2 id="超参数调试"><a href="#超参数调试" class="headerlink" title="超参数调试"></a>超参数调试</h2><h3 id="不同超参数的重要性排序"><a href="#不同超参数的重要性排序" class="headerlink" title="不同超参数的重要性排序"></a>不同超参数的重要性排序</h3><p><strong>第一梯队：</strong></p><ul><li>学习率α：最重要</li></ul><p><strong>第二梯队：</strong></p><ul><li>动量衰减参数β：一般设置为0.9</li><li>各隐藏层神经元个数#hidden units</li><li>小批量大小mini-batch size</li></ul><p><strong>第三梯队：</strong></p><ul><li>神经网络层数#layers</li><li>学习率衰减率decay_rate</li></ul><p><strong>第四梯队：</strong></p><ul><li><p>Adam优化算法超参数β1、β2、ε：一般设置为0.9、0.99、10^-8</p><a id="more"></a></li></ul><h3 id="超参数调试方法"><a href="#超参数调试方法" class="headerlink" title="超参数调试方法"></a>超参数调试方法</h3><p><strong>均匀取点 vs 随机取点：</strong></p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://s2.ax1x.com/2019/08/22/m0dXGj.png" alt="均匀取点 vs 随机取点" title>                </div>                <div class="image-caption">均匀取点 vs 随机取点</div>            </figure><p>由于事先很难知道超参数的重要程度，因此<strong>选择随机取点</strong>来选择更多的值进行更多实验。为了得到更精确的最优参数，我们应该继续<strong>对模型表现较好的区域进行由粗到细的采样</strong>。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://s2.ax1x.com/2019/08/22/m0dOiQ.png" alt="由粗到细采样" title>                </div>                <div class="image-caption">由粗到细采样</div>            </figure><h3 id="超参数调试技巧"><a href="#超参数调试技巧" class="headerlink" title="超参数调试技巧"></a>超参数调试技巧</h3><ol><li><p>选择适当的尺度</p><ul><li><p>均匀随机采样：对于超参数#layers和#hidden units等，取值为正整数，超参数每次变化的尺度都是一致的。</p></li><li><p>非均匀随机采样：例如学习率<em>α</em>，待调范围是[0.0001, 1]。在实际应用中，最佳的<em>α</em>值可能主要分布在[0.0001, 0.1]之间，而[0.1, 1]范围内<em>α</em>值效果并不好。如果使用均匀随机采样，那么有90%的采样点分布在[0.1, 1]之间，只有10%分布在[0.0001, 0.1]之间。通常的做法是<strong>将线性尺度转换为对数尺度</strong>，然后再<strong>在对数尺度下进行均匀采样</strong>。</p></li></ul><p><img src="https://s2.ax1x.com/2019/08/22/m0dHZ8.png" alt="线性尺度转换为对数尺度"></p><p>具体做法：如果线性区间为[a, b]，令m=log(a)，n=log(b)，则对应的log区间为[m,n]。对log区间的[m,n]进行随机均匀采样，然后得到的采样值r，最后反推到线性区间10^r。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">m = np.log10(a)</span><br><span class="line">n = np.log10(b)</span><br><span class="line">r = np.random.rand()</span><br><span class="line">r = m + (n-m)*r</span><br><span class="line">r = np.power(<span class="number">10</span>,r)</span><br></pre></td></tr></table></figure></li><li><p>深度学习不同的应用领域出现相互交融的现象，某个应用领域的超参数设定有可能通用于另一领域，应该更多地阅读其他研究领域的 paper，跨领域地寻找灵感。</p></li><li><p>考虑到数据的变化或者服务器的变更等因素，建议每隔几个月重新测试或评估超参数，来获得实时的最佳模型。</p></li><li><p>根据所拥有的计算资源决定训练模型的方式：</p><ul><li><p>Panda（熊猫方式）：受计算能力所限，只能对一个模型进行训练，调试不同的超参数，使得这个模型有最佳的表现；</p></li><li><p>Caviar（鱼子酱方式）：对多个模型同时进行训练，每个模型上调试不同的超参数，根据表现情况，选择最佳的模型。</p><p><img src="https://s2.ax1x.com/2019/08/22/m0dqIg.png" alt="Pandas vs. Caviar"></p></li></ul></li></ol><h2 id="批标准化（Batch-Normalization）"><a href="#批标准化（Batch-Normalization）" class="headerlink" title="批标准化（Batch Normalization）"></a>批标准化（Batch Normalization）</h2><p>批标准化 (Batch Normalization) 是对于神经网络中间隐藏层的输出进行标准化。批标准化可以使神经网络更加鲁棒，对于超参数的选择不再那么敏感，从而可以更容易地训练非常深的网络。</p><h3 id="批标准化算法（BN算法）"><a href="#批标准化算法（BN算法）" class="headerlink" title="批标准化算法（BN算法）"></a>批标准化算法（BN算法）</h3><p>第<em>l</em>层隐藏层的输入就是第<em>l</em>−1层隐藏层的输出<em>A</em>[<em>l</em>−1]。对<em>A</em>[<em>l</em>−1]进行标准化处理，从原理上来说可以提高<em>W</em>[<em>l</em>]和<em>b</em>[<em>l</em>]的训练速度和准确度实际应用中，<strong>一般是对<em>Z</em>[<em>l</em>−1]进行标准化处理</strong>而不是<em>A</em>[<em>l</em>−1]。</p><script type="math/tex; mode=display">\mu=\frac{1}{m}\sum_{i}z^{(i)}\\\sigma^2=\frac{1}{m}\sum_i(z_i-\mu)^2\\z_{norm}^{(i)}=\frac{z_i-\mu}{\sqrt{\sigma^2+\epsilon}}</script><p>其中，m 是单个 mini-batch 所包含的样本个数，ϵ 是为了防止分母为零，通常取10^−8。</p><p>这样，我们使得所有的输入z(i)均值为 0，方差为 1。但我们不想让隐藏层单元总是含有均值 0 和方差 1，也许<strong>隐藏层单元有了不同的分布会更有意义</strong>。而且，各隐藏层的输入均值在靠近 0 的区域，即处于激活函数的线性区域，<strong>不利于训练非线性神经网络</strong>。因此，设置 γ 和 β ，可以让 z~(i)的均值和方差可以为任意值。</p><script type="math/tex; mode=display">\widetilde{z}^{(i)}=\gamma z_{norm}^{(i)}+\beta</script><p>其中，γ 和 β都是超参数，神经网络通过学习得到。</p><p><strong>应用于整个神经网络：</strong></p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://s2.ax1x.com/2019/08/22/m0djRs.png" alt="BN应用于神经网络" title>                </div>                <div class="image-caption">BN应用于神经网络</div>            </figure><p>因为标准化处理中包含减去均值的一步，因此 b 实际上没有起到作用，其数值效果交由 β 来实现。因此可以省略 b 或者暂时设置为 0。</p><h3 id="批标准化有效的原因（Why-does-Batch-Norm-work？）"><a href="#批标准化有效的原因（Why-does-Batch-Norm-work？）" class="headerlink" title="批标准化有效的原因（Why does Batch Norm work？）"></a>批标准化有效的原因（Why does Batch Norm work？）</h3><ol><li><p><strong>通过对隐藏层各神经元的输入做类似的标准化处理，提高神经网络训练速度；</strong></p></li><li><p><strong>可以使前面层的权重变化对后面层造成的影响减小，整体网络更加健壮；</strong></p><ul><li><p>如果实际应用样本和训练样本的数据分布不同（如橘猫图片和黑猫图片），称发生了“<strong>Covariate Shift</strong>”。这种情况下，一般要对模型进行重新训练。<strong>BN减小了 Covariate Shift 所带来的影响</strong>，让模型变得更加健壮。</p></li><li><p>即使输入的值改变了，由于 BN的作用，使得均值和方差保持不变，限制了在前层的参数更新对数值分布的影响程度，因此后层的学习变得更容易一些。BN减少了各层 W 和 b 之间的耦合性，让各层更加独立，实现自我训练学习的效果。</p></li></ul></li><li><p><strong>起到微弱的正则化效果。</strong></p><ul><li><p>在每个 mini-batch 而非整个数据集上计算均值和方差，只由这一小部分数据估计得出的均值和方差会有一些噪声，因此最终计算出的z~(i)也有一定噪声。类似于 dropout，这种噪声会使得神经元不会再特别依赖于任何一个输入特征。</p></li><li><p>BN只有微弱的正则化效果，可以和 dropout 一起使用以获得更强大的正则化效果。但<strong>不要将BN作为正则化的手段</strong>，而是当作加速学习的方式。</p></li></ul></li></ol><h3 id="测试时（单个样本）的批标准化"><a href="#测试时（单个样本）的批标准化" class="headerlink" title="测试时（单个样本）的批标准化"></a>测试时（单个样本）的批标准化</h3><p>对于第 l 层隐藏层，考虑所有 mini-batch 在该隐藏层下的μ[l]和σ2[l]，然后用<strong>指数加权平均</strong>的方式来预测得到当前单个样本的μ[l]和σ2[l]。</p><h2 id="多分类问题（Multi-class-classification）"><a href="#多分类问题（Multi-class-classification）" class="headerlink" title="多分类问题（Multi-class classification）"></a>多分类问题（Multi-class classification）</h2><p>对于多分类问题，用C表示种类个数，神经网络中输出层就有C个神经元，即<em>n</em>[<em>L</em>]=<em>C</em>。其中，每个神经元的输出依次对应属于该类的概率，即<em>P</em>(<em>y</em>=<em>c</em>∣<em>x</em>)。为了处理多分类问题，一般使用<strong>Softmax回归模型</strong>。</p><h3 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h3><script type="math/tex; mode=display">\begin{align}& 对于输出层:\\& z^{[L]}=W^{[L]}a^{[L-1]}+b^{[L]}\\&a_i^{[L]}=\frac{e^{z_i^{[L]}}}{\sum_{i=1}^{C}e^{z_i^{[L]}}}~~~~(有\sum_{i=1}^{C}a_i^{[L]}=1)\\&\hat{y}=a^{[L]}~~~其维度为(C,1)\end{align}</script><p>例：</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://s2.ax1x.com/2019/08/22/m0dbdS.png" alt="计算实例" title>                </div>                <div class="image-caption">计算实例</div>            </figure><h3 id="损失函数和代价函数"><a href="#损失函数和代价函数" class="headerlink" title="损失函数和代价函数"></a>损失函数和代价函数</h3><p>定义损失函数为：</p><script type="math/tex; mode=display">\begin{align}&L(\hat{y},y)=-\sum_{j=1}^{C}y_jlog\hat{y}_j\\&当i为样本真实类别时，对于j\neq i,y_j=0\\&L(\hat{y},y)=-y_ilog\hat{y}_i=-log\hat{y}_i\\\end{align}</script><p>m个训练样本的代价函数为：</p><script type="math/tex; mode=display">J=\frac{1}{m}\sum_{i=1}^{m}L(\hat{y},y)</script><h3 id="梯度下降"><a href="#梯度下降" class="headerlink" title="梯度下降"></a>梯度下降</h3><script type="math/tex; mode=display">dZ^{[L]}=A^{[L]}-Y</script><p>反向传播过程的其他步骤与逻辑回归一致。</p><h2 id="深度学习框架"><a href="#深度学习框架" class="headerlink" title="深度学习框架"></a>深度学习框架</h2><h3 id="深度学习框架的选取原则"><a href="#深度学习框架的选取原则" class="headerlink" title="深度学习框架的选取原则"></a>深度学习框架的选取原则</h3><ul><li>易于编程：包括开发和迭代、部署产品；</li><li>运行速度：特别是训练大型数据集时；</li><li>是否真正开源：不仅需要开源，而且需要良好的管理，能够持续开放所有功能。</li></ul><h3 id="TensorFlow基础"><a href="#TensorFlow基础" class="headerlink" title="TensorFlow基础"></a>TensorFlow基础</h3><p>一个简单的程序框架：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> numpy <span class="keyword">as</span> np</span><br><span class="line"><span class="keyword">import</span> tensorflow <span class="keyword">as</span> tf</span><br><span class="line"></span><br><span class="line">cofficients = np.array([[<span class="number">1.</span>],[<span class="number">-10.</span>],[<span class="number">25.</span>]])</span><br><span class="line"></span><br><span class="line">w = tf.Variable(<span class="number">0</span>,dtype=tf.float32)</span><br><span class="line">x = tf.placeholder(tf.float32,[<span class="number">3</span>,<span class="number">1</span>])</span><br><span class="line"><span class="comment"># Tensorflow 重载了加减乘除符号</span></span><br><span class="line">cost = x[<span class="number">0</span>][<span class="number">0</span>]*w**<span class="number">2</span> + x[<span class="number">1</span>][<span class="number">0</span>]*w + x[<span class="number">2</span>][<span class="number">0</span>]</span><br><span class="line"><span class="comment"># 改变下面这行代码，可以换用更好的优化算法</span></span><br><span class="line">train = tf.train.GradientDescentOptimizer(<span class="number">0.01</span>).minimize(cost)</span><br><span class="line"></span><br><span class="line">init = tf.global_variables_initializer()</span><br><span class="line">session = tf.Session()</span><br><span class="line">session.run(init)</span><br><span class="line"><span class="comment">#上面一段代码可以替换为以下：</span></span><br><span class="line"><span class="comment">#with tf.Session() as session:</span></span><br><span class="line"><span class="comment">#    session.run(init)</span></span><br><span class="line"><span class="comment">#    print(session.run(w))</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> i <span class="keyword">in</span> range(<span class="number">1000</span>):</span><br><span class="line">    session.run(train, feed_dict=(x:coefficients))</span><br><span class="line">print(session.run(w))</span><br></pre></td></tr></table></figure><p>运行结果为4.99999，更改 cofficients 的值可以得到不同的结果 w。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;超参数调试&quot;&gt;&lt;a href=&quot;#超参数调试&quot; class=&quot;headerlink&quot; title=&quot;超参数调试&quot;&gt;&lt;/a&gt;超参数调试&lt;/h2&gt;&lt;h3 id=&quot;不同超参数的重要性排序&quot;&gt;&lt;a href=&quot;#不同超参数的重要性排序&quot; class=&quot;headerlink&quot; title=&quot;不同超参数的重要性排序&quot;&gt;&lt;/a&gt;不同超参数的重要性排序&lt;/h3&gt;&lt;p&gt;&lt;strong&gt;第一梯队：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;学习率α：最重要&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;第二梯队：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;动量衰减参数β：一般设置为0.9&lt;/li&gt;
&lt;li&gt;各隐藏层神经元个数#hidden units&lt;/li&gt;
&lt;li&gt;小批量大小mini-batch size&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;第三梯队：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;神经网络层数#layers&lt;/li&gt;
&lt;li&gt;学习率衰减率decay_rate&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;第四梯队：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;p&gt;Adam优化算法超参数β1、β2、ε：一般设置为0.9、0.99、10^-8&lt;/p&gt;
    
    </summary>
    
    
      <category term="学习笔记" scheme="http://yoursite.com/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
      <category term="deeplearning.ai" scheme="http://yoursite.com/tags/deeplearning-ai/"/>
    
  </entry>
  
  <entry>
    <title>deeplearning.ai学习笔记（六）优化深度神经网络之优化算法（Optimization algorithms）</title>
    <link href="http://yoursite.com/2019/08/18/deeplearning-ai%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E5%85%AD%EF%BC%89%E4%BC%98%E5%8C%96%E6%B7%B1%E5%BA%A6%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B9%8B%E4%BC%98%E5%8C%96%E7%AE%97%E6%B3%95%EF%BC%88Optimization-algorithms%EF%BC%89/"/>
    <id>http://yoursite.com/2019/08/18/deeplearning-ai学习笔记（六）优化深度神经网络之优化算法（Optimization-algorithms）/</id>
    <published>2019-08-18T08:47:56.000Z</published>
    <updated>2019-08-21T09:51:40.138Z</updated>
    
    <content type="html"><![CDATA[<p>本节课学习深度神经网络中的一些优化算法，通过使用这些技巧和方法来<strong>提高神经网络的训练速度和精度</strong>。</p><h2 id="小批量梯度下降算法（mini-batch-gradient-descent）"><a href="#小批量梯度下降算法（mini-batch-gradient-descent）" class="headerlink" title="小批量梯度下降算法（mini-batch gradient descent）"></a>小批量梯度下降算法（<strong>mini-batch</strong> gradient descent）</h2><h3 id="算法思想"><a href="#算法思想" class="headerlink" title="算法思想"></a>算法思想</h3><p>如果样本数量m很大，如达到百万数量级，由于受到矩阵运算速度的限制，训练速度往往会很慢。因此，<strong>把m个训练样本分成若干个子集（mini-batches），然后每次在单一子集上进行神经网络训练</strong>。</p><a id="more"></a><p>例：假设总的训练样本个数m=5000000，其维度为(n_x,m)。将其分成5000个子集，每个mini-batch含有1000个样本。我们将每个mini-batch记为X^{t}，其维度为(n_x,1000)。相应的每个mini-batch的输出记为Y^{t}，其维度为(1,1000)，且t=1,2,⋯,5000。</p><h3 id="算法过程"><a href="#算法过程" class="headerlink" title="算法过程"></a>算法过程</h3><p>先将总的训练样本分成T个子集（mini-batches），然后对每个mini-batch进行神经网络训练，包括Forward Propagation，Compute Cost Function，Backward Propagation，循环至T个mini-batch都训练完毕。</p><script type="math/tex; mode=display">\begin{align}& for~~t=1,\cdots,T\\&~~~~Forward~Propagation\\&~~~~Compute~Cost~Function\\&~~~~Backward~Propagation\\&~~~~W^{\{ t \}}:=W^{\{ t \}} - \alpha \centerdot dW^{\{ t \}}\\&~~~~b^{\{ t \}}:=b^{\{ t \}} - \alpha \centerdot db^{\{ t \}}\\\end{align}</script><p>经过T次循环之后，所有m个训练样本都进行了梯度下降计算。这个过程称为一个epoch，一个epoch会进行T次梯度下降算法。</p><p>注：对于Mini-Batches Gradient Descent，可以进行多次epoch训练；每次epoch最好将总体训练数据重新打乱、重新分成T组mini-batches。</p><p><strong>cost曲线：</strong></p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://s2.ax1x.com/2019/08/19/m8lcVJ.png" alt="cost曲线比较" title>                </div>                <div class="image-caption">cost曲线比较</div>            </figure><p>出现细微振荡的原因是不同的mini-batch之间是有差异的，但整体的趋势是下降的，最终也能得到较低的cost值。</p><h3 id="超参数-mini-batch-size-选取"><a href="#超参数-mini-batch-size-选取" class="headerlink" title="超参数 mini-batch size 选取"></a>超参数 <code>mini-batch size</code> 选取</h3><p><strong>考虑两种极端情况：</strong></p><ul><li>如果<strong>mini-batch size=m</strong>，即为Batch gradient descent，只包含一个子集为(X^{1},Y^{1})=(X,Y)。会比较平稳地接近全局最小值，但是因为使用了所有m个样本，每次前进的速度有些慢。</li><li>如果<strong>mini-batch size=1</strong>，即为随机梯度下降（Stachastic gradient descent），每个样本就是一个子集(X^{i},Y^{i})=(x^(i),y^(i))，共有m个子集。每次前进速度很快，但是路线曲折，有较大的振荡，最终会在最小值附近来回波动，难以真正达到最小值处。而且在数值处理上就不能使用向量化的方法来提高运算速度。</li></ul><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://s2.ax1x.com/2019/08/19/m8lf8x.png" alt="两种极端情况下梯度下降图示" title>                </div>                <div class="image-caption">两种极端情况下梯度下降图示</div>            </figure><p><strong>正确选取原则：</strong></p><ul><li>一般来说，如果总体样本数量m不太大时（如<em>m</em>≤2000），建议直接使用Batch gradient descent。</li><li>如果总体样本数量m很大时，建议将样本分成许多mini-batches。mini-batch size不能设置得太大，也不能太小。推荐选取2的幂做为mini-batch size的值（计算机存储数据一般是2的幂，这样设置可以提高运算速度），<strong>常用的有64、128、256、512</strong>。</li></ul><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://s2.ax1x.com/2019/08/19/m8l4xK.png" alt="适中mini-batch size时的梯度下降" title>                </div>                <div class="image-caption">适中mini-batch size时的梯度下降</div>            </figure><h2 id="动量梯度下降算法（Gradient-descent-with-momentum）"><a href="#动量梯度下降算法（Gradient-descent-with-momentum）" class="headerlink" title="动量梯度下降算法（Gradient descent with momentum）"></a>动量梯度下降算法（Gradient descent with momentum）</h2><h3 id="数学基础：指数加权平均（exponentially-weighted-averages）"><a href="#数学基础：指数加权平均（exponentially-weighted-averages）" class="headerlink" title="数学基础：指数加权平均（exponentially weighted averages）"></a>数学基础：指数加权平均（exponentially weighted averages）</h3><h4 id="实例：伦敦市半年内气温整体变化趋势"><a href="#实例：伦敦市半年内气温整体变化趋势" class="headerlink" title="实例：伦敦市半年内气温整体变化趋势"></a>实例：伦敦市半年内气温整体变化趋势</h4><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://s2.ax1x.com/2019/08/19/m8lIKO.png" alt="伦敦市半年内气温散点图" title>                </div>                <div class="image-caption">伦敦市半年内气温散点图</div>            </figure><p>通过移动平均（moving average）的方法来对每天气温进行平滑处理：</p><p>设<em>V</em>0=0，做为第0天的气温值。第一天至第t天气温可按如下计算：</p><script type="math/tex; mode=display">\begin{align}&V_1=0.9V_0+0.1 \theta_1 \\&V_2=0.9V_1+0.1 \theta_2 = 0.9(0.9V_0+0.1 \theta_1)+0.1 \theta_2 = 0.9^2V_0+0.9 \centerdot 0.1\theta_1+0.1\theta_2\\&V_3=0.9V_2+0.1 \theta_3=0.9(0.9^2V_0+0.9 \centerdot 0.1\theta_1+0.1\theta_2)+0.1 \theta_3 \\&~~~~= 0.9^3V_0+0.9^2 \centerdot 0.1\theta_1+0.9 \centerdot 0.1\theta_2+0.1\theta_3 \\&~~~~~~~~~~~~~\vdots \\&V_t=0.9V_{t-1}+0.1 \theta_t=0.9^tV_0+0.9^{t-1}\centerdot 0.1\theta_1 + 0.9^{t-2}\centerdot 0.1\theta_2 + \cdots + 0.9\centerdot 0.1\theta_{t-1} + 0.1\theta_t\end{align}</script><p>这种滑动平均算法称为指数加权平均。</p><h4 id="指数加权平均的一般形式"><a href="#指数加权平均的一般形式" class="headerlink" title="指数加权平均的一般形式"></a>指数加权平均的一般形式</h4><script type="math/tex; mode=display">V_t=\beta V_{t-1} +(1-\beta)\theta_t</script><p><em>β</em>值决定了指数加权平均的天数。</p><script type="math/tex; mode=display">\begin{align}& 当\beta\rightarrow0,N=\frac{1}{1-\beta}\rightarrow \infty时:\\&~~~~~~ \beta^{\frac{1}{1-\beta}}=(1-\frac{1}{N})^N=\frac{1}{e}\end{align}</script><p>一般认为衰减到1/e就可以忽略不计了，故指数加权平均的天数的计算公式为：</p><script type="math/tex; mode=display">N=\frac{1}{1-\beta}</script><p><em>β</em>值越大，则指数加权平均的天数越多，平均后的趋势线就越平缓，同时向右平移。下图绿色曲线和黄色曲线分别表示了<em>β</em>=0.98和<em>β</em>=0.5时，指数加权平均的结果。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://s2.ax1x.com/2019/08/19/m8lh26.png" alt="不同β值指数加权平均的结果" title>                </div>                <div class="image-caption">不同β值指数加权平均的结果</div>            </figure><h4 id="偏差修正（bias-correction）"><a href="#偏差修正（bias-correction）" class="headerlink" title="偏差修正（bias correction）"></a>偏差修正（bias correction）</h4><p>当<em>β</em>=0.98时，指数加权平均结果如绿色曲线所示。但是实际上，真实曲线如紫色曲线所示。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://s2.ax1x.com/2019/08/19/m8lTqe.png" alt="真实情况下的指数加权平均结果" title>                </div>                <div class="image-caption">真实情况下的指数加权平均结果</div>            </figure><p>由于开始时设置<em>V</em>0=0，所以初始值会相对小一些，直到后面受前面的影响渐渐变小，趋于正常。</p><p><strong>偏差修正：</strong></p><script type="math/tex; mode=display">V_t:=\frac{V_t}{1-\beta^t}</script><ul><li>刚开始t比较小，(1−<em>β</em>^t)&lt;1，这样就将<em>V</em>t修正得更大一些；</li><li>随着t增大，(1−<em>β</em>^t)≈1，<em>V</em>t基本不变。</li></ul><h3 id="动量梯度下降算法思想"><a href="#动量梯度下降算法思想" class="headerlink" title="动量梯度下降算法思想"></a>动量梯度下降算法思想</h3><p>在每次训练时，<strong>对梯度进行指数加权平均</strong>，然后用得到的梯度值更新权重W和常数项b。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://s2.ax1x.com/2019/08/19/m8lorD.png" alt="动量梯度下降算法" title>                </div>                <div class="image-caption">动量梯度下降算法</div>            </figure><ul><li>原始的梯度下降算法如上图蓝色折线所示。在梯度下降过程中，对于W、b之间数值范围差别较大的情况，梯度下降的振荡较大。此时每一点处的梯度只与当前方向有关，产生类似折线的效果，前进缓慢。</li><li>如果对梯度进行指数加权平均，这样使当前梯度不仅与当前方向有关，还与之前的方向有关，这样处理让梯度前进方向更加平滑，减少振荡，能够更快地到达最小值处。</li></ul><h3 id="动量梯度下降算法过程"><a href="#动量梯度下降算法过程" class="headerlink" title="动量梯度下降算法过程"></a>动量梯度下降算法过程</h3><script type="math/tex; mode=display">\begin{align}& 初始化:V_{dW}=0,V_{db}=0,\beta=0.9 \\& On~iteration~t:\\&~~~~~Compute~dW,db~on~the~current~mini-binch\\&~~~~~V_{dW}=\beta V_{dW}+(1-\beta)dW\\&~~~~~V_{db}=\beta V_{db}+(1-\beta)db\\&~~~~~W:=W-\alpha V_{dW}\\&~~~~~b:=b-\alpha V_{db}\\\end{align}</script><h2 id="均方根传递优化算法（RMSprop-Root-Mean-Square-prop）"><a href="#均方根传递优化算法（RMSprop-Root-Mean-Square-prop）" class="headerlink" title="均方根传递优化算法（RMSprop, Root Mean Square prop）"></a>均方根传递优化算法（<strong>RMSprop</strong>, Root Mean Square prop）</h2><h3 id="算法过程-1"><a href="#算法过程-1" class="headerlink" title="算法过程"></a>算法过程</h3><p>按如下方式更新参数：</p><script type="math/tex; mode=display">\begin{align}&S_W=\beta S_{dW}+(1-\beta)dW^2\\&S_b=\beta S_{db}+(1-\beta)db^2\\&W:=W-\alpha \frac{dW}{\sqrt{S_w}},b:=b-\alpha \frac{db}{\sqrt{S_b}}\\\end{align}</script><p>为了避免RMSprop算法中分母为零，通常可以在分母增加一个极小的常数<em>ε</em>：</p><script type="math/tex; mode=display">W:=W-\alpha \frac{dW}{\sqrt{S_w}+\epsilon},b:=b-\alpha \frac{db}{\sqrt{S_b}+\epsilon}</script><p>其中，<em>ε</em>一般取10^−8。</p><h3 id="算法原理"><a href="#算法原理" class="headerlink" title="算法原理"></a>算法原理</h3><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://s2.ax1x.com/2019/08/19/m8lHVH.png" alt="RMSprop算法原理" title>                </div>                <div class="image-caption">RMSprop算法原理</div>            </figure><p>从图中可以看出，梯度下降（蓝色折线）在垂直方向（b）上振荡较大，在水平方向（W）上振荡较小，表示在b方向上梯度较大，即<em>db</em>较大，而在W方向上梯度较小，即<em>dW</em>较小。因此，上述表达式中<em>Sb</em>较大，而<em>SW</em>较小。在更新W和b的表达式中，使得W变化得多一些，b变化得少一些。即加快了W方向的速度，减小了b方向的速度，减小振荡，实现快速梯度下降算法，其梯度下降过程如绿色折线所示。</p><h2 id="自适应矩估计优化算法-Adam-Adaptive-Moment-Estimation"><a href="#自适应矩估计优化算法-Adam-Adaptive-Moment-Estimation" class="headerlink" title="自适应矩估计优化算法(Adam, Adaptive Moment Estimation)"></a>自适应矩估计优化算法(<strong>Adam</strong>, Adaptive Moment Estimation)</h2><p><code>Adam优化算法</code>本质上是<strong>将动量算法和RMSprop结合</strong>起来。</p><h3 id="算法过程-2"><a href="#算法过程-2" class="headerlink" title="算法过程"></a>算法过程</h3><script type="math/tex; mode=display">\begin{align}& 初始化:V_{dW}=0,S_{dW}=0,V_{db}=0,S_{db}=0\\& On~iteration~t:\\&~~~~~Compute~dW,db~on~the~current~mini-binch\\&~~~~~V_{dW}=\beta_1 V_{dW}+(1-\beta_1)dW,V_{db}=\beta_1 V_{db}+(1-\beta_1)db\\&~~~~~S_{dW}=\beta_2 S_{dW}+(1-\beta_2)dW^2,S_{db}=\beta_2 S_{db}+(1-\beta_2)db^2\\&~~~~~V_{dW}^{corrected}=\frac{V_{dW}}{1-\beta_1^t},V_{db}^{corrected}=\frac{V_{db}}{1-\beta_1^t}\\&~~~~~S_{dW}^{corrected}=\frac{S_{dW}}{1-\beta_2^t},S_{db}^{corrected}=\frac{S_{db}}{1-\beta_2^t}\\&~~~~~W:=W-\alpha \frac{V_{dW}^{corrected}}{\sqrt{S_{dW}^{corrected}}+\epsilon},b:=b-\alpha \frac{V_{db}^{corrected}}{\sqrt{S_{db}^{corrected}}+\epsilon}\\\end{align}</script><h3 id="超参数选取"><a href="#超参数选取" class="headerlink" title="超参数选取"></a>超参数选取</h3><p><em>β</em>1通常设置为0.9，<em>β</em>2通常设置为0.999，<em>ε</em>通常设置为10^-8。(一般不会调整)</p><h2 id="学习率衰减（Learning-rate-decay）"><a href="#学习率衰减（Learning-rate-decay）" class="headerlink" title="学习率衰减（Learning rate decay）"></a>学习率衰减（Learning rate decay）</h2><h3 id="算法思想-1"><a href="#算法思想-1" class="headerlink" title="算法思想"></a>算法思想</h3><p><strong>随着迭代次数增加，学习因子<em>α</em>逐渐减小。</strong></p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://s2.ax1x.com/2019/08/19/m8lbad.png" alt="学习率衰减时的梯度下降" title>                </div>                <div class="image-caption">学习率衰减时的梯度下降</div>            </figure><ul><li>蓝色折线表示使用恒定的学习因子<em>α</em>，由于每次训练<em>α</em>相同，步进长度不变，在接近最优值处的振荡也大，在最优值附近较大范围内振荡，与最优值距离就比较远。</li><li>绿色折线表示使用衰减的<em>α</em>，随着训练次数增加，<em>α</em>逐渐减小，步进长度减小，使得能够在最优值处较小范围内微弱振荡，不断逼近最优值。</li></ul><h3 id="学习率衰减的方式"><a href="#学习率衰减的方式" class="headerlink" title="学习率衰减的方式"></a>学习率衰减的方式</h3><script type="math/tex; mode=display">\begin{align}& 1.~\alpha = \frac{1}{1+decay\_rate*epoch\_num}\alpha_0\\& （其中衰减率deacy\_rate为可调超参数、epoch\_num为迭代次数）\\&2.~\alpha = 0.95^{epoch\_num}\centerdot \alpha_0\\&3.~\alpha = \frac{k}{\sqrt{epoch\_num}} \centerdot \alpha_0~~or~~\frac{k}{\sqrt{mini-bach\_number}} \centerdot \alpha_0\\&（其中k为可调超参数）\\&4.~设置\alpha为关于t的离散值，随着t增加，\alpha呈阶梯式减小。\end{align}</script><h2 id="局部最优-Local-Optima-问题-amp-停滞区-Plateaus-问题"><a href="#局部最优-Local-Optima-问题-amp-停滞区-Plateaus-问题" class="headerlink" title="局部最优(Local Optima)问题 &amp; 停滞区(Plateaus)问题"></a>局部最优(Local Optima)问题 &amp; 停滞区(Plateaus)问题</h2><p>在使用梯度下降算法不断减小cost function时，可能会得到<strong>局部最优解（local optima）</strong>而不是<strong>全局最优解（global optima）</strong>。</p><p>在神经网络中，局部最优不能理解为如左图形碗状的凹槽，因为大部分梯度为零的点并不是这些凹槽处，而是形如右边所示的马鞍状，称为鞍点（saddle point）。特别是在神经网络中参数很多的情况下，所有参数梯度为零的点很可能是鞍点。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://s2.ax1x.com/2019/08/19/m8lOPI.png" alt="局部最优点 VS 鞍点" title>                </div>                <div class="image-caption">局部最优点 VS 鞍点</div>            </figure><p>类似马鞍状的停滞区（plateaus）会降低神经网络学习速度。停滞区是梯度接近于零的平缓区域，在停滞区上梯度很小，前进缓慢，到达鞍点需要很长时间。到达鞍点后，由于随机扰动，梯度一般能够沿着图中绿色箭头，离开鞍点，继续前进，只是在停滞区上花费了太多时间。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://s2.ax1x.com/2019/08/19/m8lqIA.png" alt="停滞区的梯度下降" title>                </div>                <div class="image-caption">停滞区的梯度下降</div>            </figure><p><strong>总结：</strong></p><ul><li>只要选择合理强大的神经网络，一般不太可能陷入局部最优处；</li><li>停滞区可能会使梯度下降变慢，降低学习速度。动量梯度下降、RMSprop、Adam算法都能有效解决停滞区下降过慢的问题。</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;本节课学习深度神经网络中的一些优化算法，通过使用这些技巧和方法来&lt;strong&gt;提高神经网络的训练速度和精度&lt;/strong&gt;。&lt;/p&gt;
&lt;h2 id=&quot;小批量梯度下降算法（mini-batch-gradient-descent）&quot;&gt;&lt;a href=&quot;#小批量梯度下降算法（mini-batch-gradient-descent）&quot; class=&quot;headerlink&quot; title=&quot;小批量梯度下降算法（mini-batch gradient descent）&quot;&gt;&lt;/a&gt;小批量梯度下降算法（&lt;strong&gt;mini-batch&lt;/strong&gt; gradient descent）&lt;/h2&gt;&lt;h3 id=&quot;算法思想&quot;&gt;&lt;a href=&quot;#算法思想&quot; class=&quot;headerlink&quot; title=&quot;算法思想&quot;&gt;&lt;/a&gt;算法思想&lt;/h3&gt;&lt;p&gt;如果样本数量m很大，如达到百万数量级，由于受到矩阵运算速度的限制，训练速度往往会很慢。因此，&lt;strong&gt;把m个训练样本分成若干个子集（mini-batches），然后每次在单一子集上进行神经网络训练&lt;/strong&gt;。&lt;/p&gt;
    
    </summary>
    
    
      <category term="学习笔记" scheme="http://yoursite.com/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
      <category term="deeplearning.ai" scheme="http://yoursite.com/tags/deeplearning-ai/"/>
    
  </entry>
  
  <entry>
    <title>deeplearning.ai学习笔记（五）优化深度神经网络之应用层面的深度学习</title>
    <link href="http://yoursite.com/2019/08/16/deeplearning-ai%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%94%EF%BC%89%E4%BC%98%E5%8C%96%E6%B7%B1%E5%BA%A6%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E4%B9%8B%E5%BA%94%E7%94%A8%E5%B1%82%E9%9D%A2%E7%9A%84%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0/"/>
    <id>http://yoursite.com/2019/08/16/deeplearning-ai学习笔记（五）优化深度神经网络之应用层面的深度学习/</id>
    <published>2019-08-16T12:03:14.000Z</published>
    <updated>2019-08-21T09:47:02.045Z</updated>
    
    <content type="html"><![CDATA[<h2 id="数据集：训练集-开发集-测试集（Train-Dev-Test-sets）"><a href="#数据集：训练集-开发集-测试集（Train-Dev-Test-sets）" class="headerlink" title="数据集：训练集/开发集/测试集（Train/Dev/Test sets）"></a>数据集：训练集/开发集/测试集（Train/Dev/Test sets）</h2><p><strong>为实现<code>交叉验证</code>（cross validation），数据集一般会划分为三个部分：</strong></p><ul><li>训练集（Train sets）：用于训练算法模型；</li><li>开发集（Dev sets）：用于验证不同算法模型的表现情况，从中选择最好的算法模型；</li><li>测试集（Test sets）：用于测试最好算法的实际表现（算法的无偏估计）。</li></ul><a id="more"></a><p>注：Test sets的目标主要是进行无偏估计。如果不需要无偏估计，也可以没有Test sets，可以通过Train sets训练不同的算法模型，然后分别在Dev sets上进行验证，根据结果选择最好的算法模型。（如果只有Train sets和Dev sets，通常把这里的Dev sets称为Test sets）</p><p><strong>比例分配：</strong></p><ul><li>样本数量不是很大（如100、1000、10000）：Train sets和Test sets的数量比例为70%/30%；如果有Dev sets，则设置比例为60%/20%/20%。</li><li>样本数量很大（如100万）：Dev sets和Test sets大到足以完成其目标即可，对于100万的样本，往往也只需要10000个样本就够了。因此，对于大数据样本，Train/Dev/Test sets的比例可设置为98%/1%/1%或99%/0.5%/0.5%。样本数据量越大，相应的Dev/Test sets的比例可以设置的越低一些。</li></ul><p><strong>训练样本和测试样本分布不匹配问题：</strong></p><p>训练样本和验证/测试样本可能来自不同的分布。一条经验原则是<strong>尽量保证Dev sets和Test sets来自于同一分布</strong>。</p><h2 id="偏差（Bias）与方差（Variance）"><a href="#偏差（Bias）与方差（Variance）" class="headerlink" title="偏差（Bias）与方差（Variance）"></a>偏差（Bias）与方差（Variance）</h2><h3 id="偏差、方差与算法的优劣"><a href="#偏差、方差与算法的优劣" class="headerlink" title="偏差、方差与算法的优劣"></a>偏差、方差与算法的优劣</h3><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://s2.ax1x.com/2019/08/19/m8lga9.png" alt="偏差方差的各种情况" title>                </div>                <div class="image-caption">偏差方差的各种情况</div>            </figure><ol><li>高偏差（欠拟合，underfitting）：算法模型在训练样本和测试样本上的表现相差不大，但都不太好。（如：Train set error为15%，而Dev set error为16%）</li><li>高方差（过拟合，overfitting）：算法模型在训练样本上的表现很好，但是在测试样本上的表现却不太好。这说明了该<strong>模型泛化能力不强</strong>。（如：Train set error为1%，而Dev set error为11%）</li><li>低偏差&amp;低方差：最好情况的算法。</li><li>高偏差&amp;高方差：可以理解成某段区域是欠拟合的，某段区域是过拟合的，是最差情况的算法。</li></ol><p>总结：一般来说，<strong>Train set error体现了是否出现high bias</strong>；<strong>Dev set error与Train set error的相对差值体现了是否出现high variance</strong>。</p><h3 id="机器学习中算法评价的基本原则"><a href="#机器学习中算法评价的基本原则" class="headerlink" title="机器学习中算法评价的基本原则"></a>机器学习中算法评价的基本原则</h3><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://s2.ax1x.com/2019/08/19/m8l02V.png" alt="算法评价流程" title>                </div>                <div class="image-caption">算法评价流程</div>            </figure><h3 id="高偏差和高方差的解决策略"><a href="#高偏差和高方差的解决策略" class="headerlink" title="高偏差和高方差的解决策略"></a>高偏差和高方差的解决策略</h3><p><strong>对于高偏差：</strong></p><ul><li>增加神经网络的隐藏层个数、神经元个数</li><li>延长训练时间</li><li>选择其它更复杂的神经网络模型</li><li>……</li></ul><p><strong>对于高方差：</strong></p><ul><li>增加训练样本数据</li><li><strong>进行正则化</strong>（Regularization）</li><li>选择其他更复杂的神经网络模型</li><li>……</li></ul><h2 id="正则化（Regularization）"><a href="#正则化（Regularization）" class="headerlink" title="正则化（Regularization）"></a>正则化（Regularization）</h2><h3 id="L2正则化"><a href="#L2正则化" class="headerlink" title="L2正则化"></a>L2正则化</h3><h4 id="具体实现"><a href="#具体实现" class="headerlink" title="具体实现"></a>具体实现</h4><p><strong>对于Logistic regression：</strong></p><script type="math/tex; mode=display">J(w,b)=\frac{1}{m} \sum_{i=1}^{m}L(\hat{y}^{(i)},y^{(i)})+\frac{\lambda}{2m}||w||_2^{2} \\||w||_2^{2}=\sum_{j=1}^{n_x}w_j^{2}=w^{T}w</script><p>注：</p><ul><li>由于<em>W</em>的维度很大，而<em>b</em>只是一个常数，参数很大程度上由<em>W</em>决定，改变<em>b</em>值对整体模型影响较小，所以没有对<em>b</em>进行正则化。</li><li><em>λ</em>——<strong>正则化参数</strong>，属于超参数的一种。可以设置<em>λ</em>为不同的值，在Dev set中进行验证，选择最佳的<em>λ</em>。</li></ul><p><strong>对于深度神经网络：</strong></p><script type="math/tex; mode=display">J(w^{[1]},b^{[1]},\cdots,w^{[L]},b^{[L]})=\frac{1}{m} \sum_{i=1}^{m}L(\hat{y}^{(i)},y^{(i)})+\frac{\lambda}{2m}||w^{[l]}||^{2} \\||w||_F^{2}=\sum_{i=1}^{n^{[l]}} \sum_{j=1}^{n^{[l-1]}}(w_{ij}^{[l]})^{2} ~~~~~~~~(Frobenius范数)\\dw^{[l]}=dw_{before}^{[l]}+\frac{\lambda}{m}w^{[l]}\\w^{[l]}:=w^{[l]}-\alpha \centerdot dw^{[l]}</script><p>由于加上了正则项，<em>dw</em>[<em>l</em>]有个增量，在更新<em>w</em>[<em>l</em>]的时候，会多减去这个增量，使得<em>w</em>[<em>l</em>]比没有正则项的值要小一些。因此，L2 regularization也被称做<strong>权重衰减</strong>（weight decay）。</p><script type="math/tex; mode=display">w^{[l]}:=w^{[l]}-\alpha \centerdot dw^{[l]}=w^{[l]}-\alpha \centerdot (dw_{before}^{[l]}+\frac{\lambda}{m}w^{[l]})=(1-\alpha \frac{\lambda}{m})w^{[l]}-\alpha \centerdot dw_{before}^{[l]}</script><h4 id="直观解释（Why-regularization-reduces-overfitting-）"><a href="#直观解释（Why-regularization-reduces-overfitting-）" class="headerlink" title="直观解释（Why regularization reduces overfitting?）"></a>直观解释（Why regularization reduces overfitting?）</h4><p>假如选择了非常复杂的神经网络模型，在未使用正则化的情况下出现了过拟合。但是，如果使用L2 regularization，当<em>λ</em>很大时，<em>w</em>[<em>l</em>]近似为零，意味着该神经网络模型中的某些神经元实际的作用很小，<strong>原本过于复杂的神经网络模型就被简单化了</strong>。因此，正则化方法可以减轻过拟合程度。</p><h3 id="L1正则化"><a href="#L1正则化" class="headerlink" title="L1正则化"></a>L1正则化</h3><script type="math/tex; mode=display">J(w,b)=\frac{1}{m} \sum_{i=1}^{m}L(\hat{y}^{(i)},y^{(i)})+\frac{\lambda}{2m}||w||_1 \\||w||_1=\sum_{j=1}^{n_x}|w_j|</script><p>与L2 regularization相比，L1 regularization得到的w更加稀疏，即很多w为零值。其优点是节约存储空间，因为大部分w为0。然而，实际上L1 regularization在解决high variance方面比L2 regularization并不更具优势。而且，L1的在微分求导方面比较复杂。所以，一般<strong>L2 regularization更加常用</strong>。</p><h3 id="随机失活（Dropout）正则化"><a href="#随机失活（Dropout）正则化" class="headerlink" title="随机失活（Dropout）正则化"></a>随机失活（<strong>Dropout</strong>）正则化</h3><h4 id="方法思想"><a href="#方法思想" class="headerlink" title="方法思想"></a>方法思想</h4><p>随机失活（Dropout）是指在深度学习网络的训练过程中，<strong>对于每层的神经元，按照一定的概率将其暂时从网络中丢弃</strong>。也就是说，每次训练时，每一层都有部分神经元不工作，起到简化复杂网络模型的效果，从而避免发生过拟合。</p><p>注：使用dropout训练结束后，在测试和实际应用模型时，不需要进行dropout</p><h4 id="实现方法：反向随机失活（Inverted-dropout）"><a href="#实现方法：反向随机失活（Inverted-dropout）" class="headerlink" title="实现方法：反向随机失活（Inverted dropout）"></a>实现方法：反向随机失活（Inverted dropout）</h4><p>假设对于第<em>l</em>层神经元，设定<strong>神经元保留概率keep_prob</strong>=0.8，即该层有20%的神经元停止工作。<em>dl</em>为随机失活向量，其中80%的元素为1，20%的元素为0。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">dl = np.random.rand(al.shape[<span class="number">0</span>],al.shape[<span class="number">1</span>])&lt;keep_prob  //生成随机失活向量</span><br><span class="line">al = np.multiply(al,dl) //第l层经过dropout的输出</span><br><span class="line">al /= keep_prob //进行缩放（scale up）以尽可能保持al的期望值相比之前没有大的变化，测试时就不需要再对样本数据进行类似的尺度伸缩操作</span><br></pre></td></tr></table></figure><p>对于m个样本，单次迭代训练时，随机失活隐藏层一定数量的神经元；然后，在删除后的剩下的神经元上正向和反向更新参数；接着，下一次迭代中，恢复之前失活的神经元，重新随机失活一定数量的神经元，进行正向和反向更新参数；不断重复上述过程，直至迭代训练完成。</p><h3 id="其他正则化方法"><a href="#其他正则化方法" class="headerlink" title="其他正则化方法"></a>其他正则化方法</h3><h4 id="数据增强（Data-Augmentation）"><a href="#数据增强（Data-Augmentation）" class="headerlink" title="数据增强（Data Augmentation）"></a>数据增强（Data Augmentation）</h4><p>增加训练样本数量通常成本较高，难以获得额外的训练样本。但可以对已有的训练样本进行一些处理来“制造”出更多的样本。虽然这些是基于原有样本的，但是对增大训练样本数量还是有很有帮助的，不需要增加额外成本，却能起到防止过拟合的效果。</p><p>例如：</p><ul><li>在图片识别问题中，可以对已有的图片进行水平翻转、垂直翻转、任意角度旋转、缩放或扩大等等。</li></ul><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://s2.ax1x.com/2019/08/19/m8l25R.png" alt="图片识别中的数据增强" title>                </div>                <div class="image-caption">图片识别中的数据增强</div>            </figure><ul><li>在数字识别问题中，可以将原有的数字图片进行任意旋转或者扭曲，增加一些noise。</li></ul><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://s2.ax1x.com/2019/08/19/m8lBvT.png" alt="数字识别中的数据增强" title>                </div>                <div class="image-caption">数字识别中的数据增强</div>            </figure><h4 id="提前终止（Early-Stopping）"><a href="#提前终止（Early-Stopping）" class="headerlink" title="提前终止（Early Stopping）"></a>提前终止（Early Stopping）</h4><p>个神经网络模型随着迭代训练次数增加，train set error一般是单调减小的，而dev set error 先减小，之后又增大。也就是说训练次数过多时，模型会对训练样本拟合的越来越好，但是对验证集拟合效果逐渐变差，即发生了过拟合。因此，迭代训练次数不是越多越好，可以<strong>通过train set error和dev set error随迭代次数的变化趋势，选择合适的迭代次数</strong>，即early stopping。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://s2.ax1x.com/2019/08/19/m8lw80.png" alt="随迭代次数的变化趋势" title>                </div>                <div class="image-caption">随迭代次数的变化趋势</div>            </figure><p><strong>Early Stopping的缺点：</strong></p><p>机器学习训练模型有两个目标：一是优化cost function，尽量减小J；二是防止过拟合。通过减少迭代次数来防止过拟合，会使得cost function不会足够小。即将两个目标融合在一起，同时优化，但可能没有“分而治之”的效果好。</p><p><strong>Early Stopping vs L2 regularization：</strong></p><p>与Early Stopping相比，L2 regularization可以实现“分而治之”的效果，但正则化参数<em>λ</em>的选择比较复杂。对这一点来说，early stopping比较简单。<strong>总的来说，L2 regularization更加常用一些。</strong></p><h2 id="标准化输入（Normalizing-inputs）"><a href="#标准化输入（Normalizing-inputs）" class="headerlink" title="标准化输入（Normalizing inputs）"></a>标准化输入（Normalizing inputs）</h2><h3 id="概念"><a href="#概念" class="headerlink" title="概念"></a>概念</h3><p>标准化输入就是对训练数据集进行<strong>归一化</strong>的操作，即将原始数据<strong>减去其均值<em>μ</em>后，再除以其方差<em>σ</em>²</strong>。</p><script type="math/tex; mode=display">\mu = \frac{1}{m} \sum_{i=1}^{m} X^{(i)}\\\sigma^{2} = \frac{1}{m} \sum_{i=1}^{m}(X^{(i)})^2\\X :=  \frac{X-\mu}{\sigma^2}</script><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://s2.ax1x.com/2019/08/19/m8lsrF.png" alt="归一化过程" title>                </div>                <div class="image-caption">归一化过程</div>            </figure><p>注：由于训练集进行了标准化处理，那么对于测试集或在实际应用时，应该使用同样的\mu<em>μ</em>和<em>σ</em>²对其进行标准化处理。</p><h3 id="进行标准化的好处"><a href="#进行标准化的好处" class="headerlink" title="进行标准化的好处"></a>进行标准化的好处</h3><p>让所有输入归一到同样的尺度上，<strong>方便进行梯度下降算法时能够更快更准确地找到全局最优解</strong>。</p><ul><li>如果不进行标准化处理，x1与x2之间分布极不平衡，训练得到的w1和w2也会在数量级上差别很大。这样导致的结果是cost function与w和b的关系可能是一个非常细长的椭圆形碗。对其进行梯度下降算法时，由于w1和w2数值差异很大，只能选择很小的学习因子<em>α</em>，来避免J发生振荡。一旦<em>α</em>较大，必然发生振荡，J不再单调下降。</li><li>如果进行了标准化操作，x1与x2分布均匀，w1和w2数值差别不大，得到的cost function与w和b的关系是类似圆形碗。对其进行梯度下降算法时，<em>α</em>可以选择相对大一些，且J一般不会发生振荡，保证了J是单调下降的。</li></ul><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://s2.ax1x.com/2019/08/19/m8lWP1.png" alt="归一化的好处图示" title>                </div>                <div class="image-caption">归一化的好处图示</div>            </figure><h2 id="梯度消失和梯度爆炸（Vanishing-and-Exploding-gradients）"><a href="#梯度消失和梯度爆炸（Vanishing-and-Exploding-gradients）" class="headerlink" title="梯度消失和梯度爆炸（Vanishing and Exploding gradients）"></a>梯度消失和梯度爆炸（Vanishing and Exploding gradients）</h2><h3 id="概念-1"><a href="#概念-1" class="headerlink" title="概念"></a>概念</h3><p>在梯度函数上出现的以指数级递增或者递减的情况分别称为<strong>梯度爆炸</strong>或者<strong>梯度消失</strong>。</p><p>假定 g(z)=z,b[l]=0，对于目标输出有：</p><script type="math/tex; mode=display">\hat{y} = (W^{[L]}W^{[L-1]}\cdots W^{[2]}W^{[1]})X</script><ul><li>对于 W[l]的值大于 1 的情况，激活函数的值将以指数级递增（数值爆炸）；</li><li>对于 W[l]的值小于 1 的情况，激活函数的值将以指数级递减（数值消失）。</li></ul><p>同样，这种情况也会引起梯度呈现同样的指数型增大或减小的变化，引起每次更新的步进长度过大或者过小，这让训练过程十分困难。</p><h3 id="改善方法：对权展w进行初始化处理"><a href="#改善方法：对权展w进行初始化处理" class="headerlink" title="改善方法：对权展w进行初始化处理"></a>改善方法：对权展w进行初始化处理</h3><p>由下式</p><script type="math/tex; mode=display">z = w_1x_1+w_2x_2+\cdots + w_nx_n+b</script><p>可知，当输入的数量 n 较大时，我们希望每个wi的值都小一些，这样它们的和得到的 z 也较小。为了<strong>得到较小的wi</strong>，可进行如下初始化：</p><ul><li>若激活函数为sigmod/tanh函数，令其方差为1/n：</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">w[l] = np.random.randn(n[l],n[l<span class="number">-1</span>])*np.sqrt(<span class="number">1</span>/n[l<span class="number">-1</span>])</span><br></pre></td></tr></table></figure><ul><li>若激活函数为ReLU函数，令其方差为2/n：</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">w[l] = np.random.randn(n[l],n[l<span class="number">-1</span>])*np.sqrt(<span class="number">1</span>/n[l<span class="number">-1</span>])</span><br></pre></td></tr></table></figure><ul><li>另外还有：</li></ul><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">w[l] = np.random.randn(n[l],n[l<span class="number">-1</span>])*np.sqrt(<span class="number">2</span>/n[l<span class="number">-1</span>]*n[l])</span><br></pre></td></tr></table></figure><h2 id="梯度检验（Gradient-Checking）"><a href="#梯度检验（Gradient-Checking）" class="headerlink" title="梯度检验（Gradient Checking）"></a>梯度检验（Gradient Checking）</h2><p>检查验证<strong>反向传播过程中梯度下降算法是否正确</strong>。</p><h3 id="梯度的数值近似"><a href="#梯度的数值近似" class="headerlink" title="梯度的数值近似"></a>梯度的数值近似</h3><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://s2.ax1x.com/2019/08/19/m8lyb4.png" alt="梯度近似值求解" title>                </div>                <div class="image-caption">梯度近似值求解</div>            </figure><p>函数在θ出的导数近似为：</p><script type="math/tex; mode=display">g(\theta)=\frac{f(\theta+\epsilon)-f(\theta-\epsilon)}{2\epsilon}</script><p>其中，<em>ε</em>&gt;0，且足够小。</p><h3 id="梯度检查的过程"><a href="#梯度检查的过程" class="headerlink" title="梯度检查的过程"></a>梯度检查的过程</h3><ol><li><p>将<em>W</em>[1],<em>b</em>[1],⋯,<em>W</em>[<em>L</em>],<em>b</em>[<em>L</em>]这些矩阵构造成一维向量，然后将这些一维向量组合起来构成一个更大的一维向量<em>θ</em>。这样<em>J</em>(<em>W</em>[1],<em>b</em>[1],⋯,<em>W</em>[<em>L</em>],<em>b</em>[<em>L</em>])就可以表示为<em>J</em>(<em>θ</em>)。</p></li><li><p>将反向传播过程通过梯度下降算法得到的d<em>W</em>[1],d<em>b</em>[1],⋯,d<em>W</em>[<em>L</em>],d<em>b</em>[<em>L</em>]按照一样的顺序构造成一个一维向量<em>dθ</em>。<em>dθ</em>的维度与<em>θ</em>一致。</p></li><li><p>接着利用<em>J</em>(<em>θ</em>)对每个<em>θ</em>i计算近似梯度，其值与反向传播算法得到的<em>dθ</em>i相比较，检查是否一致。例如，对于第i个元素，近似梯度为：</p><script type="math/tex; mode=display">d\theta_{approx}[i]=\frac{J(\theta_1,\theta_2,\cdots,\theta_i+\epsilon,\cdots)-J(\theta_1,\theta_2,\cdots,\theta_i-\epsilon,\cdots)}{2\epsilon}</script></li><li><p>计算<em>dθ</em>approx与<em>dθ</em>的欧氏距离来比较二者的相似度。公式如下：</p></li></ol><script type="math/tex; mode=display">\frac{||d\theta_{approx}-d\theta||_2}{||d\theta_{approx}||_2+||d\theta||_2}</script><p>一般来说：</p><ul><li>如果欧氏距离很小，例如10^−7，甚至更小，则表明反向梯度计算是正确的;</li><li>如果欧氏距离较大，例如10^-5，则表明梯度计算可能出现问题，需要再次检查是否有bugs存在;</li><li>如果欧氏距离很大，例如10^-3，甚至更大，则表明梯度下降计算过程有bugs，需要仔细检查。</li></ul><h3 id="几点注意"><a href="#几点注意" class="headerlink" title="几点注意"></a>几点注意</h3><ol><li>不要在整个训练过程中都进行梯度检查，仅仅作为debug使用。</li><li>如果梯度检查出现错误，找到对应出错的梯度，检查其推导是否出现错误。</li><li>计算近似梯度的时候不能忽略正则项。</li><li>梯度检查时关闭dropout，检查完毕后再打开dropout</li></ol>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;数据集：训练集-开发集-测试集（Train-Dev-Test-sets）&quot;&gt;&lt;a href=&quot;#数据集：训练集-开发集-测试集（Train-Dev-Test-sets）&quot; class=&quot;headerlink&quot; title=&quot;数据集：训练集/开发集/测试集（Train/Dev/Test sets）&quot;&gt;&lt;/a&gt;数据集：训练集/开发集/测试集（Train/Dev/Test sets）&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;为实现&lt;code&gt;交叉验证&lt;/code&gt;（cross validation），数据集一般会划分为三个部分：&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;训练集（Train sets）：用于训练算法模型；&lt;/li&gt;
&lt;li&gt;开发集（Dev sets）：用于验证不同算法模型的表现情况，从中选择最好的算法模型；&lt;/li&gt;
&lt;li&gt;测试集（Test sets）：用于测试最好算法的实际表现（算法的无偏估计）。&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="学习笔记" scheme="http://yoursite.com/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
      <category term="deeplearning.ai" scheme="http://yoursite.com/tags/deeplearning-ai/"/>
    
  </entry>
  
  <entry>
    <title>deeplearning.ai学习笔记（四）深度神经网络（Deep Neural Network）</title>
    <link href="http://yoursite.com/2019/08/14/deeplearning-ai%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E5%9B%9B%EF%BC%89%E6%B7%B1%E5%BA%A6%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%EF%BC%88Deep-Neural-Network%EF%BC%89/"/>
    <id>http://yoursite.com/2019/08/14/deeplearning-ai学习笔记（四）深度神经网络（Deep-Neural-Network）/</id>
    <published>2019-08-14T14:28:38.000Z</published>
    <updated>2019-08-15T11:11:41.698Z</updated>
    
    <content type="html"><![CDATA[<p><strong>深度神经网络</strong>其实就是包含更多的隐藏层神经网络。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://s2.ax1x.com/2019/08/15/mVik1s.png" alt="越来越“深”的神经网络" title>                </div>                <div class="image-caption">越来越“深”的神经网络</div>            </figure><h2 id="深度神经网络为何如此有效？（Why-deep-representations"><a href="#深度神经网络为何如此有效？（Why-deep-representations" class="headerlink" title="深度神经网络为何如此有效？（Why deep representations?)"></a>深度神经网络为何如此有效？（Why deep representations?)</h2><p>神经网络效果显著，其强大能力主要源自神经网络足够“深”，即<strong>网络层数越多，神经网络就更加复杂和深入，学习也更加准确</strong>。</p><a id="more"></a><h3 id="由“浅”到“深”的特征提取"><a href="#由“浅”到“深”的特征提取" class="headerlink" title="由“浅”到“深”的特征提取"></a>由“浅”到“深”的特征提取</h3><p>以人脸识别为例：</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://s2.ax1x.com/2019/08/15/mVieBV.png" alt="人脸识别的特征提取" title>                </div>                <div class="image-caption">人脸识别的特征提取</div>            </figure><p>经过训练，神经网络第一层所做的事就是从原始图片中提取出人脸的轮廓与边缘，即边缘检测。这样每个神经元得到的是一些边缘信息。神经网络第二层所做的事情就是将前一层的边缘进行组合，组合成人脸一些局部特征，比如眼睛、鼻子、嘴巴等。再往后面，就将这些局部特征组合起来，融合成人脸的模样。</p><h3 id="深度网络能减少神经元个数"><a href="#深度网络能减少神经元个数" class="headerlink" title="深度网络能减少神经元个数"></a>深度网络能减少神经元个数</h3><p>以计算逻辑输出为例</p><script type="math/tex; mode=display">y=x_1 \oplus x_2 \oplus \cdots \oplus x_n</script><p><strong>使用深度网络：</strong></p><p>每层将前一层的两两单元进行异或，最后到一个输出。整个深度网络的层数是<em>l<strong>o</strong>g</em>2(<em>n</em>)，神经元个数为：</p><script type="math/tex; mode=display">1+2+\cdots+2^{log_2(n)-1}=n-1</script><p><strong>不使用深度网络：</strong></p><p>仅仅使用单个隐藏层，由于包含了所有的逻辑位，需要的神经元个数达到指数级别。</p><h2 id="构建深度神经网络"><a href="#构建深度神经网络" class="headerlink" title="构建深度神经网络"></a>构建深度神经网络</h2><h3 id="前向传播和反向传播流程块图"><a href="#前向传播和反向传播流程块图" class="headerlink" title="前向传播和反向传播流程块图"></a>前向传播和反向传播流程块图</h3><p><strong>对于第<em>l</em>层来说：</strong></p><p>正向传播时：</p><script type="math/tex; mode=display">输入:a^{[l-1]} \\输出:a^{[l]} \\参数:W^{[l]},b^{[l]} \\缓存:z^{[l]}</script><p>反向传播时：</p><script type="math/tex; mode=display">输入:da^{[l]} \\输出:da^{[l-1]},dW^{[l]},db^{[l]}\\参数:W^{[l]},b^{[l]}</script><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://s2.ax1x.com/2019/08/15/mViPhQ.png" alt="第l层流程块图" title>                </div>                <div class="image-caption">第l层流程块图</div>            </figure><p><strong>对于整个神经网络：</strong></p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://s2.ax1x.com/2019/08/15/mViFpj.png" alt="神经网络流程块图" title>                </div>                <div class="image-caption">神经网络流程块图</div>            </figure><h3 id="前向传播和反向传播计算表达式"><a href="#前向传播和反向传播计算表达式" class="headerlink" title="前向传播和反向传播计算表达式"></a>前向传播和反向传播计算表达式</h3><h4 id="正向传播"><a href="#正向传播" class="headerlink" title="正向传播"></a>正向传播</h4><script type="math/tex; mode=display">\begin{cases}z^{[l]}=W^{[l]}a^{[l-1]}+b^{[l]} \\a^{[l]}=g^{[l]}(z^{[l]})\end{cases}</script><p><strong>m个训练样本：</strong></p><script type="math/tex; mode=display">\begin{cases}Z^{[l]}=W^{[l]}A^{[l-1]}+b^{[l]} \\A^{[l]}=g^{[l]}(Z^{[l]})\end{cases}</script><h4 id="反向传播"><a href="#反向传播" class="headerlink" title="反向传播"></a>反向传播</h4><script type="math/tex; mode=display">\begin{cases}dz^{[l]}=da^{[l]}*g^{[l]'}(z^{[l]}) \\dW^{[l]}=dz^{[l]}\centerdot a^{[l-1]}\\db^{[l]}=dz^{[l]}\\da^{[l-1]}=W^{[l]T}\centerdot dz^{[l]}\\\end{cases}\\进一步推导可得递推关系:dz^{[l]}=W^{[l+1]T}\centerdot dz^{[l+1]}*g^{[l]'}(z^{[l]})</script><p><strong>m个训练样本：</strong></p><script type="math/tex; mode=display">\begin{cases}dZ^{[l]}=dA^{[l]}*g^{[l]'}(Z^{[l]}) \\dW^{[l]}=\frac{1}{m}dZ^{[l]}\centerdot A^{[l-1]T}\\db^{[l]}=\frac{1}{m}np.sum(dZ^{[l]},axis=1,keepdim=True) \\dA^{[l-1]}=W^{[l]T}\centerdot dZ^{[l]}\\\end{cases}\\进一步推导可得递推关系:dZ^{[l]}=W^{[l+1]T}\centerdot dZ^{[l+1]}*g^{[l]'}(Z^{[l]})</script><p>注：这里的“*”运算符表示矩阵对应位置相乘。</p><h2 id="参数（Parameters）-vs-超参数（Hyperparameters）"><a href="#参数（Parameters）-vs-超参数（Hyperparameters）" class="headerlink" title="参数（Parameters） vs 超参数（Hyperparameters）"></a>参数（Parameters） vs 超参数（Hyperparameters）</h2><ul><li>参数（parameters）：如<em>W</em>[l]、<em>b</em>[l]</li><li>超参数（hyperparameters）：学习率<em>α</em>，迭代次数N，神经网络层数L，各层神经元个数<em>n</em>[<em>l</em>]，激活函数<em>g</em>(<em>z</em>)等。它们决定了参数<em>W</em>[<em>l</em>]和<em>b</em>[<em>l</em>]的值，因此称为超参数。</li></ul><blockquote><p>Applied deep learning is a very empirical process.</p></blockquote><p>如何设置最优的超参数是一个比较困难的、需要经验知识的问题。通常的做法是选择超参数一定范围内的值，分别代入神经网络进行训练，测试cost function随着迭代次数增加的变化，根据结果选择cost function最小时对应的超参数值。</p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;深度神经网络&lt;/strong&gt;其实就是包含更多的隐藏层神经网络。&lt;/p&gt;
&lt;figure class=&quot;image-bubble&quot;&gt;
                &lt;div class=&quot;img-lightbox&quot;&gt;
                    &lt;div class=&quot;overlay&quot;&gt;&lt;/div&gt;
                    &lt;img src=&quot;https://s2.ax1x.com/2019/08/15/mVik1s.png&quot; alt=&quot;越来越“深”的神经网络&quot; title&gt;
                &lt;/div&gt;
                &lt;div class=&quot;image-caption&quot;&gt;越来越“深”的神经网络&lt;/div&gt;
            &lt;/figure&gt;
&lt;h2 id=&quot;深度神经网络为何如此有效？（Why-deep-representations&quot;&gt;&lt;a href=&quot;#深度神经网络为何如此有效？（Why-deep-representations&quot; class=&quot;headerlink&quot; title=&quot;深度神经网络为何如此有效？（Why deep representations?)&quot;&gt;&lt;/a&gt;深度神经网络为何如此有效？（Why deep representations?)&lt;/h2&gt;&lt;p&gt;神经网络效果显著，其强大能力主要源自神经网络足够“深”，即&lt;strong&gt;网络层数越多，神经网络就更加复杂和深入，学习也更加准确&lt;/strong&gt;。&lt;/p&gt;
    
    </summary>
    
    
      <category term="学习笔记" scheme="http://yoursite.com/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
      <category term="deeplearning.ai" scheme="http://yoursite.com/tags/deeplearning-ai/"/>
    
  </entry>
  
  <entry>
    <title>deeplearning.ai学习笔记（三）浅层神经网络（Shallow Neural Networks）</title>
    <link href="http://yoursite.com/2019/08/12/deeplearning-ai%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%89%EF%BC%89%E6%B5%85%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C/"/>
    <id>http://yoursite.com/2019/08/12/deeplearning-ai学习笔记（三）浅层神经网络/</id>
    <published>2019-08-12T13:44:29.000Z</published>
    <updated>2019-08-15T08:39:39.766Z</updated>
    
    <content type="html"><![CDATA[<h2 id="神经网络的表示"><a href="#神经网络的表示" class="headerlink" title="神经网络的表示"></a>神经网络的表示</h2><p>以一个<strong>单隐层神经网络</strong>为例：</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://s2.ax1x.com/2019/08/14/mkzbB4.png" alt="单隐层神经网络" title>                </div>                <div class="image-caption">单隐层神经网络</div>            </figure><p><strong>结构上</strong>，从左到右，可以分成三层：<code>输入层</code>（Input layer），<code>隐藏层</code>（Hidden layer）和<code>输出层</code>（Output layer）。输入层和输出层，对应着训练样本的输入和输出。隐藏层是抽象的非线性中间层，中间这一层节点的真实值并没有所观察，这也是其被命名为隐藏层的原因。</p><a id="more"></a><p>注：单隐藏层神经网络属于为两层神经网络，<strong>输入层不计入</strong>。</p><p><strong>记法上</strong>：</p><ol><li><p>把输入矩阵X记为<em>a</em>[0]，把隐藏层输出记为<em>a</em>[1]，输出层输出记为<em>a</em>[2]（即ŷ）。</p></li><li><p>用下标表示第几个神经元（下标从1开始）。例如<em>a</em>1[1]表示隐藏层第1个神经元，<em>a</em>2[1]表示隐藏层第2个神经元。隐藏层的输出可以写成矩阵形式：</p><script type="math/tex; mode=display">a^{[1]}=\begin{bmatrix}a_1^{[1]}\\a_2^{[1]}\\a_3^{[1]}\\a_4^{[1]}\end{bmatrix}</script></li><li><p>参数</p></li></ol><ul><li>隐藏层参数：权重<em>W</em>[1]，维度是（4,3），4对应着隐藏层神经元个数，3对应着输入层x特征向量包含元素个数。常数项<em>b</em>[1]，维度是（4,1），4同样对应着隐藏层神经元个数。</li><li>输出层参数：权重<em>W</em>[2]，维度是（1,4），1对应着输出层神经元个数，4对应着输出层神经元个数。常数项<em>b</em>[2]，维度是（1,1），因为输出只有一个神经元。</li></ul><p><strong>总结：第i层的权重<em>W</em>[<em>i</em>]维度的行等于i层神经元的个数，列等于i-1层神经元的个数；第i层常数项<em>b</em>[<em>i</em>]维度的行等于i层神经元的个数，列始终为1。</strong></p><h2 id="神经网络的输出（正向传播）"><a href="#神经网络的输出（正向传播）" class="headerlink" title="神经网络的输出（正向传播）"></a>神经网络的输出（正向传播）</h2><h3 id="单个神经元的输出"><a href="#单个神经元的输出" class="headerlink" title="单个神经元的输出"></a>单个神经元的输出</h3><p>每个神经元进行两个计算：<strong>线性加权</strong>（计算z）、<strong>非线性激活</strong>（计算a）。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://s2.ax1x.com/2019/08/14/mkzHuF.png" alt="逻辑回归单元" title>                </div>                <div class="image-caption">逻辑回归单元</div>            </figure><script type="math/tex; mode=display">z=w^{T}x+b \\a=\sigma(z)</script><h3 id="单个样本的神经网络正向传播过程"><a href="#单个样本的神经网络正向传播过程" class="headerlink" title="单个样本的神经网络正向传播过程"></a>单个样本的神经网络正向传播过程</h3><p>每个节点的计算都对应着一次逻辑运算的过程，分别由计算z和a两部分组成。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://s2.ax1x.com/2019/08/14/mkzbB4.png" alt="单隐层神经网络" title>                </div>                <div class="image-caption">单隐层神经网络</div>            </figure><h4 id="非向量化计算过程"><a href="#非向量化计算过程" class="headerlink" title="非向量化计算过程"></a>非向量化计算过程</h4><p>从输入层到隐藏层：</p><script type="math/tex; mode=display">z_1^{[1]}=w_1^{[1]T}x+b_1^{[1]},a_1^{[1]}=\sigma(z_1^{[1]}) \\z_2^{[1]}=w_2^{[1]T}x+b_2^{[1]},a_2^{[1]}=\sigma(z_2^{[1]}) \\z_3^{[1]}=w_3^{[1]T}x+b_3^{[1]},a_3^{[1]}=\sigma(z_3^{[1]}) \\z_4^{[1]}=w_4^{[1]T}x+b_4^{[1]},a_4^{[1]}=\sigma(z_4^{[1]})</script><p>从隐藏层到输出层：</p><script type="math/tex; mode=display">z_1^{[2]}=w_1^{[2]T}a^{[1]}+b_1^{[2]},a_1^{[2]}=\sigma(z_1^{[2]})</script><h4 id="向量化计算过程"><a href="#向量化计算过程" class="headerlink" title="向量化计算过程"></a>向量化计算过程</h4><script type="math/tex; mode=display">z^{[1]}=W^{[1]}x+b^{[1]},a^{[1]}=\sigma(z^{[1]}) \\z^{[2]}=W^{[2]}a^{[1]}+b^{[2]},a^{[2]}=\sigma(z^{[2]})</script><h3 id="m个训练样本的神经网络正向传播过程"><a href="#m个训练样本的神经网络正向传播过程" class="headerlink" title="m个训练样本的神经网络正向传播过程"></a>m个训练样本的神经网络正向传播过程</h3><h4 id="非向量化计算过程-1"><a href="#非向量化计算过程-1" class="headerlink" title="非向量化计算过程"></a>非向量化计算过程</h4><p>for i=1 to m:</p><script type="math/tex; mode=display">z^{[1](i)}=W^{[1]}x^{(i)}+b^{[1]},a^{[1](i)}=\sigma(z^{[1](i)}) \\z^{[2](i)}=W^{[2]}a^{[1](i)}+b^{[2]},a^{[2](i)}=\sigma(z^{[2](i)})</script><h4 id="向量化计算过程-1"><a href="#向量化计算过程-1" class="headerlink" title="向量化计算过程"></a>向量化计算过程</h4><script type="math/tex; mode=display">Z^{[1]}=W^{[1]}X+b^{[1]},A^{[1]}=\sigma(Z^{[1]}) \\Z^{[2]}=W^{[2]}A^{[1]}+b^{[2]},A^{[2]}=\sigma(Z^{[2]})</script><p>其中，<em>Z</em>[1]的维度是（4,m），4是隐藏层神经元的个数；<em>A</em>[1]的维度与<em>Z</em>[1]相同；<em>Z</em>[2]和<em>A</em>[2]的维度均为（1,m）。（行表示神经元个数，列表示样本数目m）</p><h2 id="激活函数"><a href="#激活函数" class="headerlink" title="激活函数"></a>激活函数</h2><h3 id="几种常见激活函数"><a href="#几种常见激活函数" class="headerlink" title="几种常见激活函数"></a>几种常见激活函数</h3><h4 id="sigmoid函数"><a href="#sigmoid函数" class="headerlink" title="sigmoid函数"></a>sigmoid函数</h4><ul><li><p>表达式及图像：</p><p><img src="https://s2.ax1x.com/2019/08/14/mkzOE9.png" alt="sigmoid函数"></p></li><li><p>导数：</p><script type="math/tex; mode=display">g^{'}(z)=a(1-a)</script></li></ul><h4 id="tanh函数"><a href="#tanh函数" class="headerlink" title="tanh函数"></a>tanh函数</h4><ul><li><p>表达式及图像：</p><p><img src="https://s2.ax1x.com/2019/08/14/mkzj41.png" alt="tanh函数"></p></li><li><p>导数：</p><script type="math/tex; mode=display">g^{'}(z)=1-a^{2}</script></li></ul><h4 id="ReLU函数（线性整流函数，Rectified-Linear-Unit）"><a href="#ReLU函数（线性整流函数，Rectified-Linear-Unit）" class="headerlink" title="ReLU函数（线性整流函数，Rectified Linear Unit）"></a>ReLU函数（线性整流函数，Rectified Linear Unit）</h4><ul><li><p>表达式及图像：</p><p><img src="https://s2.ax1x.com/2019/08/14/mkzx9x.png" alt="ReLU函数"></p></li><li><p>导数：</p><script type="math/tex; mode=display">g^{'}(z)=\begin{cases}1 & ,z>0 \\0 & ,z<0 \\Undefined & ,z=0\end{cases}</script></li></ul><h4 id="Leaky-ReLU函数"><a href="#Leaky-ReLU函数" class="headerlink" title="Leaky ReLU函数"></a>Leaky ReLU函数</h4><ul><li><p>表达式及图像：</p><p><img src="https://s2.ax1x.com/2019/08/14/mkzz36.png" alt="Leaky ReLU函数"></p></li><li><p>导数：</p><script type="math/tex; mode=display">g^{'}(z)=\begin{cases}1 & ,z>0 \\0.01 & ,z<0 \\Undefined & ,z=0\end{cases}</script></li></ul><h3 id="激活函数的比较与选择"><a href="#激活函数的比较与选择" class="headerlink" title="激活函数的比较与选择"></a>激活函数的比较与选择</h3><ul><li><strong>sigmoid VS tanh：</strong>对于隐藏层的激活函数，一般来说，tanh函数要比sigmoid函数表现更好一些。特别的，对于二分类问题的输出层，由于取值为[0,1]，所以一般会选择sigmoid作为激活函数。</li><li><strong>ReLU &amp; Leaky ReLU：</strong>sigmoid函数和tanh函数，当|z|很大的时候，激活函数的斜率（梯度）很小，梯度下降算法会运行得比较慢。对于隐藏层，选择ReLU作为激活函数能够保证z大于零时梯度始终为1，从而提高神经网络梯度下降算法运算速度。但当z小于零时，存在梯度为0的缺点（实际影响不大），而Leaky ReLU激活函数能够保证z小于零是梯度不为0。</li></ul><p><strong>实际应用中，通常会会选择使用ReLU/Leaky ReLU，保证梯度下降速度不会太小。</strong>具体选择哪个函数作为激活函数没有一个固定的准确的答案，要根据具体实际问题进行验证。</p><h3 id="为什么要用非线性函数做激活函数？"><a href="#为什么要用非线性函数做激活函数？" class="headerlink" title="为什么要用非线性函数做激活函数？"></a>为什么要用<strong>非线性函数</strong>做激活函数？</h3><p>假设所有的激活函数都是线性的，为了简化计算，我们直接令激活函数<em>g</em>(<em>z</em>)=<em>z</em>，即<em>a=z</em>。那么，浅层神经网络的各层输出为：</p><script type="math/tex; mode=display">z^{[1]}=W^{[1]}x+b^{[1]},a^{[1]}=z^{[1]}\\z^{[2]}=W^{[2]}a^{[1]}+b^{[2]},a^{[2]}=z^{[2]}</script><p>可简化为：</p><script type="math/tex; mode=display">a^{[2]}=z^{[2]}=W^{[2]}a^{[1]}+b^{[2]}=W^{[2]}(W^{[1]}x+b^{[1]})+b^{[2]}\\=(W^{[2]}W^{[1]})x+(b^{[1]}+b^{[2]})=W^{'}x+b^{'}</script><p>可见输出结果仍是输入变量x的线性组合。</p><p>这表明：</p><ul><li>包含多层隐藏层的神经网络，如果使用线性函数作为激活函数，最终的输出仍然是输入x的线性模型，神经网络就没有任何作用了。因此，<strong>隐藏层的激活函数必须要是非线性的</strong>。</li><li>如果所有的隐藏层全部使用线性激活函数，只有输出层使用非线性激活函数，那么整个神经网络的结构就类似于一个简单的逻辑回归模型，而失去了神经网络模型本身的优势和价值。</li><li>如果是预测问题而不是分类问题，<strong>输出y是连续的情况下，输出层的激活函数可以使用线性函数</strong>。如果输出y恒为正值，则也可以使用ReLU激活函数。</li></ul><h2 id="神经网络的梯度下降法"><a href="#神经网络的梯度下降法" class="headerlink" title="神经网络的梯度下降法"></a>神经网络的梯度下降法</h2><h3 id="算法过程"><a href="#算法过程" class="headerlink" title="算法过程"></a>算法过程</h3><p>与逻辑回归类似，先对参数进行初始化，然后前向传播计算输出值，再反向传播更新参数，直至到达损失函数的最优值。</p><h3 id="参数的随机初始化"><a href="#参数的随机初始化" class="headerlink" title="参数的随机初始化"></a>参数的随机初始化</h3><h4 id="神经网络中的参数权重W不能全部初始化为零"><a href="#神经网络中的参数权重W不能全部初始化为零" class="headerlink" title="神经网络中的参数权重W不能全部初始化为零"></a>神经网络中的参数权重W不能全部初始化为零</h4><p>以例来说明：一个浅层神经网络包含两个输入，隐藏层包含两个神经元。如果权重<em>W</em>[1]和<em>W</em>[2]都初始化为零，即：</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://s2.ax1x.com/2019/08/14/mASPDe.png" alt="浅层神经网络实例" title>                </div>                <div class="image-caption">浅层神经网络实例</div>            </figure><script type="math/tex; mode=display">W^{[1]}=\begin{bmatrix}0 & 0\\0 & 0\end{bmatrix},W^{[2]}=\begin{bmatrix}0 & 0\end{bmatrix}</script><p>这样使得隐藏层第一个神经元的输出等于第二个神经元的输出，即<em>a</em>1[1]=<em>a</em>2[1]。经过推导得到d<em>z</em>1[1]=d<em>z</em>2[1]、d<em>W</em>1[1]=d<em>W</em>2[1]。隐藏层两个神经元对应的权重每次迭代更新都会得到完全相同的结果，<em>W</em>1[1]始终等于<em>W</em>2[1]，完全对称，产生<code>Symmetry breaking problem</code>，使得隐藏层设置多个神经元就没有任何意义了。</p><p>注：参数b可以全部初始化为零，并不会影响神经网络训练效果。</p><h4 id="随机初始化方法"><a href="#随机初始化方法" class="headerlink" title="随机初始化方法"></a>随机初始化方法</h4><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">W_1 = np.random.randn((<span class="number">2</span>,<span class="number">2</span>))*<span class="number">0.01</span></span><br><span class="line">b_1 = np.zero((<span class="number">2</span>,<span class="number">1</span>))</span><br><span class="line">W_2 = np.random.randn((<span class="number">1</span>,<span class="number">2</span>))*<span class="number">0.01</span></span><br><span class="line">b_2 = <span class="number">0</span></span><br></pre></td></tr></table></figure><p>注：乘以0.01的目的是<strong>尽量使得权重W初始化为比较小的值</strong>。如果使用sigmoid/tanh函数作为激活函数，W比较小，得到的|z|也比较小（靠近零点），梯度大，梯度下降算法的迭代速度快。（如果激活函数是ReLU/Leaky ReLU函数，则不需要考虑这个问题）</p><h3 id="神经网络的前向传播（Forward-propagation）"><a href="#神经网络的前向传播（Forward-propagation）" class="headerlink" title="神经网络的前向传播（Forward propagation）"></a>神经网络的前向传播（Forward propagation）</h3><p>即计算神经网络的输出。</p><h3 id="神经网络的反向传播（Back-propagation）"><a href="#神经网络的反向传播（Back-propagation）" class="headerlink" title="神经网络的反向传播（Back propagation）"></a>神经网络的反向传播（Back propagation）</h3><p><strong>计算公式：</strong></p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://s2.ax1x.com/2019/08/14/mASCuD.png" alt="反向传播计算公式" title>                </div>                <div class="image-caption">反向传播计算公式</div>            </figure><p><strong>推导过程：</strong></p><p>利用神经网络的计算图：</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://s2.ax1x.com/2019/08/14/mASpjO.png" alt="神经网络计算图" title>                </div>                <div class="image-caption">神经网络计算图</div>            </figure><p>根据求导的链式法则反向进行逐步推导，再利用向量化推广至整个训练集。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;神经网络的表示&quot;&gt;&lt;a href=&quot;#神经网络的表示&quot; class=&quot;headerlink&quot; title=&quot;神经网络的表示&quot;&gt;&lt;/a&gt;神经网络的表示&lt;/h2&gt;&lt;p&gt;以一个&lt;strong&gt;单隐层神经网络&lt;/strong&gt;为例：&lt;/p&gt;
&lt;figure class=&quot;image-bubble&quot;&gt;
                &lt;div class=&quot;img-lightbox&quot;&gt;
                    &lt;div class=&quot;overlay&quot;&gt;&lt;/div&gt;
                    &lt;img src=&quot;https://s2.ax1x.com/2019/08/14/mkzbB4.png&quot; alt=&quot;单隐层神经网络&quot; title&gt;
                &lt;/div&gt;
                &lt;div class=&quot;image-caption&quot;&gt;单隐层神经网络&lt;/div&gt;
            &lt;/figure&gt;
&lt;p&gt;&lt;strong&gt;结构上&lt;/strong&gt;，从左到右，可以分成三层：&lt;code&gt;输入层&lt;/code&gt;（Input layer），&lt;code&gt;隐藏层&lt;/code&gt;（Hidden layer）和&lt;code&gt;输出层&lt;/code&gt;（Output layer）。输入层和输出层，对应着训练样本的输入和输出。隐藏层是抽象的非线性中间层，中间这一层节点的真实值并没有所观察，这也是其被命名为隐藏层的原因。&lt;/p&gt;
    
    </summary>
    
    
      <category term="学习笔记" scheme="http://yoursite.com/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
      <category term="deeplearning.ai" scheme="http://yoursite.com/tags/deeplearning-ai/"/>
    
  </entry>
  
  <entry>
    <title>deeplearning.ai学习笔记（二）神经网络基础——以二值分类问题的逻辑回归模型为例</title>
    <link href="http://yoursite.com/2019/08/11/deeplearning-ai%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%BA%8C%EF%BC%89%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%E2%80%94%E2%80%94%E4%BB%A5%E4%BA%8C%E5%80%BC%E5%88%86%E7%B1%BB%E9%97%AE%E9%A2%98%E7%9A%84%E9%80%BB%E8%BE%91%E5%9B%9E%E5%BD%92%E6%A8%A1%E5%9E%8B%E4%B8%BA%E4%BE%8B/"/>
    <id>http://yoursite.com/2019/08/11/deeplearning-ai学习笔记（二）神经网络基础——以二值分类问题的逻辑回归模型为例/</id>
    <published>2019-08-11T02:18:57.000Z</published>
    <updated>2019-08-12T13:56:39.367Z</updated>
    
    <content type="html"><![CDATA[<h2 id="二值分类（Binary-Classification-）问题"><a href="#二值分类（Binary-Classification-）问题" class="headerlink" title="二值分类（Binary Classification ）问题"></a>二值分类（Binary Classification ）问题</h2><h3 id="描述"><a href="#描述" class="headerlink" title="描述"></a>描述</h3><p>例如：<strong>猫咪检测器</strong>（Cat vs Non-Cat ）</p><p>目标是训练一个分类器，对于输入的照片，如果它是一张猫咪的照片就输出1，否则输出0。</p><h3 id="输入"><a href="#输入" class="headerlink" title="输入"></a>输入</h3><p>将一张RGB三通道彩色图像展开为一个长的列向量做为输入。</p><p>若图片尺寸为64*64，则向量的维度n(x)=64*64*3=12288。</p><a id="more"></a><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://s2.ax1x.com/2019/08/11/exSOED.md.png" alt="输入特征向量x" title>                </div>                <div class="image-caption">输入特征向量x</div>            </figure><h3 id="输出"><a href="#输出" class="headerlink" title="输出"></a>输出</h3><p>对于二值分类问题，输出结果只有两个——<strong>0或1</strong>。</p><p>输出标签的向量形式：（m维列向量）</p><script type="math/tex; mode=display">\begin{bmatrix}y^{(1)}\\y^{(2)}  \\\vdots \\y^{(i)}  \end{bmatrix}</script><h3 id="训练数据"><a href="#训练数据" class="headerlink" title="训练数据"></a>训练数据</h3><ul><li>单个样本由一对（x,y）表示，其中x是一个n(x)维的特征向量 ，y是取值为0或1的标签。</li><li>训练集包含m个训练样本（用小写m代表训练集的样本总数），(x(i),y(i)) 表示第i个样本的输入和输出。</li><li>写成矩阵形式如下：（X.shape=n_x*m）</li></ul><script type="math/tex; mode=display">\begin{bmatrix}\vdots & \vdots & \vdots & \vdots \\x^{(1)} & x^{(2)} & \cdots & x^{(i)} \\\vdots & \vdots & \vdots & \vdots \end{bmatrix}</script><h2 id="逻辑回归（Logistic-Regression-）模型"><a href="#逻辑回归（Logistic-Regression-）模型" class="headerlink" title="逻辑回归（Logistic Regression ）模型"></a><strong>逻辑回归</strong>（Logistic Regression ）模型</h2><p>逻辑回归是一种用于解决输出是0/1的监督学习问题的学习算法，它使得预测值与训练数据之间的偏差最小。</p><h3 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h3><p>以Cat vs No - cat为例：</p><p>把一张图片展开为特征向量x做为输入，算法将估计这张图片中包含猫咪的概率。</p><script type="math/tex; mode=display">Given~x~,~\hat{y}=P(y=1|x),where~0\leq\hat{y}\leq1</script><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://s2.ax1x.com/2019/08/11/exSWEF.md.png" alt="逻辑回归模型" title>                </div>                <div class="image-caption">逻辑回归模型</div>            </figure><p>其中各个参数的意义：</p><ul><li>x：输入特征向量（一个n_x维列向量）</li><li>y：训练集标签，y∈0,1</li><li>weights——w：权重（一个n_x维列向量）</li><li>threshold——b：偏置量（一个实数）</li></ul><blockquote><p>Sigmoid 函数：</p><script type="math/tex; mode=display">\sigma(z)=\frac{1}{1+e^{-z}}</script><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://s2.ax1x.com/2019/08/11/exSog1.md.png" alt="Sigmoid函数图像" title>                </div>                <div class="image-caption">Sigmoid函数图像</div>            </figure><p>该函数的特点：</p><ul><li>当z趋于+∞，函数值趋于1</li><li>当z趋于-∞，函数值趋于0</li><li>当z=0，函数值为0.5</li></ul><p>作用：将输出值限制在[0,1]，使其可以表示一个概率值</p></blockquote><h3 id="代价函数（Cost-function-）"><a href="#代价函数（Cost-function-）" class="headerlink" title="代价函数（Cost function ）"></a>代价函数（Cost function ）</h3><h4 id="损失函数-vs-代价函数"><a href="#损失函数-vs-代价函数" class="headerlink" title="损失函数 vs 代价函数"></a>损失函数 vs 代价函数</h4><blockquote><p>损失函数（Loss function）是定义在<strong>单个样本</strong>上的，算的是一个样本的误差。</p><p>代价函数（Cost function）是定义在<strong>整个训练集</strong>上的，是所有样本误差的平均，也就是损失函数的平均。</p></blockquote><p><strong>代价函数用来衡量参数在整个模型中的作用效果。</strong></p><h4 id="逻辑回归的损失函数"><a href="#逻辑回归的损失函数" class="headerlink" title="逻辑回归的损失函数"></a>逻辑回归的损失函数</h4><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://s2.ax1x.com/2019/08/11/exSh4J.md.png" alt="损失函数" title>                </div>                <div class="image-caption">损失函数</div>            </figure><p><strong>推导过程：</strong></p><p>我们希望算法输出ŷ 表示当给定输入特征x的时候y=1的概率。换句话说，如果y等于1，那么p(y|x)就等于ŷ ；相反地，当y=0时，p(y|x)就等于1-ŷ 。因此，如果ŷ表示当y=1的概率，那么1-ŷ就表示y=0的概率。</p><p>可以定义p(y|x)如下：</p><p>由于y只有0和1两种取值，因此上面的两个方程可以归纳为如下一个方程：</p><script type="math/tex; mode=display">p(y|x)=ŷ^y*(1-ŷ)^{1-y}</script><p>因为对数函数是一个绝对的单调递增函数，最大化log(p(y|x))会得出和最大化p(y|x)相似的结果，因此可以取对数，简化公式。</p><script type="math/tex; mode=display">log(ŷ^y*(1-ŷ)^{1-y}) =ylog(ŷ)+(1-y)log(1-ŷ)</script><p>又因为通常在训练一个学习算法的时候，我们想要让概率变大。而在逻辑回归中，我们想要最小化L(ŷ,y)这个损失函数。最小化损失函数相当于最大化概率的对数，所以需要加一个负号。</p><script type="math/tex; mode=display">L(ŷ,y)=-(ylog(ŷ)+(1-y)log(1-ŷ))</script><h4 id="逻辑回归的代价函数"><a href="#逻辑回归的代价函数" class="headerlink" title="逻辑回归的代价函数"></a>逻辑回归的代价函数</h4><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://s2.ax1x.com/2019/08/11/exSI3R.md.png" alt="代价函数" title>                </div>                <div class="image-caption">代价函数</div>            </figure><p><strong>推导过程：</strong></p><p>假设取出的训练样本相互独立，或者说服从独立同分布 (I.I.D: Independent and Identically Distributed) ，这些样本的概率就是各项概率的乘积。</p><p>给定X(i)从i=1到m时p(y(i))的乘积：</p><script type="math/tex; mode=display">p(y^{(1)})*p(y^{(2)})*\cdots*p(y^{(m)})</script><p>最大化这个式子本身和最大化它的对数效果相同，所以取对数：</p><script type="math/tex; mode=display">log(p(y^{(1)}))+log(p(y^{(2)}))+\cdots+log(p(y^{(m)}))=\sum_{i=1}^{m}log(p(y^{(i)}))=-\sum_{i=1}^{m}L(ŷ^{(i)},y^{(i)})</script><p>根据最大似然估计原理，选择能使该式最大化的参数。因为要最小化代价函数，而不是最大化似然值，所以要去掉这个负号。最后为了方便起见，使这些数值处于更好的尺度上，在前面添加一个缩放系数1/m。</p><p>综上，代价函数为：</p><script type="math/tex; mode=display">J(w,b)=\frac{1}{m}\sum_{i=1}^{m}L(ŷ^{(i)},y^{(i)})=-\frac{1}{m}\sum_{i=1}^{m}[y^{(i)}log(ŷ^{(i)})+(1-y^{(i)})log(1-ŷ^{(i)})]</script><p><strong>优化逻辑回归模型时，我们试着去找参数w和b，以此来缩小代价函数J， 逻辑回归可被视为一个非常小的神经网络 。</strong></p><h2 id="训练过程——梯度下降（Gradient-Descent）算法"><a href="#训练过程——梯度下降（Gradient-Descent）算法" class="headerlink" title="训练过程——梯度下降（Gradient Descent）算法"></a>训练过程——<strong>梯度下降</strong>（Gradient Descent）算法</h2><h3 id="算法思想"><a href="#算法思想" class="headerlink" title="算法思想"></a>算法思想</h3><p>在逻辑回归问题中，代价函数J是一个凸函数(convex function) 。为了去找到优的参数值，首先用一些初始值（0或随机）来初始化w和b，因为函数是凸函数，无论在哪里初始化，应该达到同一点或大致相同的点。</p><p>梯度下降法以初始点开始，然后朝最陡的下坡方向走一步，这是梯度下降的一次迭代。经过多次迭代收敛到全局最优值或接近全局最优值。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://s2.ax1x.com/2019/08/11/exS5C9.md.png" alt="梯度下降示意图" title>                </div>                <div class="image-caption">梯度下降示意图</div>            </figure><p>参数的迭代公式：</p><script type="math/tex; mode=display">w:=w-\alpha\frac{\partial{J(w,b)}}{\partial{w}}</script><script type="math/tex; mode=display">b:=b-\alpha\frac{\partial{J(w,b)}}{\partial{b}}</script><h3 id="数学基础：计算图（Computation-Graph）"><a href="#数学基础：计算图（Computation-Graph）" class="headerlink" title="数学基础：计算图（Computation Graph）"></a>数学基础：计算图（Computation Graph）</h3><p>以下式为例</p><script type="math/tex; mode=display">J(a,b,c)=3(a+bc)</script><p>其计算图为：</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://s2.ax1x.com/2019/08/11/exSHu6.md.png" alt="计算图" title>                </div>                <div class="image-caption">计算图</div>            </figure><h4 id="计算图计算（前向传播过程）"><a href="#计算图计算（前向传播过程）" class="headerlink" title="计算图计算（前向传播过程）"></a>计算图计算（前向传播过程）</h4><p>前向传播即为计算一个样本下J的值，计算过程如下：</p><script type="math/tex; mode=display">u=b*c=3*2=6 \\v=a+u=5+6=11 \\J=3V=33</script><h4 id="计算图求导（反向传播过程）"><a href="#计算图求导（反向传播过程）" class="headerlink" title="计算图求导（反向传播过程）"></a>计算图求导（反向传播过程）</h4><p>反向传播即根据<strong>求导的链式法则</strong>，求解最终输出变量J对各个变量的导数。</p><p>计算过程如下：</p><script type="math/tex; mode=display">\frac{dJ}{dv}=\frac{d(3v)}{dv}=3 \\\frac{dJ}{da}=\frac{dJ}{dv}*\frac{dv}{da}=3*\frac{d(a+u)}{da}=3 \\\frac{dJ}{du}=\frac{dJ}{dv}*\frac{dv}{du}=3*\frac{d(a+u)}{du}=3 \\\frac{dJ}{db}=\frac{dJ}{du}*\frac{du}{db}=3*\frac{d(bc)}{db}=3c=3*2=6 \\\frac{dJ}{dc}=\frac{dJ}{du}*\frac{du}{dc}=3*\frac{d(bc)}{db}=3b=3*3=9</script><p>为简化表示，将dJ/dval简记为dval，则在本例中：</p><script type="math/tex; mode=display">da=3,db=6,dc=9</script><h3 id="逻辑回归模型的前向传播和反向传播过程（单个样本）"><a href="#逻辑回归模型的前向传播和反向传播过程（单个样本）" class="headerlink" title="逻辑回归模型的前向传播和反向传播过程（单个样本）"></a>逻辑回归模型的前向传播和反向传播过程（单个样本）</h3><h4 id="逻辑回归模型的计算图"><a href="#逻辑回归模型的计算图" class="headerlink" title="逻辑回归模型的计算图"></a>逻辑回归模型的计算图</h4><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://s2.ax1x.com/2019/08/11/exSbDK.md.png" alt="逻辑回归模型的计算图" title>                </div>                <div class="image-caption">逻辑回归模型的计算图</div>            </figure><h4 id="逻辑回归模型的前向传播"><a href="#逻辑回归模型的前向传播" class="headerlink" title="逻辑回归模型的前向传播"></a>逻辑回归模型的前向传播</h4><p>顺序计算即可。</p><h4 id="逻辑回归模型的反向传播"><a href="#逻辑回归模型的反向传播" class="headerlink" title="逻辑回归模型的反向传播"></a>逻辑回归模型的反向传播</h4><p>计算过程如下：</p><script type="math/tex; mode=display">“da”=\frac{dL}{da}=-\frac{y}{a}+\frac{1-y}{1-a} \\“dz”=\frac{dL}{dz}=\frac{dL}{da}*\frac{da}{dz}=(-\frac{y}{a}+\frac{1-y}{1-a})*\frac{d\sigma(z)}{dz} = a(1-a) \\“dw_1”=\frac{dL}{dw_1}=\frac{dL}{dz}*\frac{dz}{dw_1}=x_1*“dz” \\“dw_2”=\frac{dL}{dw_2}=\frac{dL}{dz}*\frac{dz}{dw_2}=x_2*“dz” \\“db”=\frac{dL}{db}=\frac{dL}{dz}*\frac{dz}{db}=“dz”</script><h3 id="非向量化的逻辑回归训练过程"><a href="#非向量化的逻辑回归训练过程" class="headerlink" title="非向量化的逻辑回归训练过程"></a>非向量化的逻辑回归训练过程</h3><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://s2.ax1x.com/2019/08/11/exSqHO.md.png" alt="非向量化的逻辑回归训练过程" title>                </div>                <div class="image-caption">非向量化的逻辑回归训练过程</div>            </figure><ul><li>缺点：显式地使用了两层for循环，时间效率低</li><li>解决方法：采用向量化的方法，可以极大地提高时间效率</li></ul><h3 id="向量化（Vectorizing）的逻辑回归训练过程"><a href="#向量化（Vectorizing）的逻辑回归训练过程" class="headerlink" title="向量化（Vectorizing）的逻辑回归训练过程"></a>向量化（Vectorizing）的逻辑回归训练过程</h3><script type="math/tex; mode=display">Z = W^{T}*X+b = np.dot(W.T,X)+b //此处存在python的广播机制 \\A = σ(Z) \\dZ = A - Y \\dW = \frac{1}{m}XdZ^{T}\\db = \frac{1}{m}*np.sum(dZ)\\W := W - \alpha dW\\b := b - \alpha db</script><p>注意：此为一次迭代的过程，多次迭代使用显示循环不可避免。</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;二值分类（Binary-Classification-）问题&quot;&gt;&lt;a href=&quot;#二值分类（Binary-Classification-）问题&quot; class=&quot;headerlink&quot; title=&quot;二值分类（Binary Classification ）问题&quot;&gt;&lt;/a&gt;二值分类（Binary Classification ）问题&lt;/h2&gt;&lt;h3 id=&quot;描述&quot;&gt;&lt;a href=&quot;#描述&quot; class=&quot;headerlink&quot; title=&quot;描述&quot;&gt;&lt;/a&gt;描述&lt;/h3&gt;&lt;p&gt;例如：&lt;strong&gt;猫咪检测器&lt;/strong&gt;（Cat vs Non-Cat ）&lt;/p&gt;
&lt;p&gt;目标是训练一个分类器，对于输入的照片，如果它是一张猫咪的照片就输出1，否则输出0。&lt;/p&gt;
&lt;h3 id=&quot;输入&quot;&gt;&lt;a href=&quot;#输入&quot; class=&quot;headerlink&quot; title=&quot;输入&quot;&gt;&lt;/a&gt;输入&lt;/h3&gt;&lt;p&gt;将一张RGB三通道彩色图像展开为一个长的列向量做为输入。&lt;/p&gt;
&lt;p&gt;若图片尺寸为64*64，则向量的维度n(x)=64*64*3=12288。&lt;/p&gt;
    
    </summary>
    
    
      <category term="学习笔记" scheme="http://yoursite.com/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
      <category term="deeplearning.ai" scheme="http://yoursite.com/tags/deeplearning-ai/"/>
    
  </entry>
  
  <entry>
    <title>那些既熟悉又陌生的C/C++知识点（长期更新）</title>
    <link href="http://yoursite.com/2019/08/09/%E9%82%A3%E4%BA%9B%E6%97%A2%E7%86%9F%E6%82%89%E5%8F%88%E9%99%8C%E7%94%9F%E7%9A%84C-C-%E7%9F%A5%E8%AF%86%E7%82%B9%EF%BC%88%E9%95%BF%E6%9C%9F%E6%9B%B4%E6%96%B0%EF%BC%89/"/>
    <id>http://yoursite.com/2019/08/09/那些既熟悉又陌生的C-C-知识点（长期更新）/</id>
    <published>2019-08-09T15:21:44.000Z</published>
    <updated>2019-08-09T16:04:41.156Z</updated>
    
    <content type="html"><![CDATA[<h2 id="头文件的等价写法"><a href="#头文件的等价写法" class="headerlink" title="头文件的等价写法"></a>头文件的等价写法</h2><p>在C++标准中，<strong>stdio.h</strong>更推荐使用等价写法：<strong>cstdio</strong>，也就是在前面加一个<code>c</code>，然后去掉<code>.h</code>即可。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">/* 以下两种写法等价 */</span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;stdio.h&gt;</span></span></span><br><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;cstdio&gt;</span></span></span><br></pre></td></tr></table></figure><h2 id="整型变量类型表示数的范围"><a href="#整型变量类型表示数的范围" class="headerlink" title="整型变量类型表示数的范围"></a>整型变量类型表示数的范围</h2><ul><li>整型<code>int</code>：<strong>32位</strong>整数/<strong>绝对值在10^9范围以内</strong>的整数都可以定义为int型</li><li>长整型<code>long long</code>：<strong>64位</strong>整数/<strong>10^18以内（如10^10）</strong>的整数就要定义为long long型</li></ul><h2 id="long-long型的使用"><a href="#long-long型的使用" class="headerlink" title="long long型的使用"></a>long long型的使用</h2><p>long long型赋<strong>大于2^31-1</strong>的初值，需要在初值后面加上LL</p><p>经常<strong>利用typedef用LL来代替long long</strong>，以避免在程序中大量出现long long而降低编码的效率。</p><figure class="highlight c++"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#<span class="meta-keyword">include</span><span class="meta-string">&lt;cstdio&gt;</span></span></span><br><span class="line"><span class="keyword">typedef</span> <span class="keyword">long</span> <span class="keyword">long</span> LL; <span class="comment">//给long long起个别名LL</span></span><br><span class="line"><span class="function"><span class="keyword">int</span> <span class="title">main</span><span class="params">()</span></span></span><br><span class="line"><span class="function"></span>&#123;</span><br><span class="line">    LL a = <span class="number">123456789012345L</span>L, b = <span class="number">234567890123456L</span>L;</span><br><span class="line">    <span class="built_in">printf</span>(<span class="string">"%lld\n"</span>, a + b);</span><br><span class="line">    <span class="keyword">return</span> <span class="number">0</span>;</span><br><span class="line">&#125;</span><br></pre></td></tr></table></figure><h2 id="浮点数的存储类型"><a href="#浮点数的存储类型" class="headerlink" title="浮点数的存储类型"></a>浮点数的存储类型</h2><p>对于浮点型，<strong>不要使用float，碰到浮点型的数据都应该用double来存储</strong>。</p><ul><li>单精度<code>float</code>：有效精度只有<strong>6~7位</strong></li><li>双精度<code>double</code>：有效精度有<strong>15~16位</strong></li></ul><h2 id="double型的输入输出格式"><a href="#double型的输入输出格式" class="headerlink" title="double型的输入输出格式"></a>double型的输入输出格式</h2><ul><li>输出格式：<code>%f</code>（与float型相同）</li><li>输入格式：scanf中是<code>%lf</code></li></ul><p>注：有些系统如果把输出格式写成%lf也不会出错，但尽量还是按标准来</p>]]></content>
    
    <summary type="html">
    
      
      
        &lt;h2 id=&quot;头文件的等价写法&quot;&gt;&lt;a href=&quot;#头文件的等价写法&quot; class=&quot;headerlink&quot; title=&quot;头文件的等价写法&quot;&gt;&lt;/a&gt;头文件的等价写法&lt;/h2&gt;&lt;p&gt;在C++标准中，&lt;strong&gt;stdio.h&lt;/strong&gt;更推荐使用等价写法：&lt;str
      
    
    </summary>
    
    
      <category term="C/C++" scheme="http://yoursite.com/tags/C-C/"/>
    
  </entry>
  
  <entry>
    <title>deeplearning.ai学习笔记（一）深度学习引言</title>
    <link href="http://yoursite.com/2019/08/09/deeplearning-ai%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E4%B8%80%EF%BC%89%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E5%BC%95%E8%A8%80/"/>
    <id>http://yoursite.com/2019/08/09/deeplearning-ai学习笔记（一）深度学习引言/</id>
    <published>2019-08-09T06:30:38.000Z</published>
    <updated>2019-08-09T09:05:27.062Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>AI is the new Electricity. ——吴恩达（<a href="https://www.coursera.org/instructor/andrewng" target="_blank" rel="noopener">Andrew Ng</a>）</p></blockquote><p>大约在一百年前，社会的电气化改变了每个主要行业。而如今我们见到了 AI令人惊讶的能量会产生同样巨大的转变。显然 AI的各个分支中，发展最为迅速的就是<strong>深度学习</strong>（deep learning）。而<strong>深度学习</strong>，一般指的是训练<strong>神经网络</strong>（有时是非常非常大/深的神经网络）。</p><a id="more"></a><h2 id="何为神经网络（What-is-a-neural-network-）"><a href="#何为神经网络（What-is-a-neural-network-）" class="headerlink" title="何为神经网络（What is a neural network?）"></a>何为神经网络（What is a <strong>neural network</strong>?）</h2><h3 id="引例：房价预测（Housing-Price-Prediction）"><a href="#引例：房价预测（Housing-Price-Prediction）" class="headerlink" title="引例：房价预测（Housing Price Prediction）"></a>引例：房价预测（Housing Price Prediction）</h3><p>如下图，对于单个因素（如房屋面积）的房屋预测，可以用ReLU函数进行拟合，相当于一个只有一个神经元的神经网络。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://s2.ax1x.com/2019/08/09/ebRgtx.md.png" alt="ReLU函数拟合" title>                </div>                <div class="image-caption">ReLU函数拟合</div>            </figure><p>用房子的大小 x 作为神经网络的输入，它进入到这个节点(这个小圈)中 ，然后这个小圈就输出了房价 y 。所以这个小圈，也就是一个神经网络中的一个神经元，就会执行上图中画出的这个方程。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://s2.ax1x.com/2019/08/09/ebfBw9.png" alt="单个神经元的神经网络" title>                </div>                <div class="image-caption">单个神经元的神经网络</div>            </figure><p><strong>一个很大的神经网络是由许多这样的单一神经元叠加在一起组成。</strong>比如下面这个例子，我们不仅仅根据房屋大小来预测房屋价格，我们引入其他特征量。能够容纳的家庭人口也会影响房屋价格 ，这个因素其实是取决于房屋大小以及卧室的数量这两个因素决定了这个房子是否能够容纳你的家庭 。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://s2.ax1x.com/2019/08/09/ebfvwj.md.png" alt="多因素房价预测" title>                </div>                <div class="image-caption">多因素房价预测</div>            </figure><p>所以在这个例子中：</p><ul><li>x 表示所有这四个输入 (房屋大小、卧室数量、邮政编码、富裕程度)</li><li>y表示试图去预测的价格</li><li>每一个小圆圈是ReLU 函数或者别的一些非线性函数</li></ul><p>这就是最基本的神经网络。</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://s2.ax1x.com/2019/08/09/ebftzT.md.png" alt="简单神经网络" title>                </div>                <div class="image-caption">简单神经网络</div>            </figure><h2 id="深度学习：监督学习的一种（Supervised-Learning-with-Neural-Networks）"><a href="#深度学习：监督学习的一种（Supervised-Learning-with-Neural-Networks）" class="headerlink" title="深度学习：监督学习的一种（Supervised Learning with Neural Networks）"></a>深度学习：监督学习的一种（Supervised Learning with Neural Networks）</h2><h3 id="监督学习与非监督学习"><a href="#监督学习与非监督学习" class="headerlink" title="监督学习与非监督学习"></a>监督学习与非监督学习</h3><p><code>监督学习</code>：给定标记好的训练样本集，如回归问题、分类问题</p><p><code>非监督学习</code>：给定样本集，发现特征数据中的分布结构，如聚类问题</p><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://s2.ax1x.com/2019/08/09/ebfayF.md.png" alt="监督学习" title>                </div>                <div class="image-caption">监督学习</div>            </figure><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://s2.ax1x.com/2019/08/09/ebfdL4.md.png" alt="非监督学习" title>                </div>                <div class="image-caption">非监督学习</div>            </figure><h3 id="深度学习在监督学习中的应用-amp-常用神经网络"><a href="#深度学习在监督学习中的应用-amp-常用神经网络" class="headerlink" title="深度学习在监督学习中的应用 &amp; 常用神经网络"></a>深度学习在监督学习中的应用 &amp; 常用神经网络</h3><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://s2.ax1x.com/2019/08/09/ebfDoR.md.png" alt="深度学习的应用" title>                </div>                <div class="image-caption">深度学习的应用</div>            </figure><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://s2.ax1x.com/2019/08/09/ebfTYt.md.png" alt="几种常见神经网络" title>                </div>                <div class="image-caption">几种常见神经网络</div>            </figure><h3 id="结构化数据与非结构化数据"><a href="#结构化数据与非结构化数据" class="headerlink" title="结构化数据与非结构化数据"></a>结构化数据与非结构化数据</h3><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://s2.ax1x.com/2019/08/09/ebfoFI.md.png" alt="结构化数据与非结构化数据示例" title>                </div>                <div class="image-caption">结构化数据与非结构化数据示例</div>            </figure><h2 id="深度学习兴起的原因（Why-is-Deep-Learning-taking-off-）"><a href="#深度学习兴起的原因（Why-is-Deep-Learning-taking-off-）" class="headerlink" title="深度学习兴起的原因（Why is Deep Learning taking off?）"></a>深度学习兴起的原因（Why is Deep Learning taking off?）</h2><blockquote><p>Scale drives deep learning progress.——吴恩达（<a href="https://www.coursera.org/instructor/andrewng" target="_blank" rel="noopener">Andrew Ng</a>）</p></blockquote><h3 id="深度学习的性能"><a href="#深度学习的性能" class="headerlink" title="深度学习的性能"></a>深度学习的性能</h3><ul><li>x-axis is the amount of data （数据量）</li><li>y-axis (vertical axis) is the performance of the algorithm. （算法性能）</li></ul><figure class="image-bubble">                <div class="img-lightbox">                    <div class="overlay"></div>                    <img src="https://d3c33hcgiwev3.cloudfront.net/imageAssetProxy.v1/JP--G3ooEeeJIwrF5BVsIg_b60d752c05bec0881d8ca08cfc2646d2_Screen-Shot-2017-08-05-at-2.30.09-PM.png?expiry=1565481600000&hmac=I-FnXoQoONjGN17_lNuk7vXj7BK4h_mP1txu2K-Y830" alt="数据量与算法性能关系" title>                </div>                <div class="image-caption">数据量与算法性能关系</div>            </figure><ul><li>当数据量比较少时，深度学习方法性能不一定优于经典机器学习方法。</li><li>通过增加数据量和神经网络规模可提升深度学习方法的性能。</li></ul><h3 id="深度学习兴起的原因"><a href="#深度学习兴起的原因" class="headerlink" title="深度学习兴起的原因"></a>深度学习兴起的原因</h3><ul><li>Data：信息化社会产生了巨大的数据量</li><li>Computation：现代计算机计算性能的极大提升（GPU与CPU）</li><li>Algorithms：算法的优化进一步提升了性能（如ReLU的使用）</li></ul>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;AI is the new Electricity. ——吴恩达（&lt;a href=&quot;https://www.coursera.org/instructor/andrewng&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Andrew Ng&lt;/a&gt;）&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;大约在一百年前，社会的电气化改变了每个主要行业。而如今我们见到了 AI令人惊讶的能量会产生同样巨大的转变。显然 AI的各个分支中，发展最为迅速的就是&lt;strong&gt;深度学习&lt;/strong&gt;（deep learning）。而&lt;strong&gt;深度学习&lt;/strong&gt;，一般指的是训练&lt;strong&gt;神经网络&lt;/strong&gt;（有时是非常非常大/深的神经网络）。&lt;/p&gt;
    
    </summary>
    
    
      <category term="学习笔记" scheme="http://yoursite.com/tags/%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/"/>
    
      <category term="deeplearning.ai" scheme="http://yoursite.com/tags/deeplearning-ai/"/>
    
  </entry>
  
</feed>
