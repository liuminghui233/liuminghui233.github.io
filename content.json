{"meta":{"title":"一只程序喵","subtitle":"刘明辉的个人博客","description":null,"author":"刘明辉","url":"http://yoursite.com","root":"/"},"pages":[{"title":"About","date":"2019-08-08T12:10:35.000Z","updated":"2019-08-14T16:22:23.398Z","comments":true,"path":"about/index.html","permalink":"http://yoursite.com/about/index.html","excerpt":"","text":"教育经历2017.9-至今：厦门大学信息学院（计算机科学与技术专业） 2014.9-2017.6：山东省实验中学"},{"title":"","date":"2019-08-08T07:34:55.547Z","updated":"2019-08-08T07:34:55.546Z","comments":false,"path":"categories/index.html","permalink":"http://yoursite.com/categories/index.html","excerpt":"","text":""},{"title":"","date":"2019-08-08T07:34:30.115Z","updated":"2019-08-08T07:34:30.115Z","comments":false,"path":"tags/index.html","permalink":"http://yoursite.com/tags/index.html","excerpt":"","text":""},{"title":"custom","date":"2019-08-08T07:46:19.000Z","updated":"2019-08-08T07:46:19.813Z","comments":true,"path":"custom/index.html","permalink":"http://yoursite.com/custom/index.html","excerpt":"","text":""}],"posts":[{"title":"deeplearning.ai学习笔记（十六）序列模型和注意力机制","slug":"deeplearning-ai学习笔记（十六）序列模型和注意力机制","date":"2019-09-02T08:41:50.000Z","updated":"2019-09-03T07:41:09.557Z","comments":true,"path":"2019/09/02/deeplearning-ai学习笔记（十六）序列模型和注意力机制/","link":"","permalink":"http://yoursite.com/2019/09/02/deeplearning-ai学习笔记（十六）序列模型和注意力机制/","excerpt":"Seq2Seq（Sequence-to-Sequence）模型能够应用于机器翻译、语音识别等各种序列到序列的转换问题。下面介绍其具体形式及应用。 Encoder-Decoder模型一个基本的 Seq2Seq 模型包含编码器（Encoder）和解码器（Decoder）两部分，它们通常是两个不同的 RNN。","text":"Seq2Seq（Sequence-to-Sequence）模型能够应用于机器翻译、语音识别等各种序列到序列的转换问题。下面介绍其具体形式及应用。 Encoder-Decoder模型一个基本的 Seq2Seq 模型包含编码器（Encoder）和解码器（Decoder）两部分，它们通常是两个不同的 RNN。 例1：机器翻译（Machine Translation） 将编码器的输出作为解码器的输入，由解码器负责输出正确的翻译结果。 机器翻译 例2：图像描述（Image Captioning） 图像描述 机器翻译问题基本模型机器翻译模型与语言模型的关系：机器翻译模型可以看成是有条件的语言模型。 机器翻译模型 vs. 语言模型 相似之处：机器翻译模型的decoder network与语言模型相似； 不同之处： 语言模型：自动生成一条完整语句，语句是随机的； 机器翻译模型：encoder network可以看成是语言的a^{\\lt 0 \\gt}，是模型的一个条件，即在输入语句的条件下，生成正确的翻译语句。 机器翻译模型的目标：将输入语句作为条件，找到最佳翻译语句，使条件概率概率最大： arg~max_{y^{},\\cdots,y^{}}~P(y^{},\\cdots,y^{}|x)搜索算法： 贪心搜索（Greedy Search）：根据条件，每次只寻找一个最佳单词作为翻译输出，没有考虑该单词前后关系，概率选择上有可能会出错，不符合要求。 集束搜索（Beam Search） 集束搜索算法算法过程集束搜索会考虑每个时间步多个可能的选择。设定一个集束宽（Beam Width）B，代表了解码器中每个时间步的预选单词数量。 例：B=3，则找出第一个时间步最可能的三个预选单词及其概率值P(\\hat{y}^{⟨1⟩}|x)，然后分别将三个预选词作为第二个时间步的输入，得到P(\\hat{y}^{⟨2⟩}|x,\\hat{y}^{⟨1⟩})。 集束搜索的过程 根据条件概率公式，可以求出： P(\\hat{y}^{⟨1⟩},\\hat{y}^{⟨2⟩}|x)=P(\\hat{y}^{⟨1⟩}|x)P(\\hat{y}^{⟨2⟩}|x,\\hat{y}^{⟨1⟩})以此类推，最后输出一个最优的结果，即结果符合公式： arg~max \\prod_{t=1}^{T_y}P(\\hat{y}^{}|x,\\hat{y}^{},\\cdots,\\hat{y}^{})特别地，当B=1时，集束搜索就变为贪心搜索。 算法改进：长度规范化（Length Normalization）对于以上得到的结果，存在以下两点问题： 对于多个小于 1 的概率值相乘后，会造成数值下溢（Numerical Underflow）； 模型倾向于选择单词数更少的翻译语句，使机器翻译受单词数目的影响。 对于以上问题，对上述乘积形式进行取对数log运算并且进行长度归一化： arg~max \\frac{1}{T_y^\\alpha} \\sum_{t=1}^{T_y}logP(\\hat{y}^{}|x,\\hat{y}^{},\\cdots,\\hat{y}^{})其中： Ty是翻译结果的单词数量； α是超参数归一化因子，α=1时完全进行长度归一化，\\alpha=0时不进行长度归一化，一般令\\alpha=0.7。 超参数B选取 较大的B值意味着可能更好的结果和巨大的计算成本； 较小的B值代表较小的计算成本和可能表现较差的结果。 通常来说，B取一个 10 左右的值。 错误分析 Figures out what faction of errors are “due to” beam search vs. RNN model. 集束搜索是一种启发式搜索算法，其输出结果不总为最优。实际应用中，如果机器翻译效果不好，需要通过错误分析，判断是RNN模型问题还是集束搜索算法问题。 例： Human~translation:Jane~visits~Africa~in~September.(y^*)\\\\ Algorithm~translation:Jane~visits~Africa~lat~September.(\\hat{y}) 将翻译中没有太大差别的前三个单词作为解码器前三个时间步的输入，得到第四个时间步的条件概率P(y^∗|x) $$$$ P(\\hat{y}|x)，比较其大小并分析： 如果P(y^∗|x)>P(\\hat{y}|x)，说明集束搜索算法出现错误，没有选择到概率最大的词； 如果P(y^∗|x)≤P(\\hat{y}|x)，说明RNN模型的效果不佳，预测的第四个词为“in”的概率小于“last”。 建立一个表格，记录对每一个错误的分析统计。 评估指标：BLEU指数（Bilingual Evaluation Understudy Score）将每个单词在人工翻译结果中出现的次数作为分子，在机器翻译结果中出现的次数作为分母。 上述方法是以单个词为单位进行统计，以单个词为单位的集合称为unigram（一元组）。而以成对的词为单位的集合称为bigram（二元组）。对每个二元组，可以统计其在机器翻译结果（count）和人工翻译结果（count_{clip}）出现的次数，计算Bleu指数。 以此类推，以n个单词为单位的集合称为n-gram（多元组），对应的Blue指数计算公式为： p_n=\\frac{\\sum_{n-gram∈\\hat{y}}count_{clip}(n-gram)}{\\sum_{n-gram∈\\hat{y}}count(n-gram)}对N个p_n进行几何加权平均得到： p_{ave}=exp(\\frac{1}{N}\\sum_{i=1}^{N} log^{p_n})当机器翻译结果短于人工翻译结果时，输出的大部分词可能都出现在人工翻译结果中，比较容易能得到更大的精确度分值。 改进的方法是设置一个最佳匹配长度（Best Match Length），如果机器翻译的结果短于该最佳匹配长度，则需要接受简短惩罚（Brevity Penalty，BP）: BP=\\begin{cases} 1 & ,if~MT\\_length \\geq BM\\_length\\\\ exp(1-\\frac{MT\\_length}{BM\\_length}) & ,if~MT\\_length < BM\\_length \\end{cases}因此，Bleu指数的计算公式为： Blue\\_ score=BP × exp(\\frac{1}{N}\\sum_{i=1}^{N} log^{p_n})相关论文：Papineni et. al., 2002. A method for automatic evaluation of machine translation 注意力模型（Attention Model）在机器翻译问题中，如果原语句很长，要对整个语句输入RNN的编码网络和解码网络进行翻译，效果不佳。对待长语句，正确的翻译方法是像人工翻译那样将长语句分段，每次只对长语句的一部分进行翻译。 根据这种“局部聚焦”的思想，建立了注意力模型。 例：在如下的模型中 注意力模型实例 底层是一个双向循环神经网络（BRNN），该网络中每个时间步的激活都包含前向传播和反向传播产生的激活： a^{⟨t^{'}⟩}=(\\stackrel{\\rightarrow}{a}^{⟨t^{'}⟩},\\stackrel{\\leftarrow}{a}^{⟨t^{'}⟩})顶层是一个“多对多”结构的循环神经网络，第t个时间步的输入包含该网络中前一个时间步的激活s^{⟨t−1⟩}、输出y^{⟨t−1⟩}以及底层的 BRNN 中多个时间步的激活c，其中c有： c^{⟨t⟩}=\\sum_{t^{'}}α^{⟨t,t^{'}⟩}a^{⟨t^{'}⟩}其中，参数α^{⟨t,t′⟩}即代表着y^{⟨t⟩}对a^{⟨t^{'}⟩}的“注意力”，有： α⟨t,t^{'}⟩=\\frac{exp(e^{⟨t,t^{'}⟩})}{\\sum^{Tx}_{t^{'}=1}exp(e^{⟨t,t^{'}⟩})},\\sum_{t^{'}}α⟨t,t^{'}⟩=1对于e^{⟨t,t^{'}⟩}，我们通过一个简单的神经网络学习得到。输入为s^{⟨t−1⟩}和a^{⟨t^{'}⟩}，如下图所示： 参数e训练网络 缺点：计算量较大，若输入句子长度为T_x，输出句子长度为T_y，则计算时间约为T_x*T_y。 相关论文： Bahdanau et. al., 2014. Neural machine translation by jointly learning to align and translate Xu et. al., 2015. Show, Attend and Tell: Neural Image Caption Generation with Visual Attention（将注意力模型应用到图像描述中） 语音处理问题语音识别（Speech recognition）问题描述 输入：一段以时间为横轴的音频片段； 输出：文本； 常见预处理步骤：运行音频片段来生成一个声谱图，并将其作为特征； 传统方法：将语音中每个单词分解成多个音素（phoneme）。 注意力模型 语音识别注意力模型 CTC（Connectionist Temporal Classification）损失函数模型由于输入是音频数据，使用 RNN 所建立的系统含有很多个时间步，且输出数量往往小于输入。因此，不是每一个时间步都有对应的输出。CTC 允许 RNN 生成下图红字所示的输出，并将两个空白符（blank）中重复的字符折叠起来，再将空白符去掉，得到最终的输出文本。 语音识别CTC模型 相关论文：Graves et al., 2006. Connectionist Temporal Classification: Labeling unsegmented sequence data with recurrent neural networks 触发词检测（Trigger Word Detection）触发词检测常用于各种智能设备，通过约定的触发词可以语音唤醒设备。 使用 RNN 来实现触发词检测时，可以将触发词对应的序列的标签设置为“1”，而将其他的标签设置为“0”。 触发词检测的RNN模型 但通常训练样本语音中的触发字较非触发字数目少得多，即正负样本分布不均。一种解决办法是在出现一个触发字时，将其附近的RNN都输出1。","categories":[],"tags":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/tags/学习笔记/"},{"name":"deeplearning.ai","slug":"deeplearning-ai","permalink":"http://yoursite.com/tags/deeplearning-ai/"}]},{"title":"deeplearning.ai学习笔记（十五）自然语言处理与词嵌入","slug":"deeplearning-ai学习笔记（十五）自然语言处理与词嵌入","date":"2019-09-01T06:27:57.000Z","updated":"2019-09-03T12:54:05.094Z","comments":true,"path":"2019/09/01/deeplearning-ai学习笔记（十五）自然语言处理与词嵌入/","link":"","permalink":"http://yoursite.com/2019/09/01/deeplearning-ai学习笔记（十五）自然语言处理与词嵌入/","excerpt":"词的表示one-hot向量表示表示方法： 首先建立一个较大的词汇表（例如10000）; 然后使用one-hot的方式对每个单词进行编码。","text":"词的表示one-hot向量表示表示方法： 首先建立一个较大的词汇表（例如10000）; 然后使用one-hot的方式对每个单词进行编码。 例：单词Man、Woman、King、Queen、Apple、Orange分别出现在词汇表的第5391、9853、4914、7157、456、6257的位置，则它们分别用O_{5391}、O_{9853}、O_{4914}、O_{7157}、O_{456}、O_{6257}表示。 缺点：每个单词都是独立的、正交的，无法知道不同单词之间的相似程度。 特征表示法（Featurized representation）使用一个特征向量表征单词，特征向量的每个元素都是对该单词某一特征的量化描述，量化范围可以是[-1,1]之间。 特征表示实例 特征向量的长度依情况而定，特征元素越多则对单词表征得越全面。每个单词用e+词汇表索引的方式标记，例如e_{5391}、e_{9853}、e_{4914}、e_{7157}、e_{456}、e_{6257}。 注：在实际应用中，特征向量很多特征元素并不一定对应到有物理意义的特征，是比较抽象的（使用各种词嵌入算法学到的词向量实际上大多都超出了人类的理解范围，难以从某个值中看出与语义的相关程度）。 词嵌入（word embeddings）概念词嵌入，即特征化单词的操作。 每个单词都由高维特征向量表征，为了可视化不同单词之间的相似性，可以使用降维操作，例如t-SNE算法。如下图所示： 降维可视化 从上图可以看出相似的单词分布距离较近，从而也证明了词嵌入能有效表征单词的关键特征。 词嵌入矩阵假设某个词汇库包含了10000个单词，每个单词包含的特征维度为300，那么表征所有单词的词嵌入矩阵维度为300 x 10000，用E表示。某单词w的one-hot向量表示为O_w，维度为10000 x 1，则该单词的特征向量表达式为： e_w=E·O_w因此，只要知道了词嵌入矩阵，就能计算出所有单词的特征向量。 注：这种矩阵乘积运算效率并不高。通常做法是直接从E中选取第w列作为e_w即可。 词嵌入与迁移学习将单词用不同的特征来表示，即使是训练样本中没有的单词，也可以根据词嵌入的结果得到与其词性相近的单词，从而得到与该单词相近的结果，有效减少了训练样本的数量。 用词嵌入做迁移学习步骤如下： 从大量的文本集中学习词嵌入，或者下载网上开源的、预训练好的词嵌入模型； 将这些词嵌入模型迁移到新的、只有少量标注训练集的任务中； 使用新数据微调词嵌入。（当标记数据集不是很大时可以省下这一步） 词嵌入与类比推理词嵌入可用于类比推理。例如，给定对应关系“男性（Man）”对“女性（Woman）”，想要类比出“国王（King）”对应的词汇。则可以有e_{man}−e_{woman}≈e_{king}−e_?，之后的目标就是找到词向量w，来找到使相似度sim(e_w,e_{king}−e_{man}+e_{woman})最大。 一个最常用的相似度计算函数是余弦相似度（cosine similarity）。公式为： sim(u,v)=\\frac{u^Tv}{||u||_2||v||_w}相关论文：Mikolov et. al., 2013, Linguistic regularities in continuous space word representations 词嵌入学习算法 词的语义由其上下文决定（A word is characterized by thecompany it keeps.） 学习目标：词嵌入矩阵E 神经概率语言模型（Neural Probabilistic Language Model） 神经概率语言模型 训练过程中，将语料库中的某些词作为目标词，以目标词的部分上下文作为输入，Softmax 输出的预测结果为目标词，正确的输出label是“juice”。嵌入矩阵 E 和 w、b 为需要通过训练得到的参数。 为了让神经网络输入层数目固定，可以选择只取预测单词的前4个单词作为输入，例如该句中只选择“a glass of orange”四个单词作为输入。 把输入叫做context，输出叫做target。对应到上面这句话里： context: a glass of orange target: juice context的选择方法： target前n个单词或后n个单词，n可调 target前1个单词 target附近某1个单词（Skip-Gram） 相关论文：Bengio et. al., 2003, A neural probabilistic language model Word2VecSkip-Gram模型 学习样本： 首先随机选择一个单词作为context，例如“orange”； 然后使用一个宽度为5或10（自定义）的滑动窗，在context附近选择一个单词作为target，可以是“juice”、“glass”、“my”等等。 最终得到了多个context—target对作为监督式学习样本。 训练过程：构建自然语言模型 softmax单元输出： \\hat{y}=\\frac{e^{\\theta_t^{T}·e_c}}{\\sum_{j=1}^{10000}e^{\\theta_j^{T}·e_c}}其中θ为target对应的参数，e_c为context的embedding vector。 Loss Function： L(\\hat{y},y)=-\\sum_{i=1}^{10000}y_i log\\hat{y}_i 缺点：在 Softmax 中，每次计算条件概率时，需要对词典中所有词做求和操作，因此计算量很大。 Skip-Gram模型是Word2Vec的一种，Word2Vec的另外一种模型是CBOW（Continuous Bag of Words），CBOW 模型的工作方式与 Skip-gram 相反，通过采样上下文中的词来预测中间的词。 相关论文：Mikolov et. al., 2013. Efficient estimation of word representations in vector space. 降低计算量的方法分层Softmax分类器（Hierarchical Softmax Classifier） 分层Softmax分类器 这种分类器是一种二分类器，它在每个数节点上对目标单词进行区间判断，最终定位到目标单词。 实际应用中常用哈夫曼树，把比较常用的单词放在树的顶层，而把不常用的单词放在树的底层，以提高搜索速度。 负采样模型 负采样模型 如上图所示，当输入的词为一对上下文-目标词时，标签设置为 1。另外任意取 k 对非上下文-目标词作为负样本，标签设置为 0。对于小数据集，k 取 520 较为合适；而当有大量数据时，k 可以取 25。 改用多个 Sigmoid 输出上下文-目标词（c, t）为正样本的概率： P(y=1|c,t)=\\sigma(\\theta_t^T e_c)其中，θ_t、e_c分别代表目标词和上下文的词向量。 之前训练中每次要更新 n 维的多分类 Softmax 单元（n 为词典中词的数量）。现在每次只需要更新 k+1 维的二分类 Sigmoid 单元，计算量大大降低。 关于计算选择某个词作为负样本的概率，作者推荐采用以下公式（而非经验频率或均匀分布）： p(w_i)=\\frac{f(w_i)^{\\frac{3}{4}}}{\\sum_{j=0}^{m} f(w_j)^{\\frac{3}{4}}}其中，f(w_i)代表语料库中单词w_i出现的频率。上述公式更加平滑，能够增加低频词的选取可能。 相关论文：Mikolov et. al., 2013. Distributed representation of words and phrases and their compositionality GloVe（Global Vectors）Glove模型基于语料库统计了词共现矩阵X，X中的元素X_{ij}表示单词i和单词j“为上下文-目标词”的次数。之后，用梯度下降法最小化以下损失函数： J=\\sum_{i=1}^{N} \\sum_{j=1}^{N} f(X_{ij}) (\\theta_i^t e_j +b_i+b_j^{'}-logX_{ij})^2其中： \\theta_i$$、$$e_j$$是单词$$i$$和单词$$j$$的词向量，是对称的，最终的词向量表示为：e_w = \\frac{e_w+\\theta_w}{2}$$ 权重因子f()是一个用来避免X_{ij}=0时log(X_{ij})为负无穷大、并在其他情况下调整权重的函数；当X_{ij}=0时，f(X_{ij})=0忽略了无任何相关性的context和target； b_i、b_j是偏移量。 相关论文：Pennington st. al., 2014. Glove: Global Vectors for Word Representation 词嵌入应用实例情感分类（Sentiment Classification）问题描述情感分类是指分析一段文本对某个对象的情感是正面的还是负面的。 数据集： 情感分析数据 情感分类问题难点是缺少足够多的训练样本，而词嵌入可以帮助解决训练样本不足的问题。 简单模型 情感分类简单模型 缺点：使用平均法，没有考虑句子中单词出现的次序，忽略其位置信息。而有时候，不同单词出现的次序直接决定了句意（如“Completely lacking in good taste, good service, and good ambience.”）。 RNN模型（many-to-one） RNN模型 词嵌入除偏（Debiasing word embeddings）词嵌入的结果中存在一些性别、宗教、种族等偏见或者歧视。如： Man: Computer programmer as Woman: Homemaker Father: Doctor as Mother: Nurse 词嵌入除偏的步骤：以性别歧视为例 确定偏见方向：对所有性别对立的单词求差值，再平均。 bias~direction = \\frac{1}{N} ((e_{he}-e_{she})+(e_{mela}-e_{fmela})+\\cdots) 中立化（Neutralize）本身与性别无关词汇：将要除偏的词向量在与性别相关的方向g上的值置为0。 均衡化（Equalization）本身与性别有关词汇：确保一对词（如actor&amp;actress）到g和g_⊥的距离相等。 相关论文：Bolukbasi et. al., 2016. Man is to computer programmer as woman is to homemaker? Debiasing word embeddings","categories":[],"tags":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/tags/学习笔记/"},{"name":"deeplearning.ai","slug":"deeplearning-ai","permalink":"http://yoursite.com/tags/deeplearning-ai/"}]},{"title":"deeplearning.ai学习笔记（十四）循环神经网络（Recurrent Neural Network）","slug":"deeplearning-ai学习笔记（十四）循环神经网络","date":"2019-08-31T05:18:21.000Z","updated":"2019-09-02T18:17:51.473Z","comments":true,"path":"2019/08/31/deeplearning-ai学习笔记（十四）循环神经网络/","link":"","permalink":"http://yoursite.com/2019/08/31/deeplearning-ai学习笔记（十四）循环神经网络/","excerpt":"序列模型（Sequence Model）概念前后相互关联的数据，如自然语言、音频等。 主要应用： 序列模型的主要应用 符号表示对于一个序列数据x，用x^{⟨t⟩}来表示这个数据中的第t个元素，用来表y^{⟨t⟩}示第t个标签，用T_x和T_y来表示输入和输出的长度。对于一段音频，元素可能是其中的几帧；对于一句话，元素可能是一到多个单词。","text":"序列模型（Sequence Model）概念前后相互关联的数据，如自然语言、音频等。 主要应用： 序列模型的主要应用 符号表示对于一个序列数据x，用x^{⟨t⟩}来表示这个数据中的第t个元素，用来表y^{⟨t⟩}示第t个标签，用T_x和T_y来表示输入和输出的长度。对于一段音频，元素可能是其中的几帧；对于一句话，元素可能是一到多个单词。 第i个序列数据的第t个元素用符号x^{(i)⟨t⟩}，第t个标签即为y^{(i)⟨t⟩}，对应有T^{(i)}_x和T^{(i)}_y。 词向量：one-hot向量要表示一个词语： 先建立一个词汇表（Vocabulary）/字典（Dictionary），将需要表示的所有词语变为一个列向量，可以根据字母顺序排列；（例如一个包含10000个词的词汇表，可看成是10000 x 1的向量） 根据单词在向量中的位置，用 one-hot 向量（one-hot vector）来表示该单词的标签：将每个单词编码成一个R^{|V|×1}向量，其中|V|是词汇表中单词的数量。一个单词在词汇表中的索引在该向量对应的元素为1，其余元素均为0。 标准神经网络在序列模型上存在的问题 对于不同的示例，输入和输出可能有不同的长度，因此输入层和输出层的神经元数量无法固定。 从输入文本的不同位置学到的同一特征无法共享。 模型中的参数太多，计算量太大。 为了解决这些问题，引入循环神经网络（Recurrent Neural Network，RNN）。 基本循环神经网络基本结构例：人名识别 基本RNN模型（Tx=Ty） 当元素x^{⟨t⟩}输入对应时间步（Time Step）的隐藏层的同时，该隐藏层也会接收来自上一时间步的隐藏层的激活值a^{⟨t−1⟩}，其中a^{⟨0⟩}一般直接初始化为零向量。一个时间步输出一个对应的预测结果y^{⟨t⟩}。 循环神经网络从左向右扫描数据，每个时间步的参数是共享的，输入、激活、输出的参数对应为 Wax、Waa、Wya。 基本RNN单元前向传播 基本RNN单元前向传播 前向传播的公式如下： a^{}=\\stackrel{\\rightarrow}{0} \\\\ a^{}=g_1(W_{aa}a^{}+W_{ax}x^{}+b_a)\\\\ \\hat{y}=g_2(W_{ya}a^{}+b_y)激活函数g1通常选择tanh，有时也用ReLU；g2可选 sigmoid 或 softmax，取决于需要的输出类型。 为了进一步简化公式以方便运算，可以将Waa、Wax水平并列为一个矩阵Wa，同时a^{⟨t−1⟩}和x^{⟨t⟩}堆叠成一个矩阵。则有： W_a=[W_{aa}|W_{ax}]\\\\ a^{}=g_1(W_{a}[a^{},x^{}]+b_a)\\\\ \\hat{y}=g_2(W_{y}a^{}+b_y)代价函数对于人名识别，可用交叉熵做为损失函数： L^{}(\\hat{y}^{},y^{})=-y^{}log\\hat{y}^{}-(1-y^{})log(1-\\hat{y}^{})\\\\ J=L(\\hat{y},y)=\\sum_{t=1}^{T_x}L^{}(\\hat{y}^{},y^{})反向传播循环神经网络的反向传播被称为基于时间的反向传播（Backpropagation through time），因为从右向左计算的过程就像是时间倒流。 基本RNN单元反向传播 循环神经网络的架构根据Tx与Ty的关系，RNN模型包含以下几个类型： Many to one：T_x \\gt 1,T_y=1，如情绪判断 One to many：T_x=1,T_y \\gt 1，如音乐生成 One to one：T_x=1,T_y=1 Many to many：T_x=T_y，如人名检测 Many to many：T_x\\neq T_y，如机器翻译 循环神经网络的架构 实例：语言模型（Language Model）概念语言模型是根据语言客观事实而进行的语言抽象数学建模，能够估计某个序列中各元素出现的可能性。例如，在一个语音识别系统中，语言模型能够计算两个读音相近的句子为正确结果的概率，以此为依据作出准确判断。 建立与训练建立训练集：大型语料库（Corpus），指数量众多的句子组成的文本。 标记化（Tokenize），即建立字典； 将语料库中的每个词表示为对应的 one-hot 向量。 注： 增加一个额外的标记EOS（End of Sentence）来表示一个句子的结尾。 标点符号可以忽略，也可以加入字典后用one-hot向量表示。 对于语料库中部分特殊的、不包含在字典中的词汇，例如人名、地名，可在词典中加入一个 UNK（Unique Token）标记来表示。 将标志化后的训练集用于训练 RNN： 语言模型训练过程 在第一个时间步中，输入的a^{⟨0⟩}和x^{⟨1⟩}都是零向量，y^{⟨1⟩}是通过softmax预测出的字典中每个词作为第一个词出现的概率； 在第二个时间步中，输入的x^{⟨2⟩}是训练样本的标签中的第一个单词y^{⟨1⟩}（即“cats”）和上一层的激活项a^{⟨1⟩}，输出的y^{⟨2⟩}表示的是通过softmax预测出的单词“cats”后面出现字典中的其他每个词的条件概率； 以此类推，最后就可以得到整个句子出现的概率。 定义损失函数与成本函数为： L(\\hat{y}^{},y^{})=-\\sum_{t} y_i^{}log\\hat{y}^{}\\\\ J=\\sum_t L^{}(\\hat{y}^{},y^{})采样（Sampling）在训练好一个语言模型后，可以通过采样（Sample）新的序列来了解这个模型中都学习到了一些什么。 采样 在第一个时间步输入a^{⟨0⟩} 、x^{⟨1⟩}为零向量，输出预测出的字典中每个词作为第一个词出现的概率，根据 softmax 的分布进行随机采样（np.random.choice），将采样得到的y^{⟨1⟩}作为第二个时间步的输入x^{⟨2⟩}。以此类推，直到采样到EOS，最后模型会自动生成一些句子，从这些句子中可以发现模型通过语料库学习到的知识。 RNN的梯度消失与梯度爆炸 RNN的梯度消失：由于梯度消失，在反向传播时网络很难调整靠前的参数，因此基本RNN不擅长捕获长距离的依赖关系。 如：对于下面两个句子，后面的动词单复数形式由前面的名词的单复数形式决定。 The~cat,which~already~ate~a~bunch~of~food,~was~full.\\\\ The~cats,which~already~ate~a~bunch~of~food,~were~full. RNN的梯度爆炸：因为参数会急剧膨胀到数值溢出（可能显示为 NaN），梯度爆炸比较容易发现。可以采用梯度修剪（Gradient Clipping）来解决，即观察梯度向量，如果它大于某个阈值，则缩放梯度向量以保证其不会太大。 相比之下，梯度消失问题更难解决。GRU 和 LSTM 都可以作为缓解梯度消失问题的方案。 高级循环神经网络GRU（Gated Recurrent Units, 门控循环单元）GRU改善了 RNN 的隐藏层，使其可以更好地捕捉深层连接，并改善了梯度消失问题。 GRU单元 GRU 单元有一个新的变量称为c，代表记忆细胞（Memory Cell），其作用是提供记忆的能力，例如记忆前文主语是单数还是复数等信息。在时间t，记忆细胞的值c^{⟨t⟩}等于输出的激活值a^{⟨t⟩}，\\tilde{c}^{⟨t⟩}代表下一个c的候选值。Γ_u代表更新门（Update Gate），用于决定什么时候更新记忆细胞的值。当\\Gamma_u=1时，代表更新；当\\Gamma_u=0时，代表记忆，保留之前的模块输出。 相应表达式为： \\tilde{c}^{⟨t⟩}=tanh(W_c[c^{},x^{}]+b_c)\\\\ \\Gamma _u = \\sigma (W_u[c^{},x^{}]+b_u)\\\\ c^{}=\\Gamma _u * \\tilde{c}^{⟨t⟩} + (1-\\Gamma _u ) *c^{}\\\\ a^{}=c^{}当使用 sigmoid 作为激活函数来得到\\Gamma_u时，\\Gamma_u的值在 0 到 1 的范围内，且大多数时间非常接近于 0 或 1。 因为\\Gamma_u可以很接近 0，因此c^{⟨t⟩}几乎就等于c^{⟨t-1⟩}。在经过很长的序列后，c的值依然被维持，从而实现“记忆”的功能。 以上实际上是简化过的GRU单元，完整的GRU单元添加了一个新的相关门（Relevance Gate）\\Gamma_r，表示\\tilde{c}^{⟨t⟩}和c^{⟨t⟩}的相关性。表达式为： \\tilde{c}^{⟨t⟩}=tanh(W_c[\\Gamma_r*c^{},x^{}]+b_c)\\\\ \\Gamma _u = \\sigma (W_u[c^{},x^{}]+b_u)\\\\ \\Gamma_r = \\sigma (W_r[c^{},x^{}]+b_r)\\\\ c^{}=\\Gamma _u * \\tilde{c}^{⟨t⟩} + (1-\\Gamma _u ) *c^{}\\\\ a^{}=c^{}注：公式中的“*”表示元素相乘，而非矩阵相乘。 相关论文： Cho et al., 2014. On the properties of neural machine translation: Encoder-decoder approaches Chung et al., 2014. Empirical Evaluation of Gated Recurrent Neural Networks on Sequence Modeling LSTM（Long Short Term Memory，长短期记忆）LSTM网络比 GRU 更加灵活和强大，它额外引入了遗忘门（Forget Gate）Γ_f和输出门（Output Gate） Γ_o。其结构图和公式如下： LSTM单元 将多个 LSTM 单元按时间次序连接起来，就得到一个 LSTM 网络。 以上是简化版的 LSTM。在更为常用的版本中，几个门值不仅取决于a^{⟨t−1⟩}和x^{⟨t⟩}，有时也可以偷窥上一个记忆细胞输入的值c^{⟨t−1⟩}，这被称为窥视孔连接（Peephole Connection)。此时c^{⟨t−1⟩}和门值是一对一的。 相关论文：Hochreiter &amp; Schmidhuber 1997. Long short-term memory 双向循环神经网络（Bidirectional RNN，BRNN）单向的循环神经网络在某一时刻的预测结果只能使用之前输入的序列信息。双向循环神经网络可以在序列的任意位置使用之前和之后的数据。其工作原理是增加一个反向循环层，结构如下图所示： BRNN y^{}=g(W_y[\\stackrel{\\rightarrow}{a}^{},\\stackrel{\\leftarrow}{a}^{}]+b_y)这个改进的方法不仅能用于基本的 RNN，也可以用于 GRU 或 LSTM。 缺点：需要完整的序列数据，才能预测任意位置的结果。例如构建语音识别系统，需要等待用户说完并获取整个语音表达，才能处理这段语音并进一步做语音识别。 深度循环神经网络（Deep RNN, DRNN)循环神经网络的每个时间步上也可以包含多个隐藏层，形成深度循环神经网络。结构如下图所示： DRNN a^{[l]}=g(W_a^{[l]}[a^{[l]},a^{[l-1]}]+b_a^{[l]})注：DRNN一般层数较少，3层RNN已经较复杂了。 另外一种Deep RNNs结构是每个输出层上还有一些垂直单元，如下图所示： 含垂直单元的DRNN","categories":[],"tags":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/tags/学习笔记/"},{"name":"deeplearning.ai","slug":"deeplearning-ai","permalink":"http://yoursite.com/tags/deeplearning-ai/"}]},{"title":"deeplearning.ai学习笔记（十三）卷积神经网络应用之人脸识别&神经风格迁移","slug":"deeplearning-ai学习笔记（十三）卷积神经网络应用之人脸识别-神经风格迁移","date":"2019-08-29T03:50:34.000Z","updated":"2019-08-30T09:04:01.084Z","comments":true,"path":"2019/08/29/deeplearning-ai学习笔记（十三）卷积神经网络应用之人脸识别-神经风格迁移/","link":"","permalink":"http://yoursite.com/2019/08/29/deeplearning-ai学习笔记（十三）卷积神经网络应用之人脸识别-神经风格迁移/","excerpt":"人脸识别（Face Recognition）问题描述人脸验证（Face Verification）vs. 人脸识别（Face Recognition） 人脸验证：验证输入的人脸图像是否与某个已知的身份信息对应（一对一）； 人脸识别：验证输入的人脸图像是否与多个已知身份信息中的某一个匹配（一对多）。","text":"人脸识别（Face Recognition）问题描述人脸验证（Face Verification）vs. 人脸识别（Face Recognition） 人脸验证：验证输入的人脸图像是否与某个已知的身份信息对应（一对一）； 人脸识别：验证输入的人脸图像是否与多个已知身份信息中的某一个匹配（一对多）。 难点：单样本（One-Shot）学习只采集某人的一个面部样本，就能快速准确地识别出这个人，即只用一个训练样本来获得准确的预测结果。 学习目标：相似性函数（Similarity function）相似性函数表示两张图片的相似程度，用d(img1,img2)来表示。若d(img1,img2)较小，则表示两张图片相似；若d(img1,img2)较大，则表示两张图片不是同一个人。可以设置一个超参数 τ 作为阈值，作为判断两幅图片是否为同一个人的依据。 if~d(img_1,img_2) \\leq \\tau ,~then~img_1与img_2相同对于人脸识别问题，则只需计算测试图片与数据库中K个目标的相似函数，取其中d(img1,img2)最小的目标为匹配对象。若所有的d(img1,img2)都很大，则表示数据库没有这个人。 孪生网络（Siamese Network）若一张图片经过一般的CNN网络（包括CONV层、POOL层、FC层），最终得到全连接层FC，该FC层可以看成是原始图片的编码，表征了原始图片的关键特征。其中不同图片的CNN网络所有结构和参数都是一样的，这个网络结构我们称之为孪生网络。 孪生网络 建立孪生网络后，两张图片x(1)和x(2)的相似性函数可由各自FC层f(x(1))与f(x(2))之差的范数来表示： d(x^{(1)},x^{(2)})=||f(x^{(1)})-f(x^{(2)})||^2利用梯度下降算法，不断调整网络参数，使得属于同一人的图片之间d(x(1),x(2))很小，而不同人的图片之间d(x(1),x(2))很大。 \\begin{align} &若x^{(i)},x^{(j)}是同一个人，则||f(x^{(1)})-f(x^{(2)})||^2较小\\\\ &若x^{(i)},x^{(j)}不是同一个人，则||f(x^{(1)})-f(x^{(2)})||^2较大\\\\ \\end{align}减少计算量两点技巧： 使用预计算的方式在训练时就将数据库每个模板的编码层输出f(x)保存下来。即无须保存模板图片，只要保存每个模板的f(x)即可； 测试过程中，无须计算模板的孪生网络，只要计算测试图片的孪生网络，得到的f(x(i))直接与存储的模板f(x(j))进行下一步的计算即可。 相关论文：Taigman et al., 2014, DeepFace closing the gap to human level performance 三元组损失函数（Triplet Loss）Triplet 损失函数用于训练出合适的参数，以获得高质量的人脸图像编码。 训练样本Triplet Loss需要每个样本包含三张图片：靶目标（Anchor）、正例（Positive）、反例（Negative）。顾名思义，靶目标和正例是同一人，靶目标和反例不是同一人。Anchor和Positive组成一类样本，Anchor和Negative组成另外一类样本。 Triplet样本 训练样本的选取：同一组训练样本，A、P、N的选择尽可能不要使用随机选取方法。因为随机选择的A与P一般比较接近，A与N相差也较大，模型不需要经过复杂训练就能实现这种明显识别，因此学习的特征抓不住关键区别。因此，最好人为选择A与P相差较大，A与N相差较小的图片做为样本。这种人为地增加难度和混淆度会让模型本身去学习不同人脸之间关键的差异特征。 Triplet 损失函数对于A、P、N，应满足： ||f(A)-f(P)||^2 \\leq ||f(A)-f(N)||^2~即~||f(A)-f(P)||^2-||f(A)-f(N)||^2 \\leq 0为避免所有的图片都是零向量时不等式也满足，引入超参数α（间隔，margin），且α&gt;0，则有： ||f(A)-f(P)||^2-||f(A)-f(N)||^2 \\leq -\\alpha ~即~ ||f(A)-f(P)||^2-||f(A)-f(N)||^2 +\\alpha \\leq 0定义Triplet损失函数为： L(A,P,N)=max(||f(A)-f(P)||^2-||f(A)-f(N)||^2+\\alpha,0)对于大小为 m 的训练集，代价函数为： J=\\sum_{i=1}^{m} L(A^{(i)},P^{(i)},N^{(i)})相关论文：Schroff et al., 2015, FaceNet: A unified embedding for face recognition and clustering 二分类结构除了构造triplet loss来解决人脸识别问题之外，还可以使用二分类结构。 做法是将两个siamese网络组合在一起，将各自的编码层输出经过一个逻辑输出单元，该神经元使用sigmoid函数，输出1则表示识别为同一人，输出0则表示识别为不同人。 结构如下： 二分类结构 Sigmoid 单元对应的表达式为： \\hat{y}=\\sigma(\\sum_{k-1}^{K}w_k|f(x^{(i)})_k-f(x^{(j)})_k|+b)其中，wk 和 b 都是通过梯度下降算法迭代训练得到的参数。上述计算表达式也可以用另一种表达式代替： \\hat{y}=\\sigma(\\sum_{k-1}^{K}w_k \\frac{(f(x^{(i)})_k-f(x^{(j)})_k)^2}{f(x^{(i)})_k+f(x^{(j)})_k}+b)上式被称为χ方公式，也叫χ方相似度。 神经风格迁移（Neural Style Transfer）问题描述将一张图片的风格“迁移”到另外一张图片中，生成具有其风格特色的图片。 神经风格迁移 一般用C表示内容图片，S表示风格图片，G表示生成的图片。 神经网络可视化（What are deep ConvNets learning）做法：遍历所有训练样本，找出让该层激活函数输出最大的9块图像区域；然后再找出该层的其它单元（不同的滤波器通道）激活函数输出最大的9块图像区域；共找9次，得到9 x 9的图像，其中每个3 x 3区域表示一个运算单元。 神经网络可视化 可以看出，第一层隐藏层一般检测的是原始图像的边缘和颜色阴影等简单信息。随着层数的增加，捕捉的区域更大，特征更加复杂，从边缘到纹理再到具体物体。 算法过程 随机生成图片 G 的所有像素点； 使用梯度下降算法使代价函数最小化，以不断修正 G 的所有像素点，从而使G逐渐有C的内容和S的风格。 神经风格迁移训练过程 相关论文：Gatys al., 2015. A neural algorithm of artistic style 代价函数定义代价函数由两部分组成：C与G的相似程度和S与G的相似程度。 J(G)=\\alpha J_{content}(C,G)+\\beta J_{style}(S,G)其中，α,β是超参数，用来调整J(C,G)与J(S,G)的相对比重。 内容代价函数（Content Cost Function）J(C,G) 的定义与计算过程如下： 使用一个预训练好的 CNN（例如 VGG）； 选择一个隐藏层 l 来计算内容代价函数。l 太小则内容图片和生成图片像素级别相似，l 太大则可能只有具体物体级别的相似。因此，一般选一个中间层； 设a(C)[l]、a(G)[l]为C和G在l层的激活，则有： J_{content}(C,G)=\\frac{1}{2}||a^{(C)[l]}-a^{(G)[l]}||^2C和G越相似，则J(C,G)越小。​ C和G越相似，则J(C,G)越小。 风格代价函数（Style Cost Function）利用CNN网络模型，图片的风格可以定义成第l层隐藏层不同通道间激活函数的乘积（相关性）。 理解CNN中的风格 例：红色通道提取的是图片的垂直纹理特征，黄色通道提取的是图片的橙色背景特征。计算这两个通道的相关性大小，相关性越大，表示原始图片同时包含垂直纹理与橙色背景；相关性越小，表示原始图片并没有同时包含这两个特征。 Gram矩阵 对于风格图像 S，选定网络中的第 l层，则相关系数以一个Gram矩阵的形式表示： G_{kk'}^{[l](S)}=\\sum_{i=1}^{a_H^{[l]}} \\sum_{j=1}^{a_W^{[l]}} a_{ijk}^{[l](S)} a_{ijk'}^{[l](S)}其中，i和j为第l层的高度和宽度；k和k′为选定的通道，其范围为1到 nC[l]。 同理，对于生成图像 G，有： G_{kk'}^{[l](G)}=\\sum_{i=1}^{a_H^{[l]}} \\sum_{j=1}^{a_W^{[l]}} a_{ijk}^{[l](G)} a_{ijk'}^{[l](G)}因此，第 ll 层的风格代价函数为： J_{style}^{[l]}(S,G)=\\frac{1}{(2n_H^{[l]}n_W^{[l]}n_C^{[l]})^2} \\sum_k \\sum_{k'} (G_{kk'}^{[l](S)} - G_{kk'}^{[l](G)})^2对各层都使用风格代价函数，有： J_{style}(S,G)=\\sum_l \\lambda ^{[l]} J_{style}^{[l]}(S,G)其中，λ是用于设置不同层所占权重的超参数。","categories":[],"tags":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/tags/学习笔记/"},{"name":"deeplearning.ai","slug":"deeplearning-ai","permalink":"http://yoursite.com/tags/deeplearning-ai/"}]},{"title":"deeplearning.ai学习笔记（十二）卷积神经网络应用之目标识别","slug":"deeplearning-ai学习笔记（十二）卷积神经网络应用之目标识别","date":"2019-08-28T03:48:16.000Z","updated":"2019-08-30T09:03:44.920Z","comments":true,"path":"2019/08/28/deeplearning-ai学习笔记（十二）卷积神经网络应用之目标识别/","link":"","permalink":"http://yoursite.com/2019/08/28/deeplearning-ai学习笔记（十二）卷积神经网络应用之目标识别/","excerpt":"问题描述 图片分类问题：判断图片中物体的种类； 定位分类问题：不仅要求判断出图片中物体的种类，还要在图片中标记出它的具体位置，用边框（Bounding Box）把物体圈起来（一般来说，定位分类问题通常只有一个较大的对象位于图片中间位置）； 目标识别问题：图片可以含有多个对象，甚至单张图片中会有多个不同分类的对象。","text":"问题描述 图片分类问题：判断图片中物体的种类； 定位分类问题：不仅要求判断出图片中物体的种类，还要在图片中标记出它的具体位置，用边框（Bounding Box）把物体圈起来（一般来说，定位分类问题通常只有一个较大的对象位于图片中间位置）； 目标识别问题：图片可以含有多个对象，甚至单张图片中会有多个不同分类的对象。 各类问题对比 目标标签为了定位图片中汽车的位置，可以让神经网络多输出 4 个数字—— bx、by、bh、bw。将图片左上角记为 (0, 0)，右下角记为 (1, 1)，则有： 红色方框的中心点：(bx，by) 边界框的高度：bh 边界框的宽度：bw 定义目标标签y如下： 目标标签定义 其中cn表示第n类目标存在的概率；如果Pc=0，表示没有检测到目标，则并不关心输出标签后面的 7 个维度的取值。 损失函数常用平方误差： L(\\hat{y},y)=\\begin{cases} (\\hat{y_1}-y_1)^2+(\\hat{y_2}-y_2)^2+\\cdots +(\\hat{y_8}-y_8)^2 & ,if~p_c=1（即y_1=1）\\\\ (\\hat{y_1}-y_1)^2 & ,if~p_c=0（即y_1=0） \\end{cases}除了使用平方误差，也可以使用逻辑回归损失函数，类标签c1、c2、c3 也可以通过 softmax 输出。相比较而言，平方误差已经能够取得比较好的效果。 评价指标：交并比（IoU, Intersection Over Union）交并比函数用于评价算法，计算预测边框和实际边框交集（I）与并集（U）面积之比： IoU=\\frac{S_I}{S_U}IoU 的值在 0～1 之间，且越接近 1 表示目标的定位越准确。IoU 大于等于 0.5 时，一般可以认为预测边框是正确的（也可以更加严格地定义一个更高的阈值）。 LoU 特征点检测（Landmark Detection）除了使用矩形区域检测目标类别和位置外，我们还可以仅对目标的关键特征点坐标进行定位，这些关键点被称为landmarks。 例：人脸特征检测 人脸特征点检测 滑动窗口目标检测算法基本思想该算法的步骤如下： 训练集上搜集相应的各种目标图片和非目标图片，样本图片要求尺寸较小，相应目标居于图片中心位置并基本占据整张图片。 使用训练集构建 CNN 模型，使得模型有较高的识别率。 选择大小适宜的窗口与合适的固定步幅，对测试图片进行从左到右、从上倒下的滑动遍历。每个窗口区域使用已经训练好的 CNN 模型进行识别判断。 可以选择更大的窗口，然后重复第三步的操作。 滑动窗口算法 优点：原理简单 缺点： 滑动窗的大小和步进长度都需要人为直观设定。滑动窗过小或过大，步进长度过大均会降低目标检测正确率。 每次滑动窗区域都要进行一次CNN网络计算，如果滑动窗和步进长度较小，整个目标检测的算法运行时间会很长。 卷积实现滑动窗算法可以使用卷积方式实现，以提高运行速度，节约重复运算成本。 首先，将全连接层换成卷积层，即使用与上一层尺寸一致的滤波器进行卷积运算。 不需要将输入图片分割成多个子集，分别执行向前传播，而是将它们作为一张图片输入给卷积网络进行一次 CNN 正向计算。这样，公共区域的计算可以共享，以降低运算成本。 滑动窗算法卷积实现 相关论文：Sermanet et al., 2014. OverFeat: Integrated Recognition, Localization and Detection using Convolutional Networks YOLO算法滑动窗口算法有时会出现边框的位置可能无法完美覆盖目标，或者大小不合适，或者最准确的边框并非正方形，而是长方形等问题。 YOLO（You Only Look Once）算法可以用于得到更精确的边框。 基本思想YOLO算法首先将原始图片分割成nxn网格，每个网格代表一块区域。如果目标中心坐标(b_x,b_y)不在当前网格内，则当前网格Pc=0；相反，则当前网格Pc=1（即只看中心坐标是否在当前网格内）。 YOLO算法 注：当前网格左上角坐标设定为(0, 0)，右下角坐标设定为(1, 1)，(b_x,b_y)范围限定在[0,1]之间。由于目标可能超出该网格，故b_h、b_w可以大于1。 YOLO 算法的优点： 显式输出边框坐标和大小，不会受到滑窗分类器的步长大小限制； 只进行一次 CNN 正向计算，效率很高，甚至可以达到实时识别。 非极大抑制（Non-max Suppression）YOLO 算法中，可能出现多个网格检测到同一目标。非极大值抑制（Non-max Suppression）会通过清理检测结果，找到每个目标中点所位于的网格，确保算法对每个目标只检测一次。 非极大抑制 过程如下： 将包含目标中心坐标的可信度 Pc 小于阈值（例如 0.6）的网格丢弃； 选取拥有最大 Pc 值的网格； 分别计算该网格和其他所有网格的 IoU，将 IoU 超过预设阈值（如0.5）的网格丢弃； 重复第 2~3 步，直到不存在未处理的网格。 上述步骤适用于单类别目标检测。进行多个类别目标检测时，对于每个类别，应该单独做一次非极大值抑制。 Anchor Box对于多个目标重叠的情况，需要使用不同形状的Anchor Boxes来检测。 例：一个人站在一辆车前面 Anchor Box 为了同时检测两个目标，我们可以设置两个Anchor Boxes，Anchor box 1检测人，Anchor box 2检测车。也就是说，每个网格多加了一层输出。原来的输出维度是 3 x 3 x 8，现在是3 x 3 x 2 x 8（这里的2表示有两个Anchor Boxes）每个Anchor box都有一个Pc值，若两个Pc值均大于某阈值，则检测到了两个目标。 在单目标检测中，图像中的目标被分配给了包含该目标中点的那个网格；引入 Anchor Box 进行多目标检测时，图像中的目标则被分配到了包含该目标中点的那个网格以及具有最高 IoU 值的该网格的 Anchor Box。 Anchor Boxes形状的选择可以通过人为选取，也可以使用其他机器学习算法（如k-means算法）对待检测的所有目标进行形状分类，选择主要形状。 总结：算法过程 将原始图片分割成nxn网格； 对于每一个网格，进行包含两个Anchor Boxes的预测值； 去除概率值低的预测边框； 对于每一类适用非极大抑制产生最终的预测边框。 相关论文：Redmon et al., 2015. You Only Look Once: Unified, Real-Time Object Detection R-CNN算法前面介绍的滑动窗口目标检测算法对一些明显没有目标的区域也进行了扫描，这降低了算法的运行效率。为了解决这个问题，R-CNN（Region CNN，带区域的 CNN）被提出。通过对输入图片运行图像分割算法，在不同的色块上找出候选区域（Region Proposal），就只需要在这些区域上运行分类器。 R-CNN算法 相关论文： R-CNN：Girshik et al., 2013. Rich feature hierarchies for accurate object detection and semantic segmentation Fast R-CNN：Girshik, 2015. Fast R-CNN Faster R-CNN：Ren et al., 2016. Faster R-CNN: Towards real-time object detection with region proposal networks","categories":[],"tags":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/tags/学习笔记/"},{"name":"deeplearning.ai","slug":"deeplearning-ai","permalink":"http://yoursite.com/tags/deeplearning-ai/"}]},{"title":"deeplearning.ai学习笔记（十一）深度卷积网络：实例探究","slug":"deeplearning-ai学习笔记（十一）深度卷积网络：实例探究","date":"2019-08-25T03:39:51.000Z","updated":"2019-08-28T17:56:50.058Z","comments":true,"path":"2019/08/25/deeplearning-ai学习笔记（十一）深度卷积网络：实例探究/","link":"","permalink":"http://yoursite.com/2019/08/25/deeplearning-ai学习笔记（十一）深度卷积网络：实例探究/","excerpt":"经典卷积神经网络LeNet-5 LeNet-5 一个或多个卷积层后面跟着一个池化层的模式至今仍十分常用。 当 LeNet-5模型被提出时，其池化层使用的是平均池化，而且各层激活函数一般选用 Sigmoid 和 tanh。现在，我们可以根据需要，做出改进，使用最大池化并选用 ReLU 作为激活函数。","text":"经典卷积神经网络LeNet-5 LeNet-5 一个或多个卷积层后面跟着一个池化层的模式至今仍十分常用。 当 LeNet-5模型被提出时，其池化层使用的是平均池化，而且各层激活函数一般选用 Sigmoid 和 tanh。现在，我们可以根据需要，做出改进，使用最大池化并选用 ReLU 作为激活函数。 相关论文：LeCun et.al., 1998. Gradient-based learning applied to document recognition AlexNet AlexNet 当用于训练图像和数据集时，AlexNet 能够处理非常相似的基本构造模块，这些模块往往包含大量的隐藏单元或数据。 相关论文：Krizhevsky et al.,2012. ImageNet classification with deep convolutional neural networks VGG-16 VGG-16 VGG-16 网络的“16”指网络中包含 16 个卷积层和全连接层。 超参数较少，只需要专注于构建卷积层。 结构不复杂且规整，在每一组卷积层进行滤波器翻倍操作。 相关论文：Simonvan &amp; Zisserman 2015. Very deep convolutional networks for large-scale image recognition 残差网络（ResNets, Residual Networks）因为存在梯度消失和梯度爆炸问题，网络越深就越难训练。残差网络可以有效解决这个问题。 相关论文：He et al., 2015. Deep residual networks for image recognition 跳跃连接与残差块 跳跃连接与残差块 上图的结构被称为残差块（Residual block）。通过跳跃连接（Skip connections）可以将 a[l]添加到第二个 ReLU 过程中，直接建立 a[l]与 a[l+2]之间的隔层联系。表达式如下： a^{[l+2]}=g(z^{[l+2]}+a^{[l]})=g(W^{[l+2]}a^{[l+1]}+b^{[l+2]}+a^{[l]})注：如果a[l]与a[l+2]的维度不同，需要引入矩阵Ws与a[l]相乘，使得二者的维度相匹配。参数矩阵Ws既可以通过模型训练得到，也可以作为固定值，仅使a[l]截断或者补零。 残差网络残差网络就是将许多残差块堆积在一起，形成一个深度网络。 简单残差网络 CNN中ResNet的典型结构 普通网络（Plain Network）与残差网络性能比较： 两种网络错误率曲线比较 残差网络有效的原因假设有一个大型神经网络，其输入为X，输出为a[l]。给这个神经网络额外增加两层，输出为a[l+2]。将这两层看作一个具有跳远连接的残差块。为了方便说明，假设整个网络中都选用 ReLU 作为激活函数，因此输出的所有激活值都大于等于 0。 残差网络有效的原因 当发生梯度消失时：W[l+2]≈0，b[l+2]≈0，此时有 a^{[l+2]}=g(a^{[l]})=ReLU(a^{[l]})=a^{[l]}变为恒等函数，这两层额外的残差块不会降低网络性能。 当没有发生梯度消失时：训练得到的非线性关系会使得表现效果进一步提高。 1X1卷积（1×1 Convolutions/Networks in Networks）1x1 卷积指滤波器的尺寸为 1x1 。 当通道数为 1 时，1x1 卷积意味着卷积操作等同于乘积操作。 当通道数更多时，1x1 卷积的作用实际上类似全连接层的神经网络结构，从而降低（或升高，取决于滤波器组数）数据的维度。 池化能压缩数据的高度（nH）及宽度（nW），而 1×1 卷积能压缩数据的通道数（nC）。 1X1卷积压缩通道数 相关论文：Lin et al., 2013. Network in network Inception 网络Inception 网络的名字来自电影《盗梦空间（Inception ）》，思想源自台词“We need to do deeper”，意指使神经网络更深。 Inception 与其它只选择单一尺寸和功能的filter不同，Inception Network使用不同尺寸的filters并将CONV和POOL混合起来，将所有功能输出组合拼接，再由神经网络本身去学习参数并选择最好的模块。 Inception 网络的作用：代替人工来确定卷积层中的滤波器尺寸与类型，或者确定是否需要创建卷积层或池化层。 相关论文：Szegedy et al., 2014, Going Deeper with Convolutions Inception 模块 Inception 模块 如图，Inception 网络选用不同尺寸的滤波器进行 Same 卷积，并将卷积和池化得到的输出组合拼接起来，最终让网络自己去学习需要的参数和采用的滤波器组合。 注：为了将所有的输出组合起来，池化层也使用 Same 类型的填充（padding）来池化使得输出的宽高不变，通道数也不变。 降低计算量在提升性能的同时，Inception 网络有着较大的计算成本。 例： Inception网络计算成本 图中有 32 个滤波器，每个滤波器的大小为 5x5x192。输出大小为 28x28x32，所以需要计算 28x28x32 个数字，对于每个数，都要执行 5x5x192 次乘法运算。加法运算次数与乘法运算次数近似相等。因此，可以看作这一层的计算量为 28x28x32x5x5x192 = 1.2亿。 为了解决计算量大的问题，可以引入 1x1 卷积来减少其计算量。 瓶颈层 对于同一个例子，我们使用 1x1 卷积把输入数据从 192 个通道减少到 16 个通道，然后对这个较小层运行 5x5 卷积，得到最终输出。这个 1x1 的卷积层通常被称作瓶颈层（Bottleneck layer）。 改进后的计算量为 28x28x192x16 + 28x28x32x5x5x15 = 1.24 千万，减少了约 90%。 只要合理构建瓶颈层，就可以既显著缩小计算规模，又不会降低网络性能。 Inception 网络结构引入 1x1 卷积后的 Inception 模块： 引入 1x1 卷积后的 Inception 模块 完整的 Inception 网络（GoogLeNet）： GoogLeNet 黑色椭圆圈出 Softmax 的输出层，用来参与特征的计算及结果预测，起到调整并防止发生过拟合的作用。 使用卷积神经网络的实用建议 使用开源实现：很多神经网络复杂细致，并充斥着参数调节的细节问题，因而很难仅通过阅读论文来重现他人的成果。想要搭建一个同样的神经网络，搜索开源实现方案会快很多。 运用迁移学习：在搭建计算机视觉的应用时，相比于从头训练权重，下载别人已经训练好的网络结构的权重，用其做预训练，然后转换到自己的任务上，有助于加速开发。 数据增强（Data Augmentation）：计算机视觉领域的应用都需要大量的数据。当数据不够时，数据增强就有帮助。常用的数据扩增包括镜像翻转、随机裁剪、色彩转换。 镜像翻转 随机裁剪 色彩转换：对图片的 RGB 通道数值进行随意增加或者减少，改变图片色调。PCA 颜色增强指更有针对性地对图片的 RGB 通道进行主成分分析（Principles Components Analysis，PCA），对主要的通道颜色进行增加或减少，可以采用高斯扰动做法来增加有效的样本数量。 研究或者竞赛方面提升神经网络模型性能的方法 集成（Ensembling）：独立地训练几个神经网络，并平均输出它们的输出 Multi-crop at test time：将数据增强应用到测试集，对结果进行平均 注：这些方法计算和内存成本较大，一般不适用于构建实际的生产项目。","categories":[],"tags":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/tags/学习笔记/"},{"name":"deeplearning.ai","slug":"deeplearning-ai","permalink":"http://yoursite.com/tags/deeplearning-ai/"}]},{"title":"华丽转变！从C快速入门C++","slug":"华丽转变！从C快速入门C","date":"2019-08-24T10:21:18.000Z","updated":"2019-08-24T10:24:18.587Z","comments":true,"path":"2019/08/24/华丽转变！从C快速入门C/","link":"","permalink":"http://yoursite.com/2019/08/24/华丽转变！从C快速入门C/","excerpt":"","text":"C++简介C++基本程序框架C++新特性常量定义引用动态内存分配内联函数与函数重载标准模板库STLC++11标准新特性面向对象程序设计*","categories":[],"tags":[{"name":"C/C++","slug":"C-C","permalink":"http://yoursite.com/tags/C-C/"}]},{"title":"deeplearning.ai学习笔记（十）卷积神经网络基础","slug":"deeplearning-ai学习笔记（十）卷积神经网络基础","date":"2019-08-24T05:29:51.000Z","updated":"2019-08-29T09:23:53.308Z","comments":true,"path":"2019/08/24/deeplearning-ai学习笔记（十）卷积神经网络基础/","link":"","permalink":"http://yoursite.com/2019/08/24/deeplearning-ai学习笔记（十）卷积神经网络基础/","excerpt":"计算机视觉（CV, Computer Vision）是深度学习应用的主要方向之一。计算机视觉问题包括以下几类： 图像分类（Image Classification） 目标检测（Object detection） 风格迁移（Neural Style Transfer） 使用传统神经网络处理机器视觉的一个主要问题是输入层维度很大，使得网络权重W非常庞大。这样会造成两个后果： 神经网络结构复杂，数据量相对不足，容易出现过拟合； 所需内存和计算量大。 解决这一问题的方法就是使用卷积神经网络（Convolutional Neural Network, CNN）。","text":"计算机视觉（CV, Computer Vision）是深度学习应用的主要方向之一。计算机视觉问题包括以下几类： 图像分类（Image Classification） 目标检测（Object detection） 风格迁移（Neural Style Transfer） 使用传统神经网络处理机器视觉的一个主要问题是输入层维度很大，使得网络权重W非常庞大。这样会造成两个后果： 神经网络结构复杂，数据量相对不足，容易出现过拟合； 所需内存和计算量大。 解决这一问题的方法就是使用卷积神经网络（Convolutional Neural Network, CNN）。 卷积运算（Convolutions）引例：边缘检测（Edge Detection） 垂直边缘（Vertical Edges）检测和水平边缘（Horizontal Edges）检测 图片的边缘检测可以通过与相应滤波器进行卷积来实现。 卷积运算的求解过程以垂直边缘检测为例，原始图片尺寸为 6x6，其中数值表示灰度，中间的矩阵被称作滤波器（filter），尺寸为 3x3，卷积后得到的图片尺寸为 4x4，得到结果如下： 卷积运算示意图 卷积运算的求解过程：从左到右，由上到下，每次在原始图片矩阵中取与滤波器同等大小的一部分，每一部分中的值与滤波器中的值对应相乘后求和，将结果组成一个矩阵。如果原始图片尺寸为n x n，filter尺寸为f x f，则卷积后的图片尺寸为(n-f+1) x (n-f+1)。 注：滤波器也称卷积核（kernel）。 卷积作用的直观理解以垂直边缘检测为例： 垂直边缘检测（由亮到暗） 垂直边缘检测（由暗到亮） 填充（Padding）一般的卷积运算会造成两个问题： 每次卷积运算后，输出图片的尺寸缩小； 原始图片的边缘像素在计算中作用较小，输出图片丢失边缘信息。 为解决这些问题，可以在进行卷积操作前，对原始图片在边界上进行填充（Padding），以增加矩阵的大小。通常将 0 作为填充值。 Padding 设每个方向扩展像素点数量为 p，则填充后原始图片的大小为 (n+2p)×(n+2p)，滤波器大小保持f×f不变，则输出图片大小为(n+2p−f+1)×(n+2p−f+1)。 由是否进行填充，卷积运算可分为两种： Valid 卷积：不填充，直接卷积。输出结果为(n−f+1)×(n−f+1)； Same 卷积：进行填充，并使得卷积后结果大小与输入一致。此时： p=\\frac{f-1}{2}其中f通常为奇数（滤波器有一个便于表示其所在位置的中心点）。 带步长的卷积（Strided Convolutions）步长（Stride）表示filter在原图片中水平方向和垂直方向每次的步进长度，设置步长可以压缩一部分信息。 带步长的卷积 用s表示stride长度，p表示padding长度，如果原始图片尺寸为n x n，filter尺寸为f x f，则卷积后的图片尺寸为： \\lfloor \\frac{n+2p-f}{2}+1\\rfloor × \\lfloor \\frac{n+2p-f}{2}+1\\rfloor其中取整为向下取整。 三维卷积运算以上都是在二维矩阵（灰度图）上进行卷积运算，下面研究在三维矩阵（RGB图像）上的卷积运算。 三维卷积运算：将每个单通道（R，G，B）与对应的滤波器进行卷积运算求和，然后再将三个通道的和相加，将 27 个乘积的和作为输出图片的一个像素值。 三维卷积运算（单滤波器） 三维卷积运算（多滤波器） 设输入图片的尺寸为n×n×n_c（n_c为通道数），滤波器尺寸为 f×f×n_c，则卷积后的输出图片尺寸为 (n−f+1)×(n−f+1)×n_c′，n_c′为滤波器组的个数。 一维卷积运算 一维卷积举例 卷积神经网络（CNN, Convolutional Neural Networks）单层卷积神经网络单层卷积神经网络的结构 单层卷积神经网络结构 与单纯的卷积运算相比，卷积神经网络的单层结构多了激活函数和偏移量。与标准神经网络相比，滤波器的数值对应着权重 W[l]，卷积运算对应着 W[l]与A[l−1]的乘积运算，所选的激活函数为 ReLU。 注：选定滤波器组后，参数的数目与输入图片的尺寸无关。 总结：卷积神经网络中的符号与计算 符号总结 深度卷积神经网络卷积神经网络中的三种网络层一个典型的卷积神经网络通常包含有三种层：卷积层（Convolution layer）、池化层（Pooling layer）、全连接层（Fully Connected layer）。 卷积层（CONV, Convolutional Layer）以一个简单例子来看： 简单CNN 随着CNN层数增加，n_H、n_W一般逐渐减小，而n_c一般逐渐增大。 池化层（POOL, Pooling Layer）池化层的作用是缩减模型的大小，提高计算速度，同时减小噪声提高所提取特征的稳健性。 采用较多的一种池化过程叫做最大池化（Max Pooling）。将输入拆分成不同的区域，输出的每个元素都是对应区域中元素的最大值，如下图所示： 最大池化 池化过程类似于卷积过程，上图所示的池化过程中相当于使用了一个大小 f=2f=2的滤波器，且池化步长 s=2s=2。卷积过程中的几个计算大小的公式也都适用于池化过程。 特别注意：如果有多个通道，那么就对每个通道分别执行计算过程。（与卷积区别） 最大池化的直观解释：元素值较大可能意味着池化过程之前的卷积过程提取到了某些特定的特征，池化过程中的最大化操作使得只要在一个区域内提取到某个特征，它都会保留在最大池化的输出中。 另一种池化过程是平均池化（Average Pooling），就是从取某个区域的最大值改为求这个区域的平均值： 平均池化 池化过程的特点：有一组超参数，但是并没有参数需要学习。（但仍参与反向传播的计算） 池化过程的超参数包括滤波器的大小f、步长s，以及选用最大池化还是平均池化。（填充 p则很少用到） 若池化过程的输入维度为：n_H×n_W×n_c，则输出维度为： \\lfloor \\frac{n_H-f}{2}+1\\rfloor × \\lfloor \\frac{n_W-f}{2}+1\\rfloor × n_c全连接层（FC, Fully Connected Layer）全连接层即一般的神经网络结构，每一个结点都与上一层的所有结点相连，用来把前边提取到的特征综合起来。 全连接层转变成为卷积层： 全连接层转变成为卷积层 深度卷积神经网络实例以一个简单的数字识别CNN为例 数字识别CNN 其中，CONV层后面紧接一个POOL层，CONV1和POOL1构成第一层，CONV2和POOL2构成第二层。FC3和FC4为全连接层FC，即标准的神经网络结构。最后的输出层为softmax，由10个神经元构成。 整个网络各层的尺寸和参数数量如下表格所示： 各层尺寸和参数数量 卷积在神经网络中有效的原因（Why Convolutions?） 相比标准神经网络，CNN的优势之一就是参数数目要少得多，原因有两个： 参数共享（Parameter sharing）：特征检测如果适用于图片的某个区域，那么它也可能适用于图片的其他区域。即在卷积过程中，不管输入有多大，一个特征探测器（滤波器）就能对整个输入的某一特征进行探测。 稀疏连接（Sparsity of connections）：在每一层中，由于滤波器的尺寸限制，输入和输出之间的连接是稀疏的，每个输出值只取决于输入在局部的一小部分值。 池化过程在卷积后很好地聚合了特征，通过降维来减少运算量。 由于CNN参数数目较小，所需的训练样本就相对较少，从而一定程度上不容易发生过拟合现象。 CNN比较擅长捕捉区域位置偏移。如CNN进行物体检测时，不太受物体所处图片位置的影响，增加检测的准确性和系统的健壮性。","categories":[],"tags":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/tags/学习笔记/"},{"name":"deeplearning.ai","slug":"deeplearning-ai","permalink":"http://yoursite.com/tags/deeplearning-ai/"}]},{"title":"deeplearning.ai学习笔记（九）构建机器学习项目之机器学习策略（下）","slug":"deeplearning-ai学习笔记（九）构建机器学习项目之机器学习策略（下）","date":"2019-08-23T01:35:24.000Z","updated":"2019-08-23T14:54:33.932Z","comments":true,"path":"2019/08/23/deeplearning-ai学习笔记（九）构建机器学习项目之机器学习策略（下）/","link":"","permalink":"http://yoursite.com/2019/08/23/deeplearning-ai学习笔记（九）构建机器学习项目之机器学习策略（下）/","excerpt":"错误分析（Error Analysis）通过人工检查机器学习模型得出的结果中出现的一些错误，有助于深入了解下一步要进行的工作。这个过程被称作错误分析。 分析方法对输出结果中分类错误的样本进行人工分析，建立一个表格来记录每一个分类错误的具体信息。通过统计不同错误标记类型占总数的百分比，发现哪些问题亟待解决，或者提供构思新优化方向的灵感。","text":"错误分析（Error Analysis）通过人工检查机器学习模型得出的结果中出现的一些错误，有助于深入了解下一步要进行的工作。这个过程被称作错误分析。 分析方法对输出结果中分类错误的样本进行人工分析，建立一个表格来记录每一个分类错误的具体信息。通过统计不同错误标记类型占总数的百分比，发现哪些问题亟待解决，或者提供构思新优化方向的灵感。 例： Image Dog Great Cat Blurry Incorrectly labeled Comments … 98 ✓ Labeler missed cat in background 99 ✓ 100 ✓ Drawing of a cat; Not a real cat. % of total 8% 43% 61% 6% 错误标记（incorrectly labeled）问题训练集中： DL algorithms are quite robust to random errors in the training set. 由于深度学习算法对于随机误差的鲁棒性（Robust），只要出错的样本数量较小且分布近似随机，就不必花费时间一一修正。 验证/测试集中： 在进行误差分析时，通过统计人为标记错误所占的百分比，来大致分析这种情况对模型的识别准确率的影响，并比较该比例的大小和其他错误类型的比例，以此判断是否值得去将错误的标记一一进行修正，还是可以忽略。 注：在验证集和测试集上同时使用同样的修正手段，以保证验证集和测试集来自相同的分布。 总结：快速搭建系统并迭代 Build your first system quickly, then iterate. 设置好训练、验证、测试集及衡量指标，确定目标； 快速训练出一个初步的系统，用训练集来拟合参数，用验证集调参，用测试集评估； 通过偏差/方差分析以及错误分析等方法，决定下一步优先处理的方向。 Train set与Dev/Test set分布不一致问题以猫咪识别为例： 训练集：由网络爬取得到，图片比较清晰，而且规模较大（例如 20 万）； 验证/测试集：来自用户手机拍摄，图片比较模糊，且数量较少（例如 1 万）。 分布不一致情况下的数据集划分策略：保证验证/测试集更接近实际应用场景。 例：将 20 万张网络爬取的图片和 5000 张用户上传的图片作为训练集，而将剩下的 5000 张图片一半作验证集，一半作测试集。 分布不一致情况下的偏差/方差分析在可能存在训练集和验证/测试集分布不一致的情况下，再定义一个训练-验证集（Training-dev Set）。训练-验证集和训练集的分布相同（或者是训练集分割出的子集），但是不参与训练过程。 训练集错误率和训练-验证集错误率的差值反映了方差； 训练-验证集错误率和验证集错误率的差值反映了样本分布不一致的问题。 总结：偏差/方差分析 偏差/方差分析 分布不一致问题解决建议 进行错误分析，了解训练集和验证/测试集的具体差异； 尝试将训练数据调整得更像验证集，或者收集更多类似于验证/测试集的数据。（例如：进行人工合成数据，给训练集人工添加背景噪声，合成类似实际场景的声音，即类似验证/测试集。） 迁移学习（Tranfer Learning）迁移学习（Tranfer Learning）是通过将已训练好的神经网络模型的一部分网络结构应用到另一模型，将一个神经网络从某个任务中学到的知识和经验运用到另一个任务中，以显著提高学习任务的性能。 迁移学习的过程 预训练（Pre-Training）：初始W[l], b[l]由之前的模型训练得到。 微调（Fine-Tuning） 若构建新模型的样本数量较少，只训练输出层的权重系数W[L], b[L]，保持其它层所有的权重系数W[l], b[l]不变； 若构建新模型的样本数量足够多，保留网络结构，重新训练所有层的权重系数。 迁移学习 迁移学习可以保留原神经网络的一部分，可以去掉输出层后再增加额外一些神经层。 迁移学习——增加网络层数 迁移学习的适用条件 两个任务有同样的输入（比如都是图像或者都是音频）； 拥有更多数据的任务迁移到数据较少的任务； 某一任务的低层次特征对另一个任务的学习有帮助。 多任务学习（Multi-Task Learning）多任务学习（Multi-Task Learning）使用单个神经网络模型，利用共享表示并行地训练，同时学习多个任务。多任务学习的基本假设是多个任务之间具有相关性，并且任务之间可以利用相关性相互促进。 在实践中，多任务学习的使用频率要远低于迁移学习。计算机视觉领域中的物体识别是一个多任务学习的例子。 多任务学习的输出与代价函数以汽车自动驾驶为例，需要实现的多任务是识别行人、车辆、交通标志和信号灯。如果在输入的图像中检测出车辆和交通标志，则输出的 y 为： y=\\begin{bmatrix} 0 \\\\ 1\\\\ 1\\\\ 0 \\end{bmatrix} 多任务学习实例——汽车自动驾驶 多任务学习 vs. 多分类问题：Softmax 回归的输出向量 y 中只有一个元素为 1；多任务学习的输出向量 y 中可以有多个元素为 1。 多任务学习的适用条件 训练的一组任务可以共用低层次特征； 每个任务的数据量通常比较接近； 能够训练一个足够大的神经网络，以同时做好所有的工作。与为每个任务训练单个神经网络相比，多任务学习神经网络足够大时性能不会差。 端到端深度学习（End-to-end Deep Learning）机器学习分块模型 vs. 端到端深度学习 概念 传统的机器学习分块模型：每一个模块处理一种输入，然后其输出作为下一个模块的输入，构成一条流水线。 端到端深度学习（End-to-end Deep Learning）：只用一个单一的神经网络模型来实现所有的功能，将所有模块混合在一起，只关心输入和输出。 应用情况 若数据量较少，传统机器学习分块模型所构成的流水线效果较好； 若数据量足够大，且训练出的神经网络模型足够复杂，那么端到端深度学习模型的性能会比传统机器学习分块模型更好； 若数据量规模适中，可以使用流水线混合端到端深度学习。 端到端深度学习的优缺点优点： 让数据发挥主导作用：只要有足够多的数据和足够大的神经网络都可以拟合出X到Y的映射，而不需要用人类固有的认知（或者说，成见）来进行分析； 所需手工设计的组件更少，简化设计工作流程。 缺点： 需要大量的数据； 排除了可能有用的人工设计组件。","categories":[],"tags":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/tags/学习笔记/"},{"name":"deeplearning.ai","slug":"deeplearning-ai","permalink":"http://yoursite.com/tags/deeplearning-ai/"}]},{"title":"deeplearning.ai学习笔记（八）构建机器学习项目之机器学习策略（上）","slug":"deeplearning-ai学习笔记（八）构建机器学习项目之机器学习策略（上）","date":"2019-08-22T07:49:48.000Z","updated":"2019-08-22T12:19:11.440Z","comments":true,"path":"2019/08/22/deeplearning-ai学习笔记（八）构建机器学习项目之机器学习策略（上）/","link":"","permalink":"http://yoursite.com/2019/08/22/deeplearning-ai学习笔记（八）构建机器学习项目之机器学习策略（上）/","excerpt":"正交化（Orthogonalization）方法正交化（Orthogonalization）的核心在于每次调整只会影响模型某一方面的性能，而对其他功能没有影响。这种方法有助于更快更有效地进行机器学习模型的调试和优化。 对于机器学习系统，可以大致分成四个独立的目标，且都有其对应的正交化方法：","text":"正交化（Orthogonalization）方法正交化（Orthogonalization）的核心在于每次调整只会影响模型某一方面的性能，而对其他功能没有影响。这种方法有助于更快更有效地进行机器学习模型的调试和优化。 对于机器学习系统，可以大致分成四个独立的目标，且都有其对应的正交化方法： 建立的模型在训练集上表现良好（Fit training set well on cost function）； 训练更复杂的NN 使用更高级的优化算法（如Adam） …… 建立的模型在验证集上表现良好（Fit dev set well on cost function）； 正则化 采用更多训练样本 …… 建立的模型在测试集上表现良好（Fit test set well on cost function）； 使用更多的验证集样本 …… 建立的模型在实际应用中表现良好（Performs well in real world）。 更换验证集 使用新的cost function …… 反例：early stopping——在提升验证集性能的同时降低了训练集的性能，即同时影响两个目标，不具有正交性。 系统评价指标单值评价指标通过设置一个量化的单值评价指标（single-number evaluation metric），可以使我们根据这一指标比较不同超参数对应的模型的优劣，从而选择最优的那个模型。 例：二分类问题中的准确率（Precision）、召回率（Recall）、F1 Score 准确率~P=\\frac{预测为正类的正类数量}{预测为正类的数量}*100\\\\ 召回率~R=\\frac{预测为正类的正类数量}{正类的数量}*100\\\\ F_1=\\frac{2}{\\frac{1}{P}+\\frac{1}{R}}=\\frac{2PR}{P+R}F1 Score 其实就是精准率和召回率的调和平均数（Harmonic Mean）。实际应用中，通常使用综合了精确率和召回率的单值评价指标 F1 Score 来评价模型的好坏。 F1 Score评价（A更优） 除了F1 Score之外，我们还可以使用平均值作为单值评价指标来对模型进行评估。如评价六个模型对不同国家样本的错误率不同，可以计算其平均性能，然后选择平均错误率最小的那个模型。 平均值评价（C更优） 优化指标和满足指标把所有的性能指标都综合在一起，构成单值评价指标是比较困难的。可以把某些性能作为优化指标（Optimizing metic），寻求最优化值；而某些性能作为满足指标（Satisficing metic），满足阈值即可。 例： Optimizing metic vs. Satisficing metic 将Accuracy作为优化指标，将Running time作为满足指标。即给Running time设定一个阈值，在其满足阈值的情况下，选择Accuracy最大的模型。如果设定Running time必须在100ms以内，那么很明显，模型C不满足阈值条件，首先剔除；模型B相比较模型A而言，Accuracy更高，性能更好。 人类表现水平（Human-level performance）人类水平误差 vs. 贝叶斯最优误差 机器学习系统表现水平增长 上图展示了随着时间的推进，机器学习系统和人的表现水平的变化。一般的，当机器学习超过人的表现水平后，它的进步速度逐渐变得缓慢，最终性能无法超过某个理论上限，这个上限被称为贝叶斯最优误差（Bayes Optimal Error）。 一般用人类水平误差（Human-level Error）来代表贝叶斯最优误差（或者简称贝叶斯误差）。对于不同领域的例子，不同人群由于其经验水平不一，错误率也不同。一般来说，我们将表现最好的作为人类水平误差。 总结： 贝叶斯最优误差：理论上可能达到的最优误差； 人类水平误差：贝叶斯最优误差的近似值（尤其对于图像、声音等自然感知问题）。 可避免偏差（Avoidable Bias）可避免偏差（Avoidable Bias）：模型在训练集上的误差与人类表现水平的差值。 可避免偏差低——意味着模型在训练集上的表现很好； 训练集与验证集之间错误率的差值小——意味着模型在验证集与测试集上的表现和训练集同样好。 策略：如果可避免偏差大于训练集与验证集之间错误率的差值，之后的工作就应该专注于减小偏差；反之，就应该专注于减小方差。 注：不同人选择人类水平误差的基准的不同会带来一定的影响。 例如，如果某模型在训练集上的错误率为 0.7%，验证集的错误率为 0.8%。如果选择的人类水平误差为 0.5%，那么偏差（bias）比方差（variance）更加突出；而如果选择的人类水平误差为 0.7%，则方差更加突出。也就是说，根据人类水平误差的不同选择，我们可能因此选择不同的优化操作。 提高模型表现水平 Improving your model performance","categories":[],"tags":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/tags/学习笔记/"},{"name":"deeplearning.ai","slug":"deeplearning-ai","permalink":"http://yoursite.com/tags/deeplearning-ai/"}]},{"title":"deeplearning.ai学习笔记（七）优化深度神经网络之超参数调试、批标准化与深度学习框架","slug":"deeplearning-ai学习笔记（七）优化深度神经网络之超参数调试、批标准化与深度学习框架","date":"2019-08-20T07:00:21.000Z","updated":"2019-08-22T12:18:24.240Z","comments":true,"path":"2019/08/20/deeplearning-ai学习笔记（七）优化深度神经网络之超参数调试、批标准化与深度学习框架/","link":"","permalink":"http://yoursite.com/2019/08/20/deeplearning-ai学习笔记（七）优化深度神经网络之超参数调试、批标准化与深度学习框架/","excerpt":"超参数调试不同超参数的重要性排序第一梯队： 学习率α：最重要 第二梯队： 动量衰减参数β：一般设置为0.9 各隐藏层神经元个数#hidden units 小批量大小mini-batch size 第三梯队： 神经网络层数#layers 学习率衰减率decay_rate 第四梯队： Adam优化算法超参数β1、β2、ε：一般设置为0.9、0.99、10^-8","text":"超参数调试不同超参数的重要性排序第一梯队： 学习率α：最重要 第二梯队： 动量衰减参数β：一般设置为0.9 各隐藏层神经元个数#hidden units 小批量大小mini-batch size 第三梯队： 神经网络层数#layers 学习率衰减率decay_rate 第四梯队： Adam优化算法超参数β1、β2、ε：一般设置为0.9、0.99、10^-8 超参数调试方法均匀取点 vs 随机取点： 均匀取点 vs 随机取点 由于事先很难知道超参数的重要程度，因此选择随机取点来选择更多的值进行更多实验。为了得到更精确的最优参数，我们应该继续对模型表现较好的区域进行由粗到细的采样。 由粗到细采样 超参数调试技巧 选择适当的尺度 均匀随机采样：对于超参数#layers和#hidden units等，取值为正整数，超参数每次变化的尺度都是一致的。 非均匀随机采样：例如学习率α，待调范围是[0.0001, 1]。在实际应用中，最佳的α值可能主要分布在[0.0001, 0.1]之间，而[0.1, 1]范围内α值效果并不好。如果使用均匀随机采样，那么有90%的采样点分布在[0.1, 1]之间，只有10%分布在[0.0001, 0.1]之间。通常的做法是将线性尺度转换为对数尺度，然后再在对数尺度下进行均匀采样。 具体做法：如果线性区间为[a, b]，令m=log(a)，n=log(b)，则对应的log区间为[m,n]。对log区间的[m,n]进行随机均匀采样，然后得到的采样值r，最后反推到线性区间10^r。 12345m = np.log10(a)n = np.log10(b)r = np.random.rand()r = m + (n-m)*rr = np.power(10,r) 深度学习不同的应用领域出现相互交融的现象，某个应用领域的超参数设定有可能通用于另一领域，应该更多地阅读其他研究领域的 paper，跨领域地寻找灵感。 考虑到数据的变化或者服务器的变更等因素，建议每隔几个月重新测试或评估超参数，来获得实时的最佳模型。 根据所拥有的计算资源决定训练模型的方式： Panda（熊猫方式）：受计算能力所限，只能对一个模型进行训练，调试不同的超参数，使得这个模型有最佳的表现； Caviar（鱼子酱方式）：对多个模型同时进行训练，每个模型上调试不同的超参数，根据表现情况，选择最佳的模型。 批标准化（Batch Normalization）批标准化 (Batch Normalization) 是对于神经网络中间隐藏层的输出进行标准化。批标准化可以使神经网络更加鲁棒，对于超参数的选择不再那么敏感，从而可以更容易地训练非常深的网络。 批标准化算法（BN算法）第l层隐藏层的输入就是第l−1层隐藏层的输出A[l−1]。对A[l−1]进行标准化处理，从原理上来说可以提高W[l]和b[l]的训练速度和准确度实际应用中，一般是对Z[l−1]进行标准化处理而不是A[l−1]。 \\mu=\\frac{1}{m}\\sum_{i}z^{(i)}\\\\ \\sigma^2=\\frac{1}{m}\\sum_i(z_i-\\mu)^2\\\\ z_{norm}^{(i)}=\\frac{z_i-\\mu}{\\sqrt{\\sigma^2+\\epsilon}}其中，m 是单个 mini-batch 所包含的样本个数，ϵ 是为了防止分母为零，通常取10^−8。 这样，我们使得所有的输入z(i)均值为 0，方差为 1。但我们不想让隐藏层单元总是含有均值 0 和方差 1，也许隐藏层单元有了不同的分布会更有意义。而且，各隐藏层的输入均值在靠近 0 的区域，即处于激活函数的线性区域，不利于训练非线性神经网络。因此，设置 γ 和 β ，可以让 z~(i)的均值和方差可以为任意值。 \\widetilde{z}^{(i)}=\\gamma z_{norm}^{(i)}+\\beta其中，γ 和 β都是超参数，神经网络通过学习得到。 应用于整个神经网络： BN应用于神经网络 因为标准化处理中包含减去均值的一步，因此 b 实际上没有起到作用，其数值效果交由 β 来实现。因此可以省略 b 或者暂时设置为 0。 批标准化有效的原因（Why does Batch Norm work？） 通过对隐藏层各神经元的输入做类似的标准化处理，提高神经网络训练速度； 可以使前面层的权重变化对后面层造成的影响减小，整体网络更加健壮； 如果实际应用样本和训练样本的数据分布不同（如橘猫图片和黑猫图片），称发生了“Covariate Shift”。这种情况下，一般要对模型进行重新训练。BN减小了 Covariate Shift 所带来的影响，让模型变得更加健壮。 即使输入的值改变了，由于 BN的作用，使得均值和方差保持不变，限制了在前层的参数更新对数值分布的影响程度，因此后层的学习变得更容易一些。BN减少了各层 W 和 b 之间的耦合性，让各层更加独立，实现自我训练学习的效果。 起到微弱的正则化效果。 在每个 mini-batch 而非整个数据集上计算均值和方差，只由这一小部分数据估计得出的均值和方差会有一些噪声，因此最终计算出的z~(i)也有一定噪声。类似于 dropout，这种噪声会使得神经元不会再特别依赖于任何一个输入特征。 BN只有微弱的正则化效果，可以和 dropout 一起使用以获得更强大的正则化效果。但不要将BN作为正则化的手段，而是当作加速学习的方式。 测试时（单个样本）的批标准化对于第 l 层隐藏层，考虑所有 mini-batch 在该隐藏层下的μ[l]和σ2[l]，然后用指数加权平均的方式来预测得到当前单个样本的μ[l]和σ2[l]。 多分类问题（Multi-class classification）对于多分类问题，用C表示种类个数，神经网络中输出层就有C个神经元，即n[L]=C。其中，每个神经元的输出依次对应属于该类的概率，即P(y=c∣x)。为了处理多分类问题，一般使用Softmax回归模型。 激活函数 \\begin{align} & 对于输出层:\\\\ & z^{[L]}=W^{[L]}a^{[L-1]}+b^{[L]}\\\\ &a_i^{[L]}=\\frac{e^{z_i^{[L]}}}{\\sum_{i=1}^{C}e^{z_i^{[L]}}}~~~~(有\\sum_{i=1}^{C}a_i^{[L]}=1)\\\\ &\\hat{y}=a^{[L]}~~~其维度为(C,1) \\end{align}例： 计算实例 损失函数和代价函数定义损失函数为： \\begin{align} &L(\\hat{y},y)=-\\sum_{j=1}^{C}y_jlog\\hat{y}_j\\\\ &当i为样本真实类别时，对于j\\neq i,y_j=0\\\\ &L(\\hat{y},y)=-y_ilog\\hat{y}_i=-log\\hat{y}_i\\\\ \\end{align}m个训练样本的代价函数为： J=\\frac{1}{m}\\sum_{i=1}^{m}L(\\hat{y},y)梯度下降 dZ^{[L]}=A^{[L]}-Y反向传播过程的其他步骤与逻辑回归一致。 深度学习框架深度学习框架的选取原则 易于编程：包括开发和迭代、部署产品； 运行速度：特别是训练大型数据集时； 是否真正开源：不仅需要开源，而且需要良好的管理，能够持续开放所有功能。 TensorFlow基础一个简单的程序框架： 1234567891011121314151617181920212223import numpy as npimport tensorflow as tfcofficients = np.array([[1.],[-10.],[25.]])w = tf.Variable(0,dtype=tf.float32)x = tf.placeholder(tf.float32,[3,1])# Tensorflow 重载了加减乘除符号cost = x[0][0]*w**2 + x[1][0]*w + x[2][0]# 改变下面这行代码，可以换用更好的优化算法train = tf.train.GradientDescentOptimizer(0.01).minimize(cost)init = tf.global_variables_initializer()session = tf.Session()session.run(init)#上面一段代码可以替换为以下：#with tf.Session() as session:# session.run(init)# print(session.run(w))for i in range(1000): session.run(train, feed_dict=(x:coefficients))print(session.run(w)) 运行结果为4.99999，更改 cofficients 的值可以得到不同的结果 w。","categories":[],"tags":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/tags/学习笔记/"},{"name":"deeplearning.ai","slug":"deeplearning-ai","permalink":"http://yoursite.com/tags/deeplearning-ai/"}]},{"title":"deeplearning.ai学习笔记（六）优化深度神经网络之优化算法（Optimization algorithms）","slug":"deeplearning-ai学习笔记（六）优化深度神经网络之优化算法","date":"2019-08-18T08:47:56.000Z","updated":"2019-08-29T08:15:58.991Z","comments":true,"path":"2019/08/18/deeplearning-ai学习笔记（六）优化深度神经网络之优化算法/","link":"","permalink":"http://yoursite.com/2019/08/18/deeplearning-ai学习笔记（六）优化深度神经网络之优化算法/","excerpt":"本节课学习深度神经网络中的一些优化算法，通过使用这些技巧和方法来提高神经网络的训练速度和精度。 小批量梯度下降算法（mini-batch gradient descent）算法思想如果样本数量m很大，如达到百万数量级，由于受到矩阵运算速度的限制，训练速度往往会很慢。因此，把m个训练样本分成若干个子集（mini-batches），然后每次在单一子集上进行神经网络训练。","text":"本节课学习深度神经网络中的一些优化算法，通过使用这些技巧和方法来提高神经网络的训练速度和精度。 小批量梯度下降算法（mini-batch gradient descent）算法思想如果样本数量m很大，如达到百万数量级，由于受到矩阵运算速度的限制，训练速度往往会很慢。因此，把m个训练样本分成若干个子集（mini-batches），然后每次在单一子集上进行神经网络训练。 例：假设总的训练样本个数m=5000000，其维度为(n_x,m)。将其分成5000个子集，每个mini-batch含有1000个样本。我们将每个mini-batch记为X^{t}，其维度为(n_x,1000)。相应的每个mini-batch的输出记为Y^{t}，其维度为(1,1000)，且t=1,2,⋯,5000。 算法过程先将总的训练样本分成T个子集（mini-batches），然后对每个mini-batch进行神经网络训练，包括Forward Propagation，Compute Cost Function，Backward Propagation，循环至T个mini-batch都训练完毕。 \\begin{align} & for~~t=1,\\cdots,T\\\\ &~~~~Forward~Propagation\\\\ &~~~~Compute~Cost~Function\\\\ &~~~~Backward~Propagation\\\\ &~~~~W^{\\{ t \\}}:=W^{\\{ t \\}} - \\alpha \\centerdot dW^{\\{ t \\}}\\\\ &~~~~b^{\\{ t \\}}:=b^{\\{ t \\}} - \\alpha \\centerdot db^{\\{ t \\}}\\\\ \\end{align}经过T次循环之后，所有m个训练样本都进行了梯度下降计算。这个过程称为一个epoch，一个epoch会进行T次梯度下降算法。 注：对于Mini-Batches Gradient Descent，可以进行多次epoch训练；每次epoch最好将总体训练数据重新打乱、重新分成T组mini-batches。 cost曲线： cost曲线比较 出现细微振荡的原因是不同的mini-batch之间是有差异的，但整体的趋势是下降的，最终也能得到较低的cost值。 超参数 mini-batch size 选取考虑两种极端情况： 如果mini-batch size=m，即为Batch gradient descent，只包含一个子集为(X^{1},Y^{1})=(X,Y)。会比较平稳地接近全局最小值，但是因为使用了所有m个样本，每次前进的速度有些慢。 如果mini-batch size=1，即为随机梯度下降（Stachastic gradient descent），每个样本就是一个子集(X^{i},Y^{i})=(x^(i),y^(i))，共有m个子集。每次前进速度很快，但是路线曲折，有较大的振荡，最终会在最小值附近来回波动，难以真正达到最小值处。而且在数值处理上就不能使用向量化的方法来提高运算速度。 两种极端情况下梯度下降图示 正确选取原则： 一般来说，如果总体样本数量m不太大时（如m≤2000），建议直接使用Batch gradient descent。 如果总体样本数量m很大时，建议将样本分成许多mini-batches。mini-batch size不能设置得太大，也不能太小。推荐选取2的幂做为mini-batch size的值（计算机存储数据一般是2的幂，这样设置可以提高运算速度），常用的有64、128、256、512。 适中mini-batch size时的梯度下降 动量梯度下降算法（Gradient descent with momentum）数学基础：指数加权平均（exponentially weighted averages）实例：伦敦市半年内气温整体变化趋势 伦敦市半年内气温散点图 通过移动平均（moving average）的方法来对每天气温进行平滑处理： 设V0=0，做为第0天的气温值。第一天至第t天气温可按如下计算： \\begin{align} &V_1=0.9V_0+0.1 \\theta_1 \\\\ &V_2=0.9V_1+0.1 \\theta_2 = 0.9(0.9V_0+0.1 \\theta_1)+0.1 \\theta_2 = 0.9^2V_0+0.9 \\centerdot 0.1\\theta_1+0.1\\theta_2\\\\ &V_3=0.9V_2+0.1 \\theta_3=0.9(0.9^2V_0+0.9 \\centerdot 0.1\\theta_1+0.1\\theta_2)+0.1 \\theta_3 \\\\ &~~~~= 0.9^3V_0+0.9^2 \\centerdot 0.1\\theta_1+0.9 \\centerdot 0.1\\theta_2+0.1\\theta_3 \\\\ &~~~~~~~~~~~~~\\vdots \\\\ &V_t=0.9V_{t-1}+0.1 \\theta_t=0.9^tV_0+0.9^{t-1}\\centerdot 0.1\\theta_1 + 0.9^{t-2}\\centerdot 0.1\\theta_2 + \\cdots + 0.9\\centerdot 0.1\\theta_{t-1} + 0.1\\theta_t \\end{align}这种滑动平均算法称为指数加权平均。 指数加权平均的一般形式 V_t=\\beta V_{t-1} +(1-\\beta)\\theta_tβ值决定了指数加权平均的天数。 \\begin{align} & 当\\beta\\rightarrow0,N=\\frac{1}{1-\\beta}\\rightarrow \\infty时:\\\\ &~~~~~~ \\beta^{\\frac{1}{1-\\beta}}=(1-\\frac{1}{N})^N=\\frac{1}{e} \\end{align}一般认为衰减到1/e就可以忽略不计了，故指数加权平均的天数的计算公式为： N=\\frac{1}{1-\\beta}β值越大，则指数加权平均的天数越多，平均后的趋势线就越平缓，同时向右平移。下图绿色曲线和黄色曲线分别表示了β=0.98和β=0.5时，指数加权平均的结果。 不同β值指数加权平均的结果 偏差修正（bias correction）当β=0.98时，指数加权平均结果如绿色曲线所示。但是实际上，真实曲线如紫色曲线所示。 真实情况下的指数加权平均结果 由于开始时设置V0=0，所以初始值会相对小一些，直到后面受前面的影响渐渐变小，趋于正常。 偏差修正： V_t:=\\frac{V_t}{1-\\beta^t} 刚开始t比较小，(1−β^t)&lt;1，这样就将Vt修正得更大一些； 随着t增大，(1−β^t)≈1，Vt基本不变。 动量梯度下降算法思想在每次训练时，对梯度进行指数加权平均，然后用得到的梯度值更新权重W和常数项b。 动量梯度下降算法 原始的梯度下降算法如上图蓝色折线所示。在梯度下降过程中，对于W、b之间数值范围差别较大的情况，梯度下降的振荡较大。此时每一点处的梯度只与当前方向有关，产生类似折线的效果，前进缓慢。 如果对梯度进行指数加权平均，这样使当前梯度不仅与当前方向有关，还与之前的方向有关，这样处理让梯度前进方向更加平滑，减少振荡，能够更快地到达最小值处。 动量梯度下降算法过程 \\begin{align} & 初始化:V_{dW}=0,V_{db}=0,\\beta=0.9 \\\\ & On~iteration~t:\\\\ &~~~~~Compute~dW,db~on~the~current~mini-binch\\\\ &~~~~~V_{dW}=\\beta V_{dW}+(1-\\beta)dW\\\\ &~~~~~V_{db}=\\beta V_{db}+(1-\\beta)db\\\\ &~~~~~W:=W-\\alpha V_{dW}\\\\ &~~~~~b:=b-\\alpha V_{db}\\\\ \\end{align}均方根传递优化算法（RMSprop, Root Mean Square prop）算法过程按如下方式更新参数： \\begin{align} &S_W=\\beta S_{dW}+(1-\\beta)dW^2\\\\ &S_b=\\beta S_{db}+(1-\\beta)db^2\\\\ &W:=W-\\alpha \\frac{dW}{\\sqrt{S_w}},b:=b-\\alpha \\frac{db}{\\sqrt{S_b}}\\\\ \\end{align}为了避免RMSprop算法中分母为零，通常可以在分母增加一个极小的常数ε： W:=W-\\alpha \\frac{dW}{\\sqrt{S_w}+\\epsilon},b:=b-\\alpha \\frac{db}{\\sqrt{S_b}+\\epsilon}其中，ε一般取10^−8。 算法原理 RMSprop算法原理 从图中可以看出，梯度下降（蓝色折线）在垂直方向（b）上振荡较大，在水平方向（W）上振荡较小，表示在b方向上梯度较大，即db较大，而在W方向上梯度较小，即dW较小。因此，上述表达式中Sb较大，而SW较小。在更新W和b的表达式中，使得W变化得多一些，b变化得少一些。即加快了W方向的速度，减小了b方向的速度，减小振荡，实现快速梯度下降算法，其梯度下降过程如绿色折线所示。 自适应矩估计优化算法(Adam, Adaptive Moment Estimation)Adam优化算法本质上是将动量算法和RMSprop结合起来。 算法过程 \\begin{align} & 初始化:V_{dW}=0,S_{dW}=0,V_{db}=0,S_{db}=0\\\\ & On~iteration~t:\\\\ &~~~~~Compute~dW,db~on~the~current~mini-binch\\\\ &~~~~~V_{dW}=\\beta_1 V_{dW}+(1-\\beta_1)dW,V_{db}=\\beta_1 V_{db}+(1-\\beta_1)db\\\\ &~~~~~S_{dW}=\\beta_2 S_{dW}+(1-\\beta_2)dW^2,S_{db}=\\beta_2 S_{db}+(1-\\beta_2)db^2\\\\ &~~~~~V_{dW}^{corrected}=\\frac{V_{dW}}{1-\\beta_1^t},V_{db}^{corrected}=\\frac{V_{db}}{1-\\beta_1^t}\\\\ &~~~~~S_{dW}^{corrected}=\\frac{S_{dW}}{1-\\beta_2^t},S_{db}^{corrected}=\\frac{S_{db}}{1-\\beta_2^t}\\\\ &~~~~~W:=W-\\alpha \\frac{V_{dW}^{corrected}}{\\sqrt{S_{dW}^{corrected}}+\\epsilon},b:=b-\\alpha \\frac{V_{db}^{corrected}}{\\sqrt{S_{db}^{corrected}}+\\epsilon}\\\\ \\end{align}超参数选取β1通常设置为0.9，β2通常设置为0.999，ε通常设置为10^-8。(一般不会调整) 学习率衰减（Learning rate decay）算法思想随着迭代次数增加，学习因子α逐渐减小。 学习率衰减时的梯度下降 蓝色折线表示使用恒定的学习因子α，由于每次训练α相同，步进长度不变，在接近最优值处的振荡也大，在最优值附近较大范围内振荡，与最优值距离就比较远。 绿色折线表示使用衰减的α，随着训练次数增加，α逐渐减小，步进长度减小，使得能够在最优值处较小范围内微弱振荡，不断逼近最优值。 学习率衰减的方式 \\begin{align} & 1.~\\alpha = \\frac{1}{1+decay\\_rate*epoch\\_num}\\alpha_0\\\\ & （其中衰减率deacy\\_rate为可调超参数、epoch\\_num为迭代次数）\\\\ &2.~\\alpha = 0.95^{epoch\\_num}\\centerdot \\alpha_0\\\\ &3.~\\alpha = \\frac{k}{\\sqrt{epoch\\_num}} \\centerdot \\alpha_0~~or~~\\frac{k}{\\sqrt{mini-bach\\_number}} \\centerdot \\alpha_0\\\\ &（其中k为可调超参数）\\\\ &4.~设置\\alpha为关于t的离散值，随着t增加，\\alpha呈阶梯式减小。 \\end{align}局部最优(Local Optima)问题 &amp; 停滞区(Plateaus)问题在使用梯度下降算法不断减小cost function时，可能会得到局部最优解（local optima）而不是全局最优解（global optima）。 在神经网络中，局部最优不能理解为如左图形碗状的凹槽，因为大部分梯度为零的点并不是这些凹槽处，而是形如右边所示的马鞍状，称为鞍点（saddle point）。特别是在神经网络中参数很多的情况下，所有参数梯度为零的点很可能是鞍点。 局部最优点 VS 鞍点 类似马鞍状的停滞区（plateaus）会降低神经网络学习速度。停滞区是梯度接近于零的平缓区域，在停滞区上梯度很小，前进缓慢，到达鞍点需要很长时间。到达鞍点后，由于随机扰动，梯度一般能够沿着图中绿色箭头，离开鞍点，继续前进，只是在停滞区上花费了太多时间。 停滞区的梯度下降 总结： 只要选择合理强大的神经网络，一般不太可能陷入局部最优处； 停滞区可能会使梯度下降变慢，降低学习速度。动量梯度下降、RMSprop、Adam算法都能有效解决停滞区下降过慢的问题。","categories":[],"tags":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/tags/学习笔记/"},{"name":"deeplearning.ai","slug":"deeplearning-ai","permalink":"http://yoursite.com/tags/deeplearning-ai/"}]},{"title":"deeplearning.ai学习笔记（五）优化深度神经网络之应用层面的深度学习","slug":"deeplearning-ai学习笔记（五）优化深度神经网络之应用层面的深度学习","date":"2019-08-16T12:03:14.000Z","updated":"2019-08-21T09:47:02.045Z","comments":true,"path":"2019/08/16/deeplearning-ai学习笔记（五）优化深度神经网络之应用层面的深度学习/","link":"","permalink":"http://yoursite.com/2019/08/16/deeplearning-ai学习笔记（五）优化深度神经网络之应用层面的深度学习/","excerpt":"数据集：训练集/开发集/测试集（Train/Dev/Test sets）为实现交叉验证（cross validation），数据集一般会划分为三个部分： 训练集（Train sets）：用于训练算法模型； 开发集（Dev sets）：用于验证不同算法模型的表现情况，从中选择最好的算法模型； 测试集（Test sets）：用于测试最好算法的实际表现（算法的无偏估计）。","text":"数据集：训练集/开发集/测试集（Train/Dev/Test sets）为实现交叉验证（cross validation），数据集一般会划分为三个部分： 训练集（Train sets）：用于训练算法模型； 开发集（Dev sets）：用于验证不同算法模型的表现情况，从中选择最好的算法模型； 测试集（Test sets）：用于测试最好算法的实际表现（算法的无偏估计）。 注：Test sets的目标主要是进行无偏估计。如果不需要无偏估计，也可以没有Test sets，可以通过Train sets训练不同的算法模型，然后分别在Dev sets上进行验证，根据结果选择最好的算法模型。（如果只有Train sets和Dev sets，通常把这里的Dev sets称为Test sets） 比例分配： 样本数量不是很大（如100、1000、10000）：Train sets和Test sets的数量比例为70%/30%；如果有Dev sets，则设置比例为60%/20%/20%。 样本数量很大（如100万）：Dev sets和Test sets大到足以完成其目标即可，对于100万的样本，往往也只需要10000个样本就够了。因此，对于大数据样本，Train/Dev/Test sets的比例可设置为98%/1%/1%或99%/0.5%/0.5%。样本数据量越大，相应的Dev/Test sets的比例可以设置的越低一些。 训练样本和测试样本分布不匹配问题： 训练样本和验证/测试样本可能来自不同的分布。一条经验原则是尽量保证Dev sets和Test sets来自于同一分布。 偏差（Bias）与方差（Variance）偏差、方差与算法的优劣 偏差方差的各种情况 高偏差（欠拟合，underfitting）：算法模型在训练样本和测试样本上的表现相差不大，但都不太好。（如：Train set error为15%，而Dev set error为16%） 高方差（过拟合，overfitting）：算法模型在训练样本上的表现很好，但是在测试样本上的表现却不太好。这说明了该模型泛化能力不强。（如：Train set error为1%，而Dev set error为11%） 低偏差&amp;低方差：最好情况的算法。 高偏差&amp;高方差：可以理解成某段区域是欠拟合的，某段区域是过拟合的，是最差情况的算法。 总结：一般来说，Train set error体现了是否出现high bias；Dev set error与Train set error的相对差值体现了是否出现high variance。 机器学习中算法评价的基本原则 算法评价流程 高偏差和高方差的解决策略对于高偏差： 增加神经网络的隐藏层个数、神经元个数 延长训练时间 选择其它更复杂的神经网络模型 …… 对于高方差： 增加训练样本数据 进行正则化（Regularization） 选择其他更复杂的神经网络模型 …… 正则化（Regularization）L2正则化具体实现对于Logistic regression： J(w,b)=\\frac{1}{m} \\sum_{i=1}^{m}L(\\hat{y}^{(i)},y^{(i)})+\\frac{\\lambda}{2m}||w||_2^{2} \\\\ ||w||_2^{2}=\\sum_{j=1}^{n_x}w_j^{2}=w^{T}w注： 由于W的维度很大，而b只是一个常数，参数很大程度上由W决定，改变b值对整体模型影响较小，所以没有对b进行正则化。 λ——正则化参数，属于超参数的一种。可以设置λ为不同的值，在Dev set中进行验证，选择最佳的λ。 对于深度神经网络： J(w^{[1]},b^{[1]},\\cdots,w^{[L]},b^{[L]})=\\frac{1}{m} \\sum_{i=1}^{m}L(\\hat{y}^{(i)},y^{(i)})+\\frac{\\lambda}{2m}||w^{[l]}||^{2} \\\\ ||w||_F^{2}=\\sum_{i=1}^{n^{[l]}} \\sum_{j=1}^{n^{[l-1]}}(w_{ij}^{[l]})^{2} ~~~~~~~~(Frobenius范数)\\\\ dw^{[l]}=dw_{before}^{[l]}+\\frac{\\lambda}{m}w^{[l]}\\\\ w^{[l]}:=w^{[l]}-\\alpha \\centerdot dw^{[l]}由于加上了正则项，dw[l]有个增量，在更新w[l]的时候，会多减去这个增量，使得w[l]比没有正则项的值要小一些。因此，L2 regularization也被称做权重衰减（weight decay）。 w^{[l]}:=w^{[l]}-\\alpha \\centerdot dw^{[l]}=w^{[l]}-\\alpha \\centerdot (dw_{before}^{[l]}+\\frac{\\lambda}{m}w^{[l]})=(1-\\alpha \\frac{\\lambda}{m})w^{[l]}-\\alpha \\centerdot dw_{before}^{[l]}直观解释（Why regularization reduces overfitting?）假如选择了非常复杂的神经网络模型，在未使用正则化的情况下出现了过拟合。但是，如果使用L2 regularization，当λ很大时，w[l]近似为零，意味着该神经网络模型中的某些神经元实际的作用很小，原本过于复杂的神经网络模型就被简单化了。因此，正则化方法可以减轻过拟合程度。 L1正则化 J(w,b)=\\frac{1}{m} \\sum_{i=1}^{m}L(\\hat{y}^{(i)},y^{(i)})+\\frac{\\lambda}{2m}||w||_1 \\\\ ||w||_1=\\sum_{j=1}^{n_x}|w_j|与L2 regularization相比，L1 regularization得到的w更加稀疏，即很多w为零值。其优点是节约存储空间，因为大部分w为0。然而，实际上L1 regularization在解决high variance方面比L2 regularization并不更具优势。而且，L1的在微分求导方面比较复杂。所以，一般L2 regularization更加常用。 随机失活（Dropout）正则化方法思想随机失活（Dropout）是指在深度学习网络的训练过程中，对于每层的神经元，按照一定的概率将其暂时从网络中丢弃。也就是说，每次训练时，每一层都有部分神经元不工作，起到简化复杂网络模型的效果，从而避免发生过拟合。 注：使用dropout训练结束后，在测试和实际应用模型时，不需要进行dropout 实现方法：反向随机失活（Inverted dropout）假设对于第l层神经元，设定神经元保留概率keep_prob=0.8，即该层有20%的神经元停止工作。dl为随机失活向量，其中80%的元素为1，20%的元素为0。 123dl = np.random.rand(al.shape[0],al.shape[1])&lt;keep_prob //生成随机失活向量al = np.multiply(al,dl) //第l层经过dropout的输出al /= keep_prob //进行缩放（scale up）以尽可能保持al的期望值相比之前没有大的变化，测试时就不需要再对样本数据进行类似的尺度伸缩操作 对于m个样本，单次迭代训练时，随机失活隐藏层一定数量的神经元；然后，在删除后的剩下的神经元上正向和反向更新参数；接着，下一次迭代中，恢复之前失活的神经元，重新随机失活一定数量的神经元，进行正向和反向更新参数；不断重复上述过程，直至迭代训练完成。 其他正则化方法数据增强（Data Augmentation）增加训练样本数量通常成本较高，难以获得额外的训练样本。但可以对已有的训练样本进行一些处理来“制造”出更多的样本。虽然这些是基于原有样本的，但是对增大训练样本数量还是有很有帮助的，不需要增加额外成本，却能起到防止过拟合的效果。 例如： 在图片识别问题中，可以对已有的图片进行水平翻转、垂直翻转、任意角度旋转、缩放或扩大等等。 图片识别中的数据增强 在数字识别问题中，可以将原有的数字图片进行任意旋转或者扭曲，增加一些noise。 数字识别中的数据增强 提前终止（Early Stopping）个神经网络模型随着迭代训练次数增加，train set error一般是单调减小的，而dev set error 先减小，之后又增大。也就是说训练次数过多时，模型会对训练样本拟合的越来越好，但是对验证集拟合效果逐渐变差，即发生了过拟合。因此，迭代训练次数不是越多越好，可以通过train set error和dev set error随迭代次数的变化趋势，选择合适的迭代次数，即early stopping。 随迭代次数的变化趋势 Early Stopping的缺点： 机器学习训练模型有两个目标：一是优化cost function，尽量减小J；二是防止过拟合。通过减少迭代次数来防止过拟合，会使得cost function不会足够小。即将两个目标融合在一起，同时优化，但可能没有“分而治之”的效果好。 Early Stopping vs L2 regularization： 与Early Stopping相比，L2 regularization可以实现“分而治之”的效果，但正则化参数λ的选择比较复杂。对这一点来说，early stopping比较简单。总的来说，L2 regularization更加常用一些。 标准化输入（Normalizing inputs）概念标准化输入就是对训练数据集进行归一化的操作，即将原始数据减去其均值μ后，再除以其方差σ²。 \\mu = \\frac{1}{m} \\sum_{i=1}^{m} X^{(i)}\\\\ \\sigma^{2} = \\frac{1}{m} \\sum_{i=1}^{m}(X^{(i)})^2\\\\ X := \\frac{X-\\mu}{\\sigma^2} 归一化过程 注：由于训练集进行了标准化处理，那么对于测试集或在实际应用时，应该使用同样的\\muμ和σ²对其进行标准化处理。 进行标准化的好处让所有输入归一到同样的尺度上，方便进行梯度下降算法时能够更快更准确地找到全局最优解。 如果不进行标准化处理，x1与x2之间分布极不平衡，训练得到的w1和w2也会在数量级上差别很大。这样导致的结果是cost function与w和b的关系可能是一个非常细长的椭圆形碗。对其进行梯度下降算法时，由于w1和w2数值差异很大，只能选择很小的学习因子α，来避免J发生振荡。一旦α较大，必然发生振荡，J不再单调下降。 如果进行了标准化操作，x1与x2分布均匀，w1和w2数值差别不大，得到的cost function与w和b的关系是类似圆形碗。对其进行梯度下降算法时，α可以选择相对大一些，且J一般不会发生振荡，保证了J是单调下降的。 归一化的好处图示 梯度消失和梯度爆炸（Vanishing and Exploding gradients）概念在梯度函数上出现的以指数级递增或者递减的情况分别称为梯度爆炸或者梯度消失。 假定 g(z)=z,b[l]=0，对于目标输出有： \\hat{y} = (W^{[L]}W^{[L-1]}\\cdots W^{[2]}W^{[1]})X 对于 W[l]的值大于 1 的情况，激活函数的值将以指数级递增（数值爆炸）； 对于 W[l]的值小于 1 的情况，激活函数的值将以指数级递减（数值消失）。 同样，这种情况也会引起梯度呈现同样的指数型增大或减小的变化，引起每次更新的步进长度过大或者过小，这让训练过程十分困难。 改善方法：对权展w进行初始化处理由下式 z = w_1x_1+w_2x_2+\\cdots + w_nx_n+b可知，当输入的数量 n 较大时，我们希望每个wi的值都小一些，这样它们的和得到的 z 也较小。为了得到较小的wi，可进行如下初始化： 若激活函数为sigmod/tanh函数，令其方差为1/n： 1w[l] = np.random.randn(n[l],n[l-1])*np.sqrt(1/n[l-1]) 若激活函数为ReLU函数，令其方差为2/n： 1w[l] = np.random.randn(n[l],n[l-1])*np.sqrt(1/n[l-1]) 另外还有： 1w[l] = np.random.randn(n[l],n[l-1])*np.sqrt(2/n[l-1]*n[l]) 梯度检验（Gradient Checking）检查验证反向传播过程中梯度下降算法是否正确。 梯度的数值近似 梯度近似值求解 函数在θ出的导数近似为： g(\\theta)=\\frac{f(\\theta+\\epsilon)-f(\\theta-\\epsilon)}{2\\epsilon}其中，ε&gt;0，且足够小。 梯度检查的过程 将W[1],b[1],⋯,W[L],b[L]这些矩阵构造成一维向量，然后将这些一维向量组合起来构成一个更大的一维向量θ。这样J(W[1],b[1],⋯,W[L],b[L])就可以表示为J(θ)。 将反向传播过程通过梯度下降算法得到的dW[1],db[1],⋯,dW[L],db[L]按照一样的顺序构造成一个一维向量dθ。dθ的维度与θ一致。 接着利用J(θ)对每个θi计算近似梯度，其值与反向传播算法得到的dθi相比较，检查是否一致。例如，对于第i个元素，近似梯度为： d\\theta_{approx}[i]=\\frac{J(\\theta_1,\\theta_2,\\cdots,\\theta_i+\\epsilon,\\cdots)-J(\\theta_1,\\theta_2,\\cdots,\\theta_i-\\epsilon,\\cdots)}{2\\epsilon} 计算dθapprox与dθ的欧氏距离来比较二者的相似度。公式如下： \\frac{||d\\theta_{approx}-d\\theta||_2}{||d\\theta_{approx}||_2+||d\\theta||_2}一般来说： 如果欧氏距离很小，例如10^−7，甚至更小，则表明反向梯度计算是正确的; 如果欧氏距离较大，例如10^-5，则表明梯度计算可能出现问题，需要再次检查是否有bugs存在; 如果欧氏距离很大，例如10^-3，甚至更大，则表明梯度下降计算过程有bugs，需要仔细检查。 几点注意 不要在整个训练过程中都进行梯度检查，仅仅作为debug使用。 如果梯度检查出现错误，找到对应出错的梯度，检查其推导是否出现错误。 计算近似梯度的时候不能忽略正则项。 梯度检查时关闭dropout，检查完毕后再打开dropout","categories":[],"tags":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/tags/学习笔记/"},{"name":"deeplearning.ai","slug":"deeplearning-ai","permalink":"http://yoursite.com/tags/deeplearning-ai/"}]},{"title":"deeplearning.ai学习笔记（四）深度神经网络（Deep Neural Network）","slug":"deeplearning-ai学习笔记（四）深度神经网络","date":"2019-08-14T14:28:38.000Z","updated":"2019-08-28T17:31:57.383Z","comments":true,"path":"2019/08/14/deeplearning-ai学习笔记（四）深度神经网络/","link":"","permalink":"http://yoursite.com/2019/08/14/deeplearning-ai学习笔记（四）深度神经网络/","excerpt":"深度神经网络其实就是包含更多的隐藏层神经网络。 越来越“深”的神经网络 深度神经网络为何如此有效？（Why deep representations?)神经网络效果显著，其强大能力主要源自神经网络足够“深”，即网络层数越多，神经网络就更加复杂和深入，学习也更加准确。","text":"深度神经网络其实就是包含更多的隐藏层神经网络。 越来越“深”的神经网络 深度神经网络为何如此有效？（Why deep representations?)神经网络效果显著，其强大能力主要源自神经网络足够“深”，即网络层数越多，神经网络就更加复杂和深入，学习也更加准确。 由“浅”到“深”的特征提取以人脸识别为例： 人脸识别的特征提取 经过训练，神经网络第一层所做的事就是从原始图片中提取出人脸的轮廓与边缘，即边缘检测。这样每个神经元得到的是一些边缘信息。神经网络第二层所做的事情就是将前一层的边缘进行组合，组合成人脸一些局部特征，比如眼睛、鼻子、嘴巴等。再往后面，就将这些局部特征组合起来，融合成人脸的模样。 深度网络能减少神经元个数以计算逻辑输出为例 y=x_1 \\oplus x_2 \\oplus \\cdots \\oplus x_n使用深度网络： 每层将前一层的两两单元进行异或，最后到一个输出。整个深度网络的层数是log2(n)，神经元个数为： 1+2+\\cdots+2^{log_2(n)-1}=n-1不使用深度网络： 仅仅使用单个隐藏层，由于包含了所有的逻辑位，需要的神经元个数达到指数级别。 构建深度神经网络前向传播和反向传播流程块图对于第l层来说： 正向传播时： 输入:a^{[l-1]} \\\\ 输出:a^{[l]} \\\\ 参数:W^{[l]},b^{[l]} \\\\ 缓存:z^{[l]}反向传播时： 输入:da^{[l]} \\\\ 输出:da^{[l-1]},dW^{[l]},db^{[l]}\\\\ 参数:W^{[l]},b^{[l]} 第l层流程块图 对于整个神经网络： 神经网络流程块图 前向传播和反向传播计算表达式正向传播 \\begin{cases} z^{[l]}=W^{[l]}a^{[l-1]}+b^{[l]} \\\\ a^{[l]}=g^{[l]}(z^{[l]}) \\end{cases}m个训练样本： \\begin{cases} Z^{[l]}=W^{[l]}A^{[l-1]}+b^{[l]} \\\\ A^{[l]}=g^{[l]}(Z^{[l]}) \\end{cases}反向传播 \\begin{cases} dz^{[l]}=da^{[l]}*g^{[l]'}(z^{[l]}) \\\\ dW^{[l]}=dz^{[l]}\\centerdot a^{[l-1]}\\\\ db^{[l]}=dz^{[l]}\\\\ da^{[l-1]}=W^{[l]T}\\centerdot dz^{[l]}\\\\ \\end{cases}\\\\ 进一步推导可得递推关系:dz^{[l]}=W^{[l+1]T}\\centerdot dz^{[l+1]}*g^{[l]'}(z^{[l]})m个训练样本： \\begin{cases} dZ^{[l]}=dA^{[l]}*g^{[l]'}(Z^{[l]}) \\\\ dW^{[l]}=\\frac{1}{m}dZ^{[l]}\\centerdot A^{[l-1]T}\\\\ db^{[l]}=\\frac{1}{m}np.sum(dZ^{[l]},axis=1,keepdim=True) \\\\ dA^{[l-1]}=W^{[l]T}\\centerdot dZ^{[l]}\\\\ \\end{cases}\\\\ 进一步推导可得递推关系:dZ^{[l]}=W^{[l+1]T}\\centerdot dZ^{[l+1]}*g^{[l]'}(Z^{[l]})注：这里的“*”运算符表示矩阵对应位置相乘。 参数（Parameters） vs 超参数（Hyperparameters） 参数（parameters）：如W[l]、b[l] 超参数（hyperparameters）：学习率α，迭代次数N，神经网络层数L，各层神经元个数n[l]，激活函数g(z)等。它们决定了参数W[l]和b[l]的值，因此称为超参数。 Applied deep learning is a very empirical process. 如何设置最优的超参数是一个比较困难的、需要经验知识的问题。通常的做法是选择超参数一定范围内的值，分别代入神经网络进行训练，测试cost function随着迭代次数增加的变化，根据结果选择cost function最小时对应的超参数值。","categories":[],"tags":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/tags/学习笔记/"},{"name":"deeplearning.ai","slug":"deeplearning-ai","permalink":"http://yoursite.com/tags/deeplearning-ai/"}]},{"title":"deeplearning.ai学习笔记（三）浅层神经网络（Shallow Neural Networks）","slug":"deeplearning-ai学习笔记（三）浅层神经网络","date":"2019-08-12T13:44:29.000Z","updated":"2019-09-02T17:40:58.455Z","comments":true,"path":"2019/08/12/deeplearning-ai学习笔记（三）浅层神经网络/","link":"","permalink":"http://yoursite.com/2019/08/12/deeplearning-ai学习笔记（三）浅层神经网络/","excerpt":"神经网络的表示以一个单隐层神经网络为例： 单隐层神经网络 结构上，从左到右，可以分成三层：输入层（Input layer），隐藏层（Hidden layer）和输出层（Output layer）。输入层和输出层，对应着训练样本的输入和输出。隐藏层是抽象的非线性中间层，中间这一层节点的真实值并没有所观察，这也是其被命名为隐藏层的原因。","text":"神经网络的表示以一个单隐层神经网络为例： 单隐层神经网络 结构上，从左到右，可以分成三层：输入层（Input layer），隐藏层（Hidden layer）和输出层（Output layer）。输入层和输出层，对应着训练样本的输入和输出。隐藏层是抽象的非线性中间层，中间这一层节点的真实值并没有所观察，这也是其被命名为隐藏层的原因。 注：单隐藏层神经网络属于为两层神经网络，输入层不计入。 记法上： 把输入矩阵X记为a[0]，把隐藏层输出记为a[1]，输出层输出记为a[2]（即ŷ）。 用下标表示第几个神经元（下标从1开始）。例如a1[1]表示隐藏层第1个神经元，a2[1]表示隐藏层第2个神经元。隐藏层的输出可以写成矩阵形式： a^{[1]}= \\begin{bmatrix} a_1^{[1]}\\\\ a_2^{[1]}\\\\ a_3^{[1]}\\\\ a_4^{[1]} \\end{bmatrix} 参数 隐藏层参数：权重W[1]，维度是（4,3），4对应着隐藏层神经元个数，3对应着输入层x特征向量包含元素个数。常数项b[1]，维度是（4,1），4同样对应着隐藏层神经元个数。 输出层参数：权重W[2]，维度是（1,4），1对应着输出层神经元个数，4对应着输出层神经元个数。常数项b[2]，维度是（1,1），因为输出只有一个神经元。 总结：第i层的权重W[i]维度的行等于i层神经元的个数，列等于i-1层神经元的个数；第i层常数项b[i]维度的行等于i层神经元的个数，列始终为1。 神经网络的输出（正向传播）单个神经元的输出每个神经元进行两个计算：线性加权（计算z）、非线性激活（计算a）。 逻辑回归单元 z=w^{T}x+b \\\\ a=\\sigma(z)单个样本的神经网络正向传播过程每个节点的计算都对应着一次逻辑运算的过程，分别由计算z和a两部分组成。 单隐层神经网络 非向量化计算过程从输入层到隐藏层： z_1^{[1]}=w_1^{[1]T}x+b_1^{[1]},a_1^{[1]}=\\sigma(z_1^{[1]}) \\\\ z_2^{[1]}=w_2^{[1]T}x+b_2^{[1]},a_2^{[1]}=\\sigma(z_2^{[1]}) \\\\ z_3^{[1]}=w_3^{[1]T}x+b_3^{[1]},a_3^{[1]}=\\sigma(z_3^{[1]}) \\\\ z_4^{[1]}=w_4^{[1]T}x+b_4^{[1]},a_4^{[1]}=\\sigma(z_4^{[1]})从隐藏层到输出层： z_1^{[2]}=w_1^{[2]T}a^{[1]}+b_1^{[2]},a_1^{[2]}=\\sigma(z_1^{[2]})向量化计算过程 z^{[1]}=W^{[1]}x+b^{[1]},a^{[1]}=\\sigma(z^{[1]}) \\\\ z^{[2]}=W^{[2]}a^{[1]}+b^{[2]},a^{[2]}=\\sigma(z^{[2]})m个训练样本的神经网络正向传播过程非向量化计算过程for i=1 to m: z^{[1](i)}=W^{[1]}x^{(i)}+b^{[1]},a^{[1](i)}=\\sigma(z^{[1](i)}) \\\\ z^{[2](i)}=W^{[2]}a^{[1](i)}+b^{[2]},a^{[2](i)}=\\sigma(z^{[2](i)})向量化计算过程 Z^{[1]}=W^{[1]}X+b^{[1]},A^{[1]}=\\sigma(Z^{[1]}) \\\\ Z^{[2]}=W^{[2]}A^{[1]}+b^{[2]},A^{[2]}=\\sigma(Z^{[2]})其中，Z[1]的维度是（4,m），4是隐藏层神经元的个数；A[1]的维度与Z[1]相同；Z[2]和A[2]的维度均为（1,m）。（行表示神经元个数，列表示样本数目m） 激活函数几种常见激活函数sigmoid函数 表达式及图像： 导数： g^{'}(z)=a(1-a) tanh函数 表达式及图像： 导数： g^{'}(z)=1-a^{2} ReLU函数（线性整流函数，Rectified Linear Unit） 表达式及图像： 导数： g^{'}(z)=\\begin{cases} 1 & ,z>0 \\\\ 0 & ,z","categories":[],"tags":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/tags/学习笔记/"},{"name":"deeplearning.ai","slug":"deeplearning-ai","permalink":"http://yoursite.com/tags/deeplearning-ai/"}]},{"title":"deeplearning.ai学习笔记（二）神经网络基础——以二值分类问题的逻辑回归模型为例","slug":"deeplearning-ai学习笔记（二）神经网络基础——以二值分类问题的逻辑回归模型为例","date":"2019-08-11T02:18:57.000Z","updated":"2019-08-12T13:56:39.367Z","comments":true,"path":"2019/08/11/deeplearning-ai学习笔记（二）神经网络基础——以二值分类问题的逻辑回归模型为例/","link":"","permalink":"http://yoursite.com/2019/08/11/deeplearning-ai学习笔记（二）神经网络基础——以二值分类问题的逻辑回归模型为例/","excerpt":"二值分类（Binary Classification ）问题描述例如：猫咪检测器（Cat vs Non-Cat ） 目标是训练一个分类器，对于输入的照片，如果它是一张猫咪的照片就输出1，否则输出0。 输入将一张RGB三通道彩色图像展开为一个长的列向量做为输入。 若图片尺寸为64*64，则向量的维度n(x)=64*64*3=12288。","text":"二值分类（Binary Classification ）问题描述例如：猫咪检测器（Cat vs Non-Cat ） 目标是训练一个分类器，对于输入的照片，如果它是一张猫咪的照片就输出1，否则输出0。 输入将一张RGB三通道彩色图像展开为一个长的列向量做为输入。 若图片尺寸为64*64，则向量的维度n(x)=64*64*3=12288。 输入特征向量x 输出对于二值分类问题，输出结果只有两个——0或1。 输出标签的向量形式：（m维列向量） \\begin{bmatrix} y^{(1)}\\\\ y^{(2)} \\\\ \\vdots \\\\ y^{(i)} \\end{bmatrix}训练数据 单个样本由一对（x,y）表示，其中x是一个n(x)维的特征向量 ，y是取值为0或1的标签。 训练集包含m个训练样本（用小写m代表训练集的样本总数），(x(i),y(i)) 表示第i个样本的输入和输出。 写成矩阵形式如下：（X.shape=n_x*m） \\begin{bmatrix} \\vdots & \\vdots & \\vdots & \\vdots \\\\ x^{(1)} & x^{(2)} & \\cdots & x^{(i)} \\\\ \\vdots & \\vdots & \\vdots & \\vdots \\end{bmatrix}逻辑回归（Logistic Regression ）模型逻辑回归是一种用于解决输出是0/1的监督学习问题的学习算法，它使得预测值与训练数据之间的偏差最小。 定义以Cat vs No - cat为例： 把一张图片展开为特征向量x做为输入，算法将估计这张图片中包含猫咪的概率。 Given~x~,~\\hat{y}=P(y=1|x),where~0\\leq\\hat{y}\\leq1 逻辑回归模型 其中各个参数的意义： x：输入特征向量（一个n_x维列向量） y：训练集标签，y∈0,1 weights——w：权重（一个n_x维列向量） threshold——b：偏置量（一个实数） Sigmoid 函数： \\sigma(z)=\\frac{1}{1+e^{-z}} Sigmoid函数图像 该函数的特点： 当z趋于+∞，函数值趋于1 当z趋于-∞，函数值趋于0 当z=0，函数值为0.5 作用：将输出值限制在[0,1]，使其可以表示一个概率值 代价函数（Cost function ）损失函数 vs 代价函数 损失函数（Loss function）是定义在单个样本上的，算的是一个样本的误差。 代价函数（Cost function）是定义在整个训练集上的，是所有样本误差的平均，也就是损失函数的平均。 代价函数用来衡量参数在整个模型中的作用效果。 逻辑回归的损失函数 损失函数 推导过程： 我们希望算法输出ŷ 表示当给定输入特征x的时候y=1的概率。换句话说，如果y等于1，那么p(y|x)就等于ŷ ；相反地，当y=0时，p(y|x)就等于1-ŷ 。因此，如果ŷ表示当y=1的概率，那么1-ŷ就表示y=0的概率。 可以定义p(y|x)如下： 由于y只有0和1两种取值，因此上面的两个方程可以归纳为如下一个方程： p(y|x)=ŷ^y*(1-ŷ)^{1-y}因为对数函数是一个绝对的单调递增函数，最大化log(p(y|x))会得出和最大化p(y|x)相似的结果，因此可以取对数，简化公式。 log(ŷ^y*(1-ŷ)^{1-y}) =ylog(ŷ)+(1-y)log(1-ŷ)又因为通常在训练一个学习算法的时候，我们想要让概率变大。而在逻辑回归中，我们想要最小化L(ŷ,y)这个损失函数。最小化损失函数相当于最大化概率的对数，所以需要加一个负号。 L(ŷ,y)=-(ylog(ŷ)+(1-y)log(1-ŷ))逻辑回归的代价函数 代价函数 推导过程： 假设取出的训练样本相互独立，或者说服从独立同分布 (I.I.D: Independent and Identically Distributed) ，这些样本的概率就是各项概率的乘积。 给定X(i)从i=1到m时p(y(i))的乘积： p(y^{(1)})*p(y^{(2)})*\\cdots*p(y^{(m)})最大化这个式子本身和最大化它的对数效果相同，所以取对数： log(p(y^{(1)}))+log(p(y^{(2)}))+\\cdots+log(p(y^{(m)}))=\\sum_{i=1}^{m}log(p(y^{(i)}))=-\\sum_{i=1}^{m}L(ŷ^{(i)},y^{(i)})根据最大似然估计原理，选择能使该式最大化的参数。因为要最小化代价函数，而不是最大化似然值，所以要去掉这个负号。最后为了方便起见，使这些数值处于更好的尺度上，在前面添加一个缩放系数1/m。 综上，代价函数为： J(w,b)=\\frac{1}{m}\\sum_{i=1}^{m}L(ŷ^{(i)},y^{(i)})=-\\frac{1}{m}\\sum_{i=1}^{m}[y^{(i)}log(ŷ^{(i)})+(1-y^{(i)})log(1-ŷ^{(i)})]优化逻辑回归模型时，我们试着去找参数w和b，以此来缩小代价函数J， 逻辑回归可被视为一个非常小的神经网络 。 训练过程——梯度下降（Gradient Descent）算法算法思想在逻辑回归问题中，代价函数J是一个凸函数(convex function) 。为了去找到优的参数值，首先用一些初始值（0或随机）来初始化w和b，因为函数是凸函数，无论在哪里初始化，应该达到同一点或大致相同的点。 梯度下降法以初始点开始，然后朝最陡的下坡方向走一步，这是梯度下降的一次迭代。经过多次迭代收敛到全局最优值或接近全局最优值。 梯度下降示意图 参数的迭代公式： w:=w-\\alpha\\frac{\\partial{J(w,b)}}{\\partial{w}} b:=b-\\alpha\\frac{\\partial{J(w,b)}}{\\partial{b}}数学基础：计算图（Computation Graph）以下式为例 J(a,b,c)=3(a+bc)其计算图为： 计算图 计算图计算（前向传播过程）前向传播即为计算一个样本下J的值，计算过程如下： u=b*c=3*2=6 \\\\ v=a+u=5+6=11 \\\\ J=3V=33计算图求导（反向传播过程）反向传播即根据求导的链式法则，求解最终输出变量J对各个变量的导数。 计算过程如下： \\frac{dJ}{dv}=\\frac{d(3v)}{dv}=3 \\\\ \\frac{dJ}{da}=\\frac{dJ}{dv}*\\frac{dv}{da}=3*\\frac{d(a+u)}{da}=3 \\\\ \\frac{dJ}{du}=\\frac{dJ}{dv}*\\frac{dv}{du}=3*\\frac{d(a+u)}{du}=3 \\\\ \\frac{dJ}{db}=\\frac{dJ}{du}*\\frac{du}{db}=3*\\frac{d(bc)}{db}=3c=3*2=6 \\\\ \\frac{dJ}{dc}=\\frac{dJ}{du}*\\frac{du}{dc}=3*\\frac{d(bc)}{db}=3b=3*3=9为简化表示，将dJ/dval简记为dval，则在本例中： da=3,db=6,dc=9逻辑回归模型的前向传播和反向传播过程（单个样本）逻辑回归模型的计算图 逻辑回归模型的计算图 逻辑回归模型的前向传播顺序计算即可。 逻辑回归模型的反向传播计算过程如下： “da”=\\frac{dL}{da}=-\\frac{y}{a}+\\frac{1-y}{1-a} \\\\ “dz”=\\frac{dL}{dz}=\\frac{dL}{da}*\\frac{da}{dz}=(-\\frac{y}{a}+\\frac{1-y}{1-a})*\\frac{d\\sigma(z)}{dz} = a(1-a) \\\\ “dw_1”=\\frac{dL}{dw_1}=\\frac{dL}{dz}*\\frac{dz}{dw_1}=x_1*“dz” \\\\ “dw_2”=\\frac{dL}{dw_2}=\\frac{dL}{dz}*\\frac{dz}{dw_2}=x_2*“dz” \\\\ “db”=\\frac{dL}{db}=\\frac{dL}{dz}*\\frac{dz}{db}=“dz”非向量化的逻辑回归训练过程 非向量化的逻辑回归训练过程 缺点：显式地使用了两层for循环，时间效率低 解决方法：采用向量化的方法，可以极大地提高时间效率 向量化（Vectorizing）的逻辑回归训练过程 Z = W^{T}*X+b = np.dot(W.T,X)+b //此处存在python的广播机制 \\\\ A = σ(Z) \\\\ dZ = A - Y \\\\ dW = \\frac{1}{m}XdZ^{T}\\\\ db = \\frac{1}{m}*np.sum(dZ)\\\\ W := W - \\alpha dW\\\\ b := b - \\alpha db注意：此为一次迭代的过程，多次迭代使用显示循环不可避免。","categories":[],"tags":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/tags/学习笔记/"},{"name":"deeplearning.ai","slug":"deeplearning-ai","permalink":"http://yoursite.com/tags/deeplearning-ai/"}]},{"title":"那些既熟悉又陌生的C/C++知识点（长期更新）","slug":"那些既熟悉又陌生的C-C-知识点（长期更新）","date":"2019-08-09T15:21:44.000Z","updated":"2019-08-09T16:04:41.156Z","comments":true,"path":"2019/08/09/那些既熟悉又陌生的C-C-知识点（长期更新）/","link":"","permalink":"http://yoursite.com/2019/08/09/那些既熟悉又陌生的C-C-知识点（长期更新）/","excerpt":"","text":"头文件的等价写法在C++标准中，stdio.h更推荐使用等价写法：cstdio，也就是在前面加一个c，然后去掉.h即可。 123/* 以下两种写法等价 */#include&lt;stdio.h&gt;#include&lt;cstdio&gt; 整型变量类型表示数的范围 整型int：32位整数/绝对值在10^9范围以内的整数都可以定义为int型 长整型long long：64位整数/10^18以内（如10^10）的整数就要定义为long long型 long long型的使用long long型赋大于2^31-1的初值，需要在初值后面加上LL 经常利用typedef用LL来代替long long，以避免在程序中大量出现long long而降低编码的效率。 12345678#include&lt;cstdio&gt;typedef long long LL; //给long long起个别名LLint main()&#123; LL a = 123456789012345LL, b = 234567890123456LL; printf(\"%lld\\n\", a + b); return 0;&#125; 浮点数的存储类型对于浮点型，不要使用float，碰到浮点型的数据都应该用double来存储。 单精度float：有效精度只有6~7位 双精度double：有效精度有15~16位 double型的输入输出格式 输出格式：%f（与float型相同） 输入格式：scanf中是%lf 注：有些系统如果把输出格式写成%lf也不会出错，但尽量还是按标准来","categories":[],"tags":[{"name":"C/C++","slug":"C-C","permalink":"http://yoursite.com/tags/C-C/"}]},{"title":"deeplearning.ai学习笔记（一）深度学习引言","slug":"deeplearning-ai学习笔记（一）深度学习引言","date":"2019-08-09T06:30:38.000Z","updated":"2019-08-09T09:05:27.062Z","comments":true,"path":"2019/08/09/deeplearning-ai学习笔记（一）深度学习引言/","link":"","permalink":"http://yoursite.com/2019/08/09/deeplearning-ai学习笔记（一）深度学习引言/","excerpt":"AI is the new Electricity. ——吴恩达（Andrew Ng） 大约在一百年前，社会的电气化改变了每个主要行业。而如今我们见到了 AI令人惊讶的能量会产生同样巨大的转变。显然 AI的各个分支中，发展最为迅速的就是深度学习（deep learning）。而深度学习，一般指的是训练神经网络（有时是非常非常大/深的神经网络）。","text":"AI is the new Electricity. ——吴恩达（Andrew Ng） 大约在一百年前，社会的电气化改变了每个主要行业。而如今我们见到了 AI令人惊讶的能量会产生同样巨大的转变。显然 AI的各个分支中，发展最为迅速的就是深度学习（deep learning）。而深度学习，一般指的是训练神经网络（有时是非常非常大/深的神经网络）。 何为神经网络（What is a neural network?）引例：房价预测（Housing Price Prediction）如下图，对于单个因素（如房屋面积）的房屋预测，可以用ReLU函数进行拟合，相当于一个只有一个神经元的神经网络。 ReLU函数拟合 用房子的大小 x 作为神经网络的输入，它进入到这个节点(这个小圈)中 ，然后这个小圈就输出了房价 y 。所以这个小圈，也就是一个神经网络中的一个神经元，就会执行上图中画出的这个方程。 单个神经元的神经网络 一个很大的神经网络是由许多这样的单一神经元叠加在一起组成。比如下面这个例子，我们不仅仅根据房屋大小来预测房屋价格，我们引入其他特征量。能够容纳的家庭人口也会影响房屋价格 ，这个因素其实是取决于房屋大小以及卧室的数量这两个因素决定了这个房子是否能够容纳你的家庭 。 多因素房价预测 所以在这个例子中： x 表示所有这四个输入 (房屋大小、卧室数量、邮政编码、富裕程度) y表示试图去预测的价格 每一个小圆圈是ReLU 函数或者别的一些非线性函数 这就是最基本的神经网络。 简单神经网络 深度学习：监督学习的一种（Supervised Learning with Neural Networks）监督学习与非监督学习监督学习：给定标记好的训练样本集，如回归问题、分类问题 非监督学习：给定样本集，发现特征数据中的分布结构，如聚类问题 监督学习 非监督学习 深度学习在监督学习中的应用 &amp; 常用神经网络 深度学习的应用 几种常见神经网络 结构化数据与非结构化数据 结构化数据与非结构化数据示例 深度学习兴起的原因（Why is Deep Learning taking off?） Scale drives deep learning progress.——吴恩达（Andrew Ng） 深度学习的性能 x-axis is the amount of data （数据量） y-axis (vertical axis) is the performance of the algorithm. （算法性能） 数据量与算法性能关系 当数据量比较少时，深度学习方法性能不一定优于经典机器学习方法。 通过增加数据量和神经网络规模可提升深度学习方法的性能。 深度学习兴起的原因 Data：信息化社会产生了巨大的数据量 Computation：现代计算机计算性能的极大提升（GPU与CPU） Algorithms：算法的优化进一步提升了性能（如ReLU的使用）","categories":[],"tags":[{"name":"学习笔记","slug":"学习笔记","permalink":"http://yoursite.com/tags/学习笔记/"},{"name":"deeplearning.ai","slug":"deeplearning-ai","permalink":"http://yoursite.com/tags/deeplearning-ai/"}]}]}